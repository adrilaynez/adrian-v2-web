import { TranslationDictionary } from './types';

export const es: TranslationDictionary = {
    common: {
        language: "Idioma",
        loading: "Cargando...",
        error: "Error",
        comingSoon: "Próximamente",
        backToProjects: "Volver a Proyectos",
        toggleLanguage: "Cambiar idioma",
        code: "Código",
        liveDemo: "Demo en Vivo",
        viewCaseStudy: "Ver Caso de Estudio",
    },
    nav: {
        home: "Inicio",
        projects: "Proyectos",
        lab: "Laboratorio",
        notes: "Notas",
    },
    projects: {
        hero: {
            badge: "Investigación y Desarrollo",
            titlePrefix: "Construyendo la",
            titleSuffix: "Frontera Digital.",
            description: "Una colección curada de mi trabajo en sistemas distribuidos, infraestructura de IA y computación de alto rendimiento.",
        },
        flagship: {
            badge: "Proyecto Insignia",
            featured: "Destacado",
            liveDemo: "Demo en Vivo Disponible",
            title: "LM-Lab",
            description: "Una plataforma interactiva para explorar arquitecturas de modelos de lenguaje desde primeros principios. Visualiza matrices de transición, sondea dinámicas de inferencia y genera texto — todo impulsado por un backend FastAPI en vivo con PyTorch.",
            highlights: {
                inference: {
                    title: "Inferencia en Vivo",
                    desc: "Predicción del siguiente carácter en tiempo real con distribuciones de probabilidad",
                },
                matrix: {
                    title: "Matriz de Transición",
                    desc: "Mapa de calor interactivo de las probabilidades bigrama aprendidas",
                },
                generation: {
                    title: "Generación de Texto",
                    desc: "Genera texto con temperatura configurable y seguimiento paso a paso",
                },
            },
            cta: {
                explorer: "Abrir Laboratorio",
                architecture: "Ver Arquitectura",
                demo: "Ejecutar Demo Interactiva",
            },
        },
        experiments: {
            title: "Experimentos Seleccionados",
            items: {
                distriKv: {
                    title: "Distri-KV",
                    desc: "Un almacén clave-valor distribuido implementado en Go, con consenso Raft y sharding.",
                },
                neuroVis: {
                    title: "NeuroVis",
                    desc: "Herramienta de visualización interactiva para activaciones de redes neuronales en tiempo real.",
                },
                autoAgent: {
                    title: "Auto-Agent",
                    desc: "Un framework de agente autónomo ligero enfocado en tareas de codificación.",
                },
            },
        },
    },
    notes: {
        hero: {
            est: "EST. 2024",
            archive: "ARCHIVO DE INVESTIGACIÓN",
            titlePrefix: "El Cuaderno de",
            titleSuffix: "Ingeniería",
            description: "Exploraciones en <strong class='text-primary'>inteligencia distribuida</strong>, topología de alta dimensión y la mecánica del software moderno.",
        },
        featured: {
            badge: "ÚLTIMA INVESTIGACIÓN",
            readTime: "{minutes} min de lectura",
            figure: "Figura 1.0: Visualización del Espacio Latente",
        },
        grid: {
            title: "Entradas Anteriores",
        },
        backToNotes: "Volver a Notas",
        noteNotFound: "Nota no encontrada",
    },
    lab: {
        bigram: "Bigrama",
        ngram: "N-Gram",
        mlp: "MLP",
        transformer: "Transformer",
        neuralNetworks: "Redes Neuronales",
        playground: {
            inputs: {
                x1Label: "x₁ (entrada 1)",
                x2Label: "x₂ (entrada 2)",
                scaleHint: "(en escala 0–1)",
                xLabel: "Entrada x",
                wLabel: "Peso w",
                bLabel: "Sesgo b",
                targetLabel: "Objetivo",
            },
        },
        shell: {
            allModels: "Volver al Lab",
        },
        active: "Lab. Activo",
        waking: "Despertando",
        serverWarning: {
            title: "ARRANQUE EN FRÍO DETECTADO",
            subtitle: "PROTOCOLO DE CONTENCIÓN ACTIVO",
            message: "El servidor está despertando de su hibernación. Las instancias gratuitas de Render se apagan tras inactividad — sí, lo hosteo en un servidor gratis porque soy un estudiante sin un duro.",
            donate: "Si la espera de 30s te resulta insoportable, invítame a un café para que pueda pagar un servidor de verdad. O simplemente espera, es entretenimiento gratis.",
            status: "INTENTANDO CONEXIÓN",
            dismiss: "SOBREVIVIRÉ",
            connected: "SEÑAL ADQUIRIDA",
        },
        mode: {
            educational: "Educativo",
            educationalDescription: "Experiencia guiada con explicaciones narrativas y progresivas.",
            freeLab: "Lab Libre",
            freeLabDescription: "Acceso completo a herramientas y visualizaciones para experimentación manual y análisis.",
            selectViewingMode: "Selecciona el Modo de Visualización",
            availableModels: "Modelos Disponibles",
        },
        status: {
            ready: "Listo",
            coming: "Próximo",
        },
        models: {
            bigram: {
                name: "Explorador Bigrama",
                subtitle: "Capítulo 1 · Contando Pares",
                description: "Empieza aquí. El modelo de lenguaje más simple: cuenta con qué frecuencia un carácter sigue a otro, guárdalo en una tabla y muestrea el siguiente carácter. Verás exactamente cómo un modelo genera texto a partir de estadísticas puras — y por qué un solo carácter de memoria no es suficiente.",
            },
            ngram: {
                name: "Laboratorio N-Gram",
                subtitle: "Capítulo 2 · Más Memoria, Más Problemas",
                description: "¿Y si el modelo recuerda dos caracteres? ¿Tres? ¿Cinco? Las predicciones mejoran — pero la tabla explota exponencialmente y el modelo aún no puede generalizar. Descubre los límites fundamentales de los modelos basados en conteo.",
            },
            neuralNetworks: {
                name: "Redes Neuronales",
                subtitle: "Capítulo 3 · Del Conteo al Aprendizaje",
                description: "El conteo chocó contra un muro. Ahora aprendemos. Construye intuición sobre perceptrones, funciones de activación, retropropagación y descenso de gradiente — los bloques que permiten a las máquinas descubrir patrones por sí mismas.",
            },
            mlp: {
                name: "Modelo MLP",
                subtitle: "Capítulo 4 · Modelado Neuronal del Lenguaje",
                description: "Aplica todo lo aprendido: reemplaza la tabla N-gram con una red neuronal que usa embeddings densos y pesos aprendidos. Ve cómo un MLP generaliza más allá de coincidencias exactas y produce mejor texto con menos parámetros.",
            },
            transformer: {
                name: "Arquitectura Transformer",
                subtitle: "Capítulo 5 · La Atención es Todo",
                description: "La arquitectura detrás de GPT y la IA moderna. La auto-atención permite al modelo enfocarse dinámicamente en cualquier parte de la secuencia, eliminando ventanas de contexto fijas. Próximamente.",
            },
        },
        dashboard: {
            chip: "Laboratorio de Interpretabilidad de Modelos",
            suite: "Suite",
            description1: "Explora el funcionamiento interno de los modelos de lenguaje mediante visualizaciones interactivas.",
            description2: "Sigue una ruta guiada o experimenta libremente en el sandbox.",
            launchUnit: "INICIAR UNIDAD",
            secureLock: "BLOQUEO SEGURO",
            footerCopyright: "© 2026 LM-LAB INSTRUMENTS",
            footerSystem: "SISTEMA_INTERPRETABILIDAD",
            secureConnection: "Conexión Segura",
            hardwareMock: "Hardware: v4-8 TPU MOCK",
        },
        placeholders: {
            mlp: {
                title: "Explorador MLP",
                description: "Explorador de modelos de lenguaje Multi-Layer Perceptron. Actualmente en desarrollo - vuelve pronto.",
            },
            transformer: {
                title: "Explorador Transformer",
                description: "Explorador de modelos transformer basados en atención. Actualmente en desarrollo - vuelve pronto.",
            },
        },
        landing: {
            hero: {
                badge: "Unidad de Investigación",
                subtitle: "Laboratorio de Interpretabilidad Interactiva",
                description: "Desmitificando los Modelos de Lenguaje a través de la ingeniería de primeros principios y evidencia visual.",
                subDescription: "Esta unidad se centra en la interpretabilidad mecanística: la ingeniería inversa de los pesos neuronales en conceptos humanos comprensibles.",
                start: "Inicializar Modelo Base",
                recommended: "Recomendado para principiantes",
            },
            highlights: {
                visualizations: "Visualización Interactiva",
                inference: "Inferencia en Vivo",
                guided: "Ruta Guiada",
                backend: "Backend PyTorch",
            },
            learningPath: {
                title: "Ruta de Aprendizaje",
                status: {
                    soon: "En Desarrollo",
                    ready: "Unidad Activa",
                },
            },
            modes: {
                title: "Protocolos de Laboratorio",
                entryTitle: "Elige Tu Experiencia",
                entrySubtitle: "Selecciona cómo quieres explorar el lab. Puedes cambiarlo en cualquier momento.",
                defaultNote: "Usando Modo Educativo por defecto",
                educational: {
                    title: "Modo Educativo",
                    subtitle: "Descubrimiento Guiado",
                    description: "Narrativa paso a paso que explica el 'porqué' detrás de las matemáticas. Ideal para el aprendizaje conceptual.",
                    tag: "Recomendado",
                    features: ["Narrativas guiadas", "Revelaciones progresivas", "Explicaciones conceptuales"],
                },
                freeLab: {
                    title: "Modo Lab Libre",
                    subtitle: "Entorno Sandbox",
                    description: "Acceso total a todas las herramientas de visualización y parámetros de generación. Para experimentación avanzada.",
                    tag: "Avanzado",
                    features: ["Todas las herramientas", "Control de parámetros", "Sin flujo guiado"],
                },
                cta: "Empezar con Bigrama",
                ctaSubtext: "El modelo más simple — el mejor punto de partida",
                changeMode: "Cambiar modo",
                selectedMode: "Seleccionado",
            },
            availableModels: {
                title: "Unidades Biológicas Disponibles",
                enter: "Entrar al Lab",
                locked: "Protocolo Restringido",
            },
            footer: {
                text: "Instrumento Científico v2.2 // Build 2026",
            },
        },
    },
    footer: {
        builtBy: "Construido por",
        sourceAvailable: "El código fuente está disponible en",
    },
    datasetExplorer: {
        title: "Evidencia del Corpus",
        subtitle: "¿Por qué el modelo aprendió '{context}' -> '{next}'?",
        scanning: "Escaneando corpus de entrenamiento...",
        occurrencesFound: "Ocurrencias Encontradas",
        source: "Fuente",
        contextSnippets: "Fragmentos de Contexto",
        noExamples: "No se encontraron ejemplos para esta transición.",
        fetchError: "No se pudieron obtener ejemplos del dataset",
        explorerTitle: "Explorador del Corpus",
        searching: "Buscando en el Dataset...",
        querySequence: "Secuencia Consultada",
        found: "Se encontraron {count} ocurrencias",
        exampleContexts: "Contextos de Ejemplo",
        noExamplesValidation: "No se encontraron ejemplos en el fragmento de validación.",
    },
    training: {
        title: "Insight del Entrenamiento",
        noData: "Ejecuta inferencia para ver datos de entrenamiento",
        tooltip: {
            lossTitle: "¿Qué es la Pérdida (Loss)?",
            lossErrorPrefix: "Error de Predicción:",
            lossError: "La pérdida mide cuán 'sorprendido' está el modelo. Una pérdida alta significa que adivina mal frecuentemente.",
            lossBenchmarkPrefix: "El Referente:",
            lossBenchmark: "Adivinar al azar daría una pérdida de ~4.56 (-ln(1/96)). ¡Cualquier valor menor significa que el modelo ha aprendido algo!",
            lossCurve: "La curva descendente muestra al modelo descubriendo patrones lentamente en tu texto.",
        },
        stats: {
            finalLoss: "Pérdida Final",
            steps: "Pasos",
            batchSize: "Tamaño de Lote",
            learningRate: "Ratio de Aprendizaje",
            parameters: "Parámetros",
            tooltips: {
                finalLoss: "El nivel de error. Al final del entrenamiento, debería ser lo más bajo posible.",
                steps: "Cuántas veces el modelo practicó para mejorar sus predicciones.",
                batchSize: "La cantidad de piezas de información que el modelo procesa a la vez.",
                learningRate: "La velocidad de aprendizaje. Ni muy rápido para no pasarse, ni muy lento para no tardar demasiado.",
                parameters: "El tamaño de la red neuronal o 'cerebro' del modelo.",
            },
        },
    },
    ngram: {
        training: {
            title: "Insights del Entrenamiento",
            stats: {
                totalTokens: "Tokens Totales",
                uniqueContexts: "Contextos Únicos",
                utilization: "Utilización de Contexto",
                sparsity: "Espasidad",
                transitionDensity: "Densidad de Transición",
                subs: {
                    possiblePrefix: "de",
                    possibleSuffix: "posibles",
                    fractionObserved: "Fracción de contextos observados",
                    unseen: "Fracción de contexto no visto",
                },
            },
        },
        widgets: {
            typoBreaker: {
                title: "Rompe el modelo",
                subtitle: "Escribe una palabra mal escrita o una frase nueva — mira cómo el modelo falla",
                placeholder: "Escribe una palabra mal escrita o una frase nueva…",
                reset: "Reiniciar",
                test: "Probar",
                tryLabel: "Prueba:",
                contextLookup: "Búsqueda de contexto",
                modelConfidence: "Confianza del modelo",
                randomMarker: "↑ azar (1/{vocab} ≈ 1%)",
                verdictKnownPrefix: "El modelo encontró un contexto familiar",
                verdictKnownSuffix: "y puede hacer una predicción razonable. Pero cambia aunque sea un carácter y todo el contexto pasa a ser desconocido.",
                verdictUnknownStrong: "No se encontró un contexto coincidente.",
                verdictUnknownBody: "El modelo nunca ha visto esta secuencia exacta de caracteres en el entrenamiento. La confianza colapsa al azar (1/{vocab} por carácter). Un humano entendería la intención — el modelo N-grama no puede.",
                examples: {
                    swapTwoLetters: "Intercambia dos letras",
                    commonMisspelling: "Error común",
                    novelWord: "Palabra nueva",
                    missingVowel: "Falta una vocal",
                },
            },
            generalizationFailure: {
                seenInTraining: "Visto en el entrenamiento",
                neverSeenInTraining: "Nunca visto en el entrenamiento",
                nextWord: "siguiente palabra →",
                confidence: "confianza",
                neverSeenNoPrediction: "Nunca visto. No hay predicción posible.",
                explanation: "Cambiar \"cat\" por \"dog\" crea una fila totalmente nueva en la tabla. El modelo no puede transferir lo que sabe sobre gatos — cada contexto está completamente aislado.",
            },
            sparsityHeatmap: {
                title: "Mapa de densidad de la tabla",
                subtitle: "¿Cuánta parte de la tabla de probabilidades tiene datos reales?",
                entriesSuffix: "entradas",
                fill: "Relleno",
                density: "Densidad:",
                legend: {
                    high: "Alta",
                    medium: "Media",
                    low: "Baja",
                    empty: "Vacía",
                },
                insights: {
                    n1: "La tabla de bigramas está mayormente llena — con solo 96 contextos posibles, incluso un corpus modesto cubre la mayoría de pares de caracteres. Pero este modelo solo ve un carácter de historia.",
                    n2: "La tabla de trigramas ya es notablemente más dispersa. Con 9.216 contextos posibles, muchas combinaciones de 2 caracteres nunca aparecen en el entrenamiento. El modelo empieza a adivinar al azar en contextos no vistos.",
                    n3: "La tabla de 4-gramas está casi completamente vacía. Con 884.736 contextos posibles, la gran mayoría no tiene ejemplos de entrenamiento. El modelo es esencialmente ciego para la mayoría de inputs.",
                    n4: "La tabla de 5-gramas es un desierto de ceros. Más de 8 mil millones de contextos posibles, y tus datos cubren una fracción diminuta. Esto no es un problema resoluble — es una certeza matemática.",
                },
            },
            confidenceImprovement: {
                title: "Cómo el contexto afina las predicciones",
                subtitle: "Haz clic en cualquier fila para ver la distribución completa",
                after: "Después de",
                summary: "32% → 85% → 91% — más contexto = predicciones más precisas",
                hints: {
                    n1: "Después de solo \"h\", muchas vocales y consonantes son plausibles. El modelo reparte la probabilidad de forma muy dispersa.",
                    n2: "\"th\" es una señal muy potente — en inglés, \"the\" es la palabra más común. La confianza salta drásticamente.",
                    n3: "\"the\" casi siempre termina con un espacio. Ahora el modelo está al 91% — queda muy poca ambigüedad.",
                },
            },
            contextDrilldown: {
                lookupTitle: "Búsqueda de contexto",
                lookupSubtitle: "Escribe un contexto de {n} caracteres para ver su distribución del siguiente carácter",
                lookupPlaceholder: "Introduce {n} caracteres…",
                lookupButton: "Buscar",
                progressSuffix: "caracteres",
                noDataFree: "No se encontraron datos para este contexto. Puede que el modelo no haya visto \"{context}\" en el entrenamiento. Este es el problema de la dispersión en acción.",
                drilldownTitle: "Exploración por contexto",
                drilldownSubtitle: "Elige {n} carácter{suffix} para explorar las predicciones del modelo",
                breadcrumbStart: "Inicio",
                breadcrumbDistribution: "distribución",
                pickFirst: "Elige el primer carácter ({remaining} restantes)",
                pickNext: "Después de \"{context}\" — elige el siguiente ({remaining} restantes)",
                back: "Atrás",
                fetching: "Obteniendo distribución para \"{context}\"…",
                fetchError: "No se pudo obtener la distribución",
                noDataDrilldown: "Sin datos para el contexto \"{context}\". Este contexto nunca se observó en el entrenamiento — el problema de la dispersión en acción.",
                chartTitle: "P(siguiente | \"{context}\")",
                chartTop: "Top {count} predicciones",
            },
            infiniteTable: {
                title: "El problema de cobertura de datos",
                subtitle: "¿Cuánta parte de cada tabla N-grama puedes llenar con datos reales?",
                trainingDataSize: "Tamaño de datos de entrenamiento",
                tokensLabel: "{count} tokens",
                entriesLabel: "{count} entradas",
                insight: {
                    v0: "Incluso con {tokens} tokens de datos de entrenamiento, la tabla de 5-gramas ({entries} entradas) está prácticamente vacía. El modelo no tendría predicción para casi cualquier contexto que encuentre.",
                    v1: "Con {tokens} tokens, la tabla de 5-gramas está por debajo del 1%. La mayoría de contextos en inferencia tendrán cero ejemplos de entrenamiento.",
                    v2: "Con {tokens} tokens, las tablas de N pequeño se llenan — pero la tabla de 5-gramas sigue cubierta solo en {pct}. La dispersión es un problema de datos, no solo de almacenamiento.",
                },
            },
            countingComparison: {
                bigramTitle: "Bigrama (N=1)",
                bigramContext: "contexto de 1 carácter",
                bigramNote: "Muy disperso — muchos caracteres pueden seguir plausiblemente a \"h\".",
                trigramTitle: "Trigrama (N=2)",
                trigramContext: "contexto de 2 caracteres",
                trigramNote: "Más afilado — \"th\" casi siempre lleva a \"e\".",
                tooltips: {
                    h_e: "Después de 'h', 'e' es el siguiente carácter más común — pero muchas otras letras también pueden seguir a 'h'.",
                    h_a: "Después de 'h', 'a' aparece en palabras como 'have', 'hand', 'hard'.",
                    h_i: "Después de 'h', 'i' aparece en palabras como 'his', 'him', 'hit'.",
                    th_e: "Después de 'th', 'e' es abrumadoramente probable — 'the' es la palabra más común en inglés.",
                    th_a: "Después de 'th', 'a' aparece en 'that', 'than', 'thank'.",
                    th_i: "Después de 'th', 'i' aparece en 'this', 'thing', 'think'.",
                },
            },
        },
    },
    landing: {
        hero: {
            status: "Sistema Online :: v2.2",
            role: "Investigación e Ingeniería",
            title: "ADRIAN LAYNEZ ORTIZ",
            tagline1: "Matemáticas e Informática.",
            tagline2: "Interpretabilidad Mecanística · Ingeniería de Alto Rendimiento.",
            cta: {
                lab: "Ver Laboratorio",
                notes: "Leer Notas",
            },
        },
        metrics: {
            research: "Años de Investigación",
            repos: "Repos Open Source",
            projects: "Proyectos Activos",
            curiosity: "Curiosidad",
        },
        about: {
            badge: "Sobre Mí",
            building: "Desarrollando",
            projectTitle: "Motor de Deep Learning — CUDA / C++",
            projectDesc: "Kernels personalizados para operaciones matriciales y retropropagación",
            bio: {
                titlePrefix: "Uniendo Matemáticas Abstractas",
                titleSuffix: "e Inteligencia Artificial",
                p1: "Estudio el Doble Grado en <strong class='text-foreground'>Matemáticas e Ingeniería Informática</strong> en la Universidad Complutense de Madrid. Mi investigación se centra en comprender las redes neuronales a su nivel más profundo — desde la dinámica de gradientes hasta la optimización a nivel de kernel.",
                p2: "Me especializo en <strong class='text-foreground'>Interpretabilidad Mecanística</strong> — la ciencia de realizar ingeniería inversa sobre cómo las redes neuronales representan y procesan la información internamente. En lugar de tratar los modelos como cajas negras, descompongo sus circuitos para entender <em class='text-foreground/80'>por qué funcionan</em>.",
                mission: "Mi misión: hacer los sistemas de IA transparentes a través de un análisis matemático riguroso e ingeniería de bajo nivel.",
            },
        },
        skills: {
            title: "Competencias Técnicas",
            linearAlgebra: "Álgebra Lineal",
            topology: "Topología",
            convexOpt: "Optimización Convexa",
        },
        work: {
            badge: "Trabajo Seleccionado",
            titlePrefix: "Ingeniería desde",
            titleSuffix: "Primeros Principios",
            description: "Cada proyecto comienza con una pregunta. Desde reimplementar papers seminales hasta escribir kernels de GPU desde cero, cada uno es un ejercicio de comprensión profunda.",
            viewAll: "Ver Todos los Proyectos",
            items: {
                nanoTransformer: {
                    title: "Nano-Transformer",
                    desc: "Reproducción desde cero de 'Attention Is All You Need' en PyTorch — Multi-Head Attention, Positional Encodings y LayerNorm implementados sin módulos preconstruidos.",
                },
                cudaKernels: {
                    title: "Kernels Matriciales CUDA",
                    desc: "Kernels de CUDA escritos a mano explorando la optimización SGEMM — desde implementaciones ingenuas hasta estrategias de memoria compartida en mosaico, comparadas con cuBLAS.",
                },
                autograd: {
                    title: "Motor Autograd",
                    desc: "Librería ligera de diferenciación automática en modo inverso. Construye dinámicamente grafos de computación y propaga gradientes mediante la regla de la cadena.",
                },
                mathDl: {
                    title: "Matemáticas del Deep Learning",
                    desc: "Artículos interactivos explorando la teoría rigurosa detrás de la IA moderna — análisis de convergencia SGD, el álgebra lineal de LoRA y geometría diferencial en variedades neuronales.",
                },
                distributed: {
                    title: "Inferencia Distribuida",
                    desc: "Exploraciones arquitectónicas en entrenamiento paralelo de datos, fragmentación de modelos y tuberías de inferencia optimizadas para redes neuronales a gran escala.",
                },
            },
        },
        contact: {
            badge: "Abierto a Oportunidades",
            titlePrefix: "Construyamos",
            titleMiddle: "Algo",
            titleSuffix: "Juntos",
            description: "Ya sea una colaboración de investigación, una oportunidad de pasantía o simplemente una conversación sobre las matemáticas de la inteligencia — me encantaría saber de ti.",
            email: "Contactar",
            github: "Perfil de GitHub",
            githubShort: "GitHub",
            linkedin: "LinkedIn",
        },
    },
    models: {
        bigram: {
            title: "Modelo de Lenguaje Bigrama",
            description: "El bloque fundamental del modelado de secuencias. Un modelo probabilístico que predice el siguiente carácter basándose únicamente en el predecesor inmediato.",
            params: "Parámetros",
            vocab: "Vocabulario",
            trainingData: "Datos de Entrenamiento",
            loss: "Pérdida Final",
            unknown: "Desconocido",
            tooltips: {
                params: "Son como las conexiones del cerebro. Este modelo es simple, por lo que no necesita muchas.",
                vocab: "Es el conjunto de letras y símbolos que el modelo conoce, como su propio alfabeto.",
                trainingData: "La cantidad de texto que el modelo leyó para aprender a escribir.",
                loss: "Es la puntuación de 'error'. Cuanto más baja sea, mejor sabe el modelo qué letra viene a continuación.",
            },
            sections: {
                visualization: {
                    title: "Visualización: Matriz de Transición",
                    description: "Aquí es donde vive el 'conocimiento' del modelo. Para un modelo Bigrama, esta cuadrícula representa qué letras suelen seguir a otras."
                },
                inference: {
                    title: "Inferencia y Generación",
                    description: "Interactúa con el modelo en tiempo real. Observa cómo 'adivina' el siguiente carácter basándose en probabilidades aprendidas.",
                    placeholder: "Escribe texto para analizar...",
                },
                architecture: {
                    title: "Arquitectura del Modelo",
                    description: "Una mirada técnica a las 'neuronas' y capas que procesan la información."
                },
                training: {
                    title: "Insights de Entrenamiento",
                    description: "Observando el proceso de aprendizaje. Estas métricas muestran cómo el modelo optimizó sus parámetros reduciendo el error de predicción (pérdida) durante 5000 iteraciones."
                },
            },
            hero: {
                scientificInstrument: "Instrumento Científico v1.0",
                explanationButton: "¿Necesitas una explicación intuitiva?",
                explanationSub: "Entiende la idea central antes de sumergirte en las matemáticas y visualizaciones.",
            },
            matrix: {
                title: "Matriz de Transición",
                activeSlice: "Transición de Slice Activo",
                tryIt: {
                    label: "Pruébalo:",
                    text: "Haz clic en cualquier celda coloreada para ver",
                    highlight: "ejemplos reales de entrenamiento",
                },
                searchPlaceholder: "Resaltar carácter…",
                runInference: "Ejecuta inferencia para generar la matriz de transición",
                nextChar: "Sig. car.",
                probability: "P (%)",
                distribution: "Distribución",
                tooltip: {
                    title: "¿Cómo leer este gráfico?",
                    desc: "Las filas representan el carácter actual y las columnas el siguiente carácter. Las celdas más brillantes indican mayor probabilidad de transición.",
                    rows: "Filas (Y):",
                    rowsDesc: "La letra que el modelo acaba de escribir.",
                    cols: "Columnas (X):",
                    colsDesc: "La letra que el modelo intenta adivinar.",
                    brightness: "Brillo:",
                    brightnessDesc: "Cuanto más brillante sea un cuadrado, más probable es que ese par de letras aparezca en el texto.",
                    example: "Ejemplo: Si la fila es 'q' y la columna 'u' brilla intensamente, significa que el modelo sabe que después de 'q' casi siempre viene 'u'.",
                },
                slice: "Slice:",
                datasetMeta: {
                    learnedFrom: "Aprendido de",
                    summarizes: "resume",
                    rawChars: "caracteres brutos",
                    inTrain: "en el split de entrenamiento",
                    vocab: "a través de",
                    symbols: "símbolos únicos",
                    corpus: "Nombre del Corpus:",
                    rawText: "Texto Bruto Total:",
                    trainingSplit: "Datos de Entrenamiento:",
                    vocabulary: "Tamaño del Vocabulario:",
                    charTokens: "caracteres",
                },
                probFlow: {
                    badge: "Visualizador de Flujo de Probabilidad",
                    alreadyNormalized: "⚠ La matriz parece pre-normalizada",
                    description: "Explora cómo los conteos brutos se convierten en probabilidades y cómo el modelo muestrea el siguiente token. Este diagrama interactivo muestra el pipeline completo de inferencia: desde seleccionar un carácter de contexto, hasta normalizar su fila en una distribución de probabilidad, hasta muestrear estocásticamente el siguiente token.",
                    step1: "Paso 1: Seleccionar Contexto",
                    step2: "Paso 2: Normalizar",
                    step3: "Paso 3: Muestrear Siguiente Token",
                    currentToken: "Token Actual",
                    typeToChange: "Escribe para cambiar contexto",
                    normalize: "Normalizar",
                    softmax: "Softmax",
                    temperature: "Temperatura",
                    educational: {
                        normTitle: "Normalización Simple",
                        normDesc: "Divide cada conteo por la suma de la fila. Esto convierte frecuencias brutas en probabilidades que suman 1.0.",
                        softmaxTitle: "Softmax (Escalado por Temperatura)",
                        softmaxDesc: "Exponencia valores y normaliza. La temperatura controla la nitidez: temp baja → distribución punteada, temp alta → distribución uniforme.",
                        tempTitle: "Temperatura",
                        tempDesc: "Controla la nitidez de la distribución. Temperatura baja (< 1) concentra la probabilidad en los tokens más probables. Temperatura alta (> 1) la distribuye más uniformemente, produciendo resultados más variados.",
                    },
                    tempLabel: "Temperatura",
                    tempTooltip: "Controla la aleatoriedad. Más baja = más determinista, Más alta = más creativo/aleatorio",
                    sampleButton: "Muestrear Siguiente Token",
                    sample: "Muestrear Siguiente Token",
                    sampling: "Muestreando...",
                    result: "Resultado Muestreado",
                    sampled: "Muestreado",
                    topCandidate: "Candidato principal",
                    mostLikely: "Más Probable",
                    probability: "Probabilidad",
                    roll: "Tirada Aleatoria",
                    explanation: "El modelo lanzó un dado ponderado (tirada = {roll}) y seleccionó '{token}' con probabilidad {prob}%",
                    stochasticNote: "El muestreo es estocástico — cada clic puede producir un resultado diferente incluso para el mismo carácter de contexto.",
                },
                labModeGuide: "Esta es la matriz de transición completa entrenada con ensayos de Paul Graham. Cada fila es un carácter; cada columna es el carácter que le sigue. Celdas más brillantes = transiciones más frecuentes. Haz clic en cualquier celda para ver ejemplos reales del corpus.",
                limitationGuide: "Observa la restricción fundamental: el modelo solo mira el último carácter. No puede aprender que 'th' casi siempre va seguido de 'e', porque cuando ve 'h', la 't' ya está olvidada. Esta memoria de un solo token es exactamente lo que los modelos N-gram y neurales superan.",
                storySteps: {
                    problem: {
                        title: "El Problema",
                        body: "El lenguaje es secuencial — cada carácter depende de lo que vino antes. El desafío es capturar esta estructura computacionalmente. ¿Cómo construimos un modelo que pueda predecir lo que viene después en un flujo de texto?",
                    },
                    representation: {
                        title: "Representando Texto",
                        body: "Antes de modelar el lenguaje, necesitamos decidir cómo representarlo. La elección de representación determina el tamaño del vocabulario, la capacidad del modelo y sus limitaciones.",
                    },
                    solution: {
                        title: "La Solución Bigrama",
                        body: "El enfoque más simple: contar con qué frecuencia cada carácter sigue a todos los demás en un gran corpus de entrenamiento. Estos conteos, una vez normalizados en probabilidades, forman un modelo estadístico completo del lenguaje a nivel de carácter.",
                    },
                    matrix: {
                        title: "La Matriz de Transición",
                        body: "Cada conteo se almacena en una matriz V × V (V = tamaño del vocabulario). Cada fila representa un carácter actual; cada columna representa el siguiente. El brillo de una celda codifica la probabilidad de transición aprendida del texto real.",
                    },
                    probabilities: {
                        title: "De Conteos a Probabilidades",
                        body: "Los conteos brutos se normalizan fila por fila para que cada fila sume 1.0, formando una distribución de probabilidad válida. El modelo puede entonces hacer predicciones concretas: \"Después de 'h', hay un 34% de probabilidad de que el siguiente carácter sea 'e'.\"",
                    },
                    limitation: {
                        title: "La Limitación Fundamental",
                        body: "El modelo bigrama tiene cero memoria más allá del carácter inmediatamente anterior. No puede aprender que 'th' casi siempre va seguido de 'e', porque cuando ve 'h', la 't' ya está olvidada. Este horizonte de un solo token es lo que motiva los modelos N-gram y neurales.",
                    },
                },
                representation: {
                    charTitle: "Tokens a nivel de carácter",
                    charBody: "Vocabulario pequeño y fijo (~96 caracteres ASCII imprimibles). Toda entrada posible es representable. Simple de implementar y visualizar — ideal para entender los fundamentos.",
                    wordTitle: "Tokens a nivel de palabra",
                    wordBody: "Unidades semánticas más ricas, pero el vocabulario puede alcanzar 50.000–500.000 entradas. Las palabras raras causan escasez; las palabras no vistas en inferencia causan fallos. Mucho más difícil de escalar.",
                },
                builderLabel: "Constructor bigrama paso a paso",
            },
            inference: {
                title: "Consola de Inferencia",
                probDist: "1. Distribución de Probabilidad",
                probDistDesc: "Escribe una frase para ver los top-k caracteres más probables a continuación.",
                tooltip: {
                    title: "¿Qué es la Inferencia?",
                    process: "El Proceso:",
                    processDesc: "El modelo toma tu texto, mira el",
                    processHighlight: "último carácter",
                    processEnd: ", y busca las probabilidades de lo que viene después en su cerebro (la Matriz).",
                    topK: "Top-K:",
                    topKDesc: "Solo mostramos los ganadores principales. Si K=5, ves los 5 candidatos más probables.",
                    note: "Nota: Este modelo es \"determinista\" en sus probabilidades pero \"estocástico\" (aleatorio) cuando realmente elige un carácter para generar texto.",
                },
                lastChar: "Último car.:",
                form: {
                    input: "Texto de Entrada",
                    placeholder: "Escribe texto para analizar...",
                    topK: "Predicciones Top-K",
                    analyze: "Analizar",
                    analyzing: "Analizando...",
                },
            },
            stepwise: {
                title: "Predicción Paso a Paso",
                mainTitle: "2. Predicción Paso a Paso",
                description: "Observa al modelo predecir una secuencia carácter por carácter.",
                form: {
                    input: "Texto de Entrada",
                    placeholder: "Texto inicial...",
                    steps: "Pasos de Predicción",
                    predict: "Predecir Pasos",
                    predicting: "Prediciendo...",
                },
                table: {
                    step: "Paso",
                    char: "Carácter",
                    prob: "Probabilidad",
                },
                result: "Resultado:",
            },
            generation: {
                title: "Patio de Generación",
                mainTitle: "3. Generación de Texto",
                description: "Deja que el modelo alucine texto muestreando de la distribución.",
                tooltip: {
                    title: "¿Cómo se genera el texto?",
                    sampling: "Muestreo:",
                    samplingDesc: "El modelo no solo elige la respuesta #1. \"Tira un dado\" ponderado por probabilidades. Por eso puede generar texto diferente cada vez.",
                    temp: "Temperatura:",
                    tempDesc: "Valores más altos hacen que el dado sea más \"loco\" (más aleatorio). Valores más bajos lo hacen más \"seguro\" y repetitivo.",
                    note: "¡Prueba temperatura 2.0 para ver galimatías, o 0.1 para verlo atascarse en bucles!",
                },
                form: {
                    startChar: "Carácter Inicial",
                    numTokens: "Número de Tokens",
                    temp: "Temperatura",
                    generate: "Generar",
                    generating: "Generando...",
                },
                copyToClipboard: "Copiar texto generado",
            },
            architecture: {
                title: "Especificación Técnica",
                subtitle: "Desglose detallado del mecanismo interno del modelo, capacidades y restricciones.",
                mechanism: "Mecanismo de Inferencia",
                capabilities: "Capacidades",
                constraints: "Restricciones",
                modelCard: {
                    title: "Tarjeta del Modelo",
                    type: "Tipo de Arquitectura",
                    complexity: "Clasificación de Complejidad",
                    useCases: "Casos de Uso Principales",
                    description: "Descripción",
                },
                tooltips: {
                    matrixW: {
                        title: "¿Qué es la Matriz W?",
                        desc: "Es esencialmente una tabla de búsqueda de 9216 números (96x96 caracteres en el vocabulario). Cada número representa la \"puntuación no normalizada\" de cuán probable es que un carácter siga a otro.",
                    },
                    softmax: {
                        title: "¿Qué es Softmax?",
                        desc: "Softmax toma puntuaciones brutas (logits) y las aplasta en una distribución de probabilidad. Todos los números se vuelven positivos y suman 1 (100%).",
                    },
                    loss: {
                        title: "¿Qué es la Pérdida (Entropía Cruzada)?",
                        desc: "La pérdida mide la distancia entre la predicción del modelo y la verdad. Si la verdad es 'n' y el modelo dio a 'n' un 0.1% de probabilidad, la pérdida será muy alta. El entrenamiento es el proceso de ajustar los pesos para minimizar esta distancia.",
                    },
                },
                stepsList: {
                    matrixW: "Busca la fila de la matriz de pesos W correspondiente al índice del carácter actual. Esta fila contiene las puntuaciones brutas no normalizadas (logits) para cada posible carácter siguiente.",
                    softmax: "Aplica softmax a la fila de logits para producir una distribución de probabilidad válida sobre el vocabulario. Cada valor se vuelve positivo y la fila suma exactamente 1.0.",
                    loss: "Durante el entrenamiento, calcula la pérdida de entropía cruzada entre la distribución predicha y el verdadero siguiente carácter. Retropropaga gradientes para actualizar W y minimizar el error de predicción futuro.",
                },
                analysis: {
                    strengths: [
                        "Solución exacta en forma cerrada — no se requiere descenso de gradiente. Los conteos son estadísticas suficientes.",
                        "Entrenamiento instantáneo en cualquier tamaño de corpus. O(N) en el número de tokens de entrenamiento.",
                        "Totalmente interpretable: cada celda en W es una probabilidad directamente legible.",
                    ],
                    limitations: [
                        "Cero contexto más allá del token inmediatamente anterior — no puede modelar patrones multi-carácter.",
                        "Sin generalización: cada par de caracteres se trata independientemente sin noción de similitud.",
                        "El vocabulario escala como O(V²) — impracticable para modelos a nivel de palabra con vocabularios grandes.",
                    ],
                },
                steps: {
                    predicts: "Predice el siguiente carácter vía:",
                    optimizes: "Optimiza parámetros usando:",
                },
            },
            guide: {
                badge: "Guía para Exploradores No Técnicos",
                title: "¿Cómo funciona este \"Cerebro\"?",
                subtitle: "Explicando el modelo Bigrama para que hasta mi madre lo entienda (con mucho amor).",
                switchHint: "Cambia al Modo Educativo para ver la guía conceptual",
                cards: {
                    memory: {
                        title: "Memoria de Pez",
                        desc: "Un modelo **Bigrama** tiene la memoria más corta del mundo: solo recuerda la **última letra** que escribió. Para decidir qué letra viene después, solo puede mirar la anterior. No tiene contexto de palabras o frases enteras.",
                    },
                    darts: {
                        title: "Lanzamiento de Dardos",
                        desc: "El modelo no \"lee\". Solo tiene una tabla gigante que dice: \"Si la última letra fue 'a', hay un 10% de probabilidad de que la siguiente sea 'n'\". Lanzar el dardo (muestreo) es lo que genera texto de manera aleatoria pero coherente.",
                    },
                    heatmap: {
                        title: "El Mapa de Calor",
                        desc: "La cuadrícula coloreada (Matriz) es el **corazón** del modelo. Los cuadrados brillantes son las \"rutas\" más frecuentes que el modelo encontró en los libros que leyó durante su entrenamiento.",
                    },
                },
            },
            historicalContext: {
                description: "El modelo bigrama es la instancia más simple de una cadena de Markov aplicada al lenguaje. Estudiado por primera vez por Claude Shannon en su artículo de 1948 'A Mathematical Theory of Communication', los bigramas a nivel de carácter demostraron que incluso modelos estadísticos sin contexto capturan estructura significativa en el lenguaje natural.",
                limitations: [
                    "Cero memoria más allá del predecesor inmediato — no puede aprender patrones multi-carácter como 'th' → 'e'.",
                    "Sin generalización — cada par de caracteres se trata independientemente sin noción de similitud.",
                ],
                evolution: "Las limitaciones de los modelos bigrama motivaron directamente las extensiones N-gram (contexto más largo) y eventualmente los enfoques neuronales (representaciones aprendidas). Todo modelo de lenguaje moderno puede rastrear su linaje hasta esta simple matriz de transición.",
            },
            educationalOverlay: {
                visualGuideTitle: "Guía de Visualización",
                visualGuideDescription: "Cada celda de esta matriz representa P(siguiente | actual), la probabilidad de que un carácter siga a otro. Las celdas más brillantes indican parejas de caracteres más frecuentes en el corpus de entrenamiento.",
                probabilityAnalysisTitle: "Análisis de Probabilidad",
                probabilityAnalysisDescription: "Escribe cualquier texto para ver qué caracteres predice el modelo como siguientes, ordenados por probabilidad aprendida. El modelo solo mira el último carácter: no tiene memoria del contexto anterior.",
                generationLabTitle: "Laboratorio de Generación",
                generationLabDescription: "La generación de texto funciona muestreando repetidamente la distribución de probabilidades. La temperatura controla cuán aleatoria es cada muestra: valores bajos producen resultados más predecibles; valores altos, secuencias más creativas (o sin sentido).",
            },
        },
        ngram: {
            title: "Modelo de Lenguaje N-Grama",
            description: "Un modelo de lenguaje estadístico a nivel de carácter con tamaño de contexto variable. Visualiza cómo aumentar la ventana de contexto agudiza las predicciones a costa de una escasez exponencial.",
            sections: {
                context: {
                    title: "Tamaño del Contexto",
                    description: "Ajusta el tamaño del contexto (N) para condicionar las predicciones en más historia.",
                },
                slice: {
                    title: "Slice Activo",
                    descriptionN1: "Para N=1 (Bigrama), visualizamos la matriz de transición de Markov simple P(siguiente | actual).",
                    descriptionNPlus: "Para N>1, visualizamos el slice condicional P(siguiente | contexto). Haz clic en las celdas para rastrear ejemplos.",
                },
                inference: {
                    title: "Inferencia y Generación",
                    description: "Interactúa con el modelo en tiempo real. Observa cómo selecciona el siguiente token basándose en las probabilidades aprendidas.",
                    placeholder: "Escribe texto para analizar...",
                    distribution: {
                        title: "Distribución de Probabilidad",
                        desc: "Escribe una frase para ver los top-k caracteres siguientes más probables.",
                    },
                    stepwise: {
                        title: "Predicción Paso a Paso",
                        desc: "Observa al modelo predecir una secuencia carácter por carácter.",
                    },
                    generation: {
                        title: "Generación de Texto",
                        desc: "Deja que el modelo alucine texto muestreando de la distribución.",
                    },
                },
            },
            hero: {
                stats: {
                    uniqueContexts: { label: "Contextos Únicos", desc: "N-gramas observados" },
                    vocab: { label: "Vocabulario", desc: "Caracteres únicos" },
                    contextSpace: { label: "Espacio de Contexto", desc: "|V|^{n}" },
                    tokens: { label: "Tokens de Entrenamiento", desc: "Total tokens vistos" },
                },
            },
            viz: {
                hint: {
                    label: "Pruébalo:",
                    text: "Haz clic en cualquier celda coloreada de la matriz para ver <strong class='text-white font-semibold'>ejemplos reales de entrenamiento</strong>.",
                },
            },
            controls: {
                contextSize: "Tamaño de Contexto (N)",
                contextDesc: "Número de caracteres previos para condicionar",
                unigram: "Unigrama",
                bigram: "Bigrama",
                trigram: "Trigrama",
                fourgram: "4-grama",
                fivegram: "5-grama",
                explosion: "Explosión (5+)",
            },
            lab: {
                technicalExplanation: {
                    title: "Explicación técnica",
                    description: "Desglose detallado del mecanismo interno del modelo, capacidades y restricciones.",
                    mechanism: "Mecanismo de inferencia",
                    capabilitiesTitle: "Capacidades",
                    constraintsTitle: "Restricciones",
                    steps: {
                        lookup: "Busca la fila de probabilidades correspondiente al último contexto de {n} caracteres.",
                        normalize: "Aplica suavizado (add-α, α={alpha}) y normaliza para obtener una distribución de probabilidad.",
                        predict: "Muestrea o toma argmax para predecir el siguiente carácter.",
                    },
                    capabilities: [
                        "Entrenamiento exacto en forma cerrada — el conteo es suficiente.",
                        "Predicciones locales más precisas a medida que aumenta el contexto.",
                        "Totalmente interpretable: cada entrada es una estadística legible.",
                    ],
                    constraints: [
                        "Sin generalización: los contextos no vistos no tienen entrada.",
                        "Espacio de estados exponencial: |V|^N crece demasiado rápido para llenarse.",
                        "Horizonte limitado: olvida todo antes de los últimos N caracteres.",
                    ],
                    modelCardTitle: "Tarjeta del modelo",
                    complexity: "Clasificación de complejidad",
                    complexityValue: "Baja",
                    useCases: "Casos de uso principales",
                    useCasesList: [
                        "Exploración educativa",
                        "Baseline para comparación",
                        "Generación local rápida",
                    ],
                    trainingStats: "Estadísticas de entrenamiento",
                    modelCard: "FICHA DEL MODELO · N={n}",
                    modelType: "Tipo de modelo",
                    modelTypeValue: "{nPlusOne}-grama (longitud de contexto = {n})",
                    parameterCount: "Número de parámetros",
                    parameterCountValue: "|V|^{n} × |V| = {count}",
                    trainingMethod: "Método de entrenamiento",
                    trainingMethodValue: "Máxima verosimilitud (conteo)",
                    smoothing: "Suavizado",
                    smoothingValue: "Suavizado Laplace add-α (α={alpha})",
                    corpusInfo: "Corpus",
                    trainingTokens: "Tokens de entrenamiento",
                    trainingTokensValue: "{count}",
                    uniqueContexts: "Contextos únicos",
                    uniqueContextsValue: "{seen} / {possible}",
                    perplexity: "Perplejidad",
                    finalLoss: "Pérdida final",
                    inferenceComplexity: "Complejidad de inferencia",
                    inferenceComplexityValue: "O(|V|) por paso (lookup de tabla)",
                    mathematicalFormulation: "Formulación matemática",
                    formulaDesc: "Los conteos se normalizan para formar probabilidades condicionales por contexto.",
                },
                guidedExperiments: "Experimentos Guiados",
                guidedExperimentsChallenges: "5 desafíos",
                advancedMetrics: "Métricas Avanzadas",
                advancedMetricsExperts: "para expertos",
                advancedMetricsDesc: "Pérdida, perplejidad y rendimiento",
                advancedMetricsHint: "Estas métricas (pérdida, perplejidad, NLL) tendrán más sentido después del capítulo de Redes Neuronales. Por ahora, menor perplejidad = mejores predicciones.",
                badge: "Modo Lab Libre · Acceso completo a instrumentos",
                experiments: {
                    instructions: "Instrucciones",
                    expectedObservation: "Observación esperada",
                    goToPanel: "Ir al panel",
                    1: {
                        title: "El Efecto del Contexto",
                        instruction: "Establece N=1, genera 50 caracteres y guarda el resultado. Luego establece N=3 y genera de nuevo con la misma frase semilla.",
                        observation: "El resultado con N=3 se lee más naturalmente — verás prefijos comunes como 'th', 'the', 'in' aparecer más consistentemente que con N=1.",
                    },
                    2: {
                        title: "Encontrando el Muro",
                        instruction: "Avanza por N=1 → N=2 → N=3 → N=4 y observa el panel de Dispersión después de cada cambio. Registra la perplejidad y la utilización del contexto en cada N.",
                        observation: "La perplejidad baja con cada paso, pero la utilización del contexto también se desploma. En N=4, la mayoría de las filas de la tabla están vacías — el modelo se queda sin evidencia.",
                    },
                    3: {
                        title: "El Contexto Imposible",
                        instruction: "Establece N=4. En la Consola de Inferencia, escribe una frase que el modelo nunca haya visto — prueba 'zqxj' o cualquier combinación inusual de 4 caracteres.",
                        observation: "El modelo no devuelve ninguna predicción con confianza. No tiene entrada para este contexto exacto de 4 caracteres y no puede razonar por analogía.",
                    },
                    4: {
                        title: "Bigrama vs 4-grama: El Duelo",
                        instruction: "Genera 80 caracteres con N=1 y guárdalos. Luego cambia a N=4 y genera 80 caracteres con la misma semilla. Lee ambos resultados en voz alta.",
                        observation: "N=1 suena aleatorio. N=4 produce fragmentos reconocibles pero se rompe a mitad de secuencia cuando encuentra contextos no vistos y tiene que adivinar al azar.",
                    },
                    5: {
                        title: "Rendimientos Decrecientes",
                        instruction: "Registra la perplejidad del Resumen de Rendimiento en N=1, 2, 3 y 4. Calcula la caída de cada paso al siguiente.",
                        observation: "La mejora de N=1→2 es grande. N=2→3 es menor. N=3→4 es aún menor. Más memoria ayuda cada vez menos a medida que crece la dispersión.",
                    },
                },
                contextLevels: {
                    1: "Sin contexto — cada carácter se predice de forma independiente según la frecuencia del corpus. El más rápido pero el menos preciso.",
                    2: "Condiciona en 1 carácter previo. Cadena de Markov simple; baja dispersión, precisión moderada.",
                    3: "Condiciona en 2 caracteres previos. Mejores predicciones pero el espacio de contexto crece a |V|².",
                    4: "Condiciona en 3 caracteres. Alta precisión en secuencias vistas; dispersión significativa en las no vistas.",
                    5: "Contexto máximo. Predicciones muy precisas donde hay datos, pero la mayoría de contextos no se han visto — explosión combinatoria inminente.",
                },
                flow: {
                    afterContext: "La matriz a continuación muestra la distribución de probabilidad aprendida de los datos de entrenamiento para el nivel N actual.",
                    afterMatrix: "Usa la consola de inferencia para consultar el modelo con tu propio texto y observar cómo el tamaño de contexto afecta las predicciones.",
                    afterComparison: "El gráfico de calidad de entrenamiento a continuación refleja qué tan bien el modelo se ajusta al corpus en el nivel N seleccionado.",
                },
                performanceSummary: {
                    title: "Resumen de Rendimiento",
                    description: "Métricas de ejecución y entrenamiento del modelo actual",
                    inferenceTime: "Tiempo de Inferencia",
                    device: "Dispositivo",
                    corpusSize: "Tamaño del Corpus",
                    trainingDuration: "Duración del Entrenamiento",
                    totalTokens: "Total de Tokens",
                    perplexity: "Perplejidad",
                    finalLoss: "NLL Final",
                    ms: "ms",
                    tokens: "tokens",
                },
                comparison: {
                    title: "Comparación de Modelos",
                    description: "Métricas para N=1..5",
                    ppl: "PPL",
                    util: "Util",
                    space: "Espacio",
                    tooltipPpl: "Perplejidad — menor significa predicciones más seguras",
                    tooltipUtil: "Fracción de contextos posibles vistos durante el entrenamiento",
                    tooltipSpace: "Total de combinaciones de contexto posibles (|V|^N)",
                },
                sparsity: {
                    title: "Dispersión de Datos",
                    description: "Cuánto del espacio de contexto se observa realmente",
                    observedContexts: "Contextos Observados",
                    possibleSuffix: "posibles",
                    avgTransitions: "Trans. Promedio / Contexto",
                    nextTokens: "siguientes-tokens por contexto observado",
                    utilLabel: "Utilización de contexto",
                    utilHint: "Fracción de contextos posibles vistos en datos de entrenamiento",
                    sparsityLabel: "Dispersión de tabla",
                    sparsityHint: "Fracción de pares (contexto, siguiente-token) nunca observados",
                },
                warning5: {
                    title: "Umbral combinatorio superado",
                    hint: "Reduce N a 1–4 para inferencia en vivo, predicción paso a paso y generación. Un N menor también reduce la dispersión.",
                },
                sections: {
                    transitions: "Probabilidades de Transición",
                    transitionsDescN1: "Matriz completa P(siguiente | actual)",
                    transitionsDescNPlus: "Slice P(siguiente | contexto)",
                    conditionedOn: "Condicionado en:",
                    sparsity: "Dispersión de Datos",
                    trainingQuality: "Calidad de Entrenamiento",
                    trainingQualityDesc: "Curva de pérdida para el modelo N={n} durante el entrenamiento",
                    nextToken: "Predicción del Siguiente Token",
                    nextTokenDesc: "Escribe texto y observa la distribución de probabilidad sobre los siguientes caracteres",
                    stepwise: "Predicción Paso a Paso",
                    stepwiseDesc: "Rastrea la ventana de contexto deslizándose carácter a carácter",
                    generation: "Generación de Texto",
                    generationDesc: "Genera texto de forma autorregresiva usando el modelo N-grama actual",
                },
                hero: {
                    title: "Modelo de Lenguaje N-Grama",
                    description: "Un modelo de lenguaje estadístico a nivel de carácter con tamaño de contexto variable. Visualiza cómo aumentar la ventana de contexto agudiza las predicciones a costa de una escasez exponencial.",
                    uniqueContexts: "Contextos Únicos",
                    vocabulary: "Vocabulario",
                    contextSpace: "Espacio de Contexto",
                    trainingTokens: "Tokens de Entrenamiento",
                    uniqueChars: "Caracteres únicos",
                    totalTokensSeen: "Total de tokens vistos",
                },
                lossChart: {
                    title: "Pérdida de entrenamiento (NLL)",
                    final: "Final:",
                    ppl: "PPL:",
                    start: "Inicio",
                    progress: "Progreso de entrenamiento",
                    end: "Fin",
                    perplexity: "Perplejidad",
                    perplexityHint: "Menor = predicciones más seguras",
                    finalNll: "NLL Final",
                    finalNllHint: "Log-verosimilitud negativa en datos de entrenamiento",
                },
                footer: "LM-Lab · Instrumento Científico v1.0",
            },
            training: {
                title: "Insights de Entrenamiento",
                stats: {
                    totalTokens: "Total Tokens",
                    uniqueContexts: "Contextos Únicos",
                    utilization: "Utilización",
                    sparsity: "Espasidad",
                    transitionDensity: "Densidad de Matriz",
                    subs: {
                        possiblePrefix: "de",
                        possibleSuffix: "posibles",
                        fractionObserved: "fracción de contextos posibles observados",
                        unseen: "de contextos nunca vistos",
                    },
                },
            },
            historical: {
                title: "Significado Histórico y Contexto",
                learnMore: "Aprender Más",
                description: "Descripción",
                limitations: "Limitaciones Clave",
                evolution: "Evolución a la IA Moderna",
            },
            explosion: {
                title: "Contexto Demasiado Grande — Explosión Combinatoria",
                description: "A medida que aumenta N, el número de contextos posibles crece exponencialmente (|V|^N). Para este tamaño de vocabulario, calcular la matriz de transición completa se vuelve computacionalmente impracticable y requiere un conjunto de datos enorme para evitar la escasez.",
                complexity: "|V|^N = Complejidad Espacial",
                limit: "Límite Clásico Alcanzado",
            },
            diagnostics: {
                vocabSize: "Vocabulario",
                contextSize: "Tamaño de Contexto (N)",
                contextSpace: "Espacio de Contexto (|V|^N)",
                sparsity: "Espasidad",
                sub: {
                    observed: "{count} observados",
                    possible: "Contextos Posibles",
                    utilized: "{percent}% utilizado",
                },
            },
            educationalOverlay: {
                contextControlTitle: "Control del Tamaño de Contexto",
                contextControlDescription: "Aumentar N permite al modelo condicionar con más historia, pero el número de contextos posibles crece como |V|^N. Esa explosión exponencial es la tensión central de los modelos n-grama: más contexto da predicciones más finas, pero también más dispersión de datos.",
                sliceVisualizationTitle: "Vista por Slice de Matriz",
                sliceVisualizationDescription: "Para N > 1, el tensor de transición completo es demasiado grande para mostrarse. En su lugar, fijamos el contexto actual y mostramos la fila de probabilidad resultante: un slice de la tabla de alta dimensión.",
                probabilityDistributionTitle: "Distribución de Probabilidad",
                probabilityDistributionDescription: "El modelo toma los últimos N caracteres de tu entrada, encuentra el contexto correspondiente en su tabla y devuelve la distribución de probabilidad sobre los posibles siguientes caracteres.",
                generationPredictionTitle: "Generación y Predicción",
                generationPredictionDescription: "En modo educativo nos centramos en entender cómo se elige un único token siguiente. Cambia a Lab Libre para desbloquear el trazador paso a paso completo y el playground de generación.",
                simplifiedSimulation: "La predicción paso a paso y la generación completa están disponibles en modo Lab Libre.",
            },
        },
        mlp: {
            title: "MLP + Embeddings",
            description: "Explora 108 configuraciones MLP entrenadas. Observa cómo los embeddings emergen del ruido, compara dinámicas de entrenamiento entre arquitecturas y genera texto desde representaciones aprendidas a nivel de carácter.",
            hero: {
                badge: "Laboratorio de Investigación",
            },
            freeLab: {
                title: "Laboratorio de Configuración MLP",
                description: "Selecciona cualquier configuración del Model Zoo, inspecciona curvas de entrenamiento, explora el espacio de embeddings y compara modelos lado a lado.",
            },
            page: {
                switchToEducational: "Cambia al Modo Educativo para la narrativa guiada completa",
            },
            narrative: {
                hero: {
                    eyebrow: "Capítulo 4 · Modelado Neural del Lenguaje",
                    titlePrefix: "Más Allá de las Tablas:",
                    titleHighlight: "MLP + Embeddings",
                    description: "Ya construiste perceptrones, aprendiste retropropagación y viste por qué la profundidad importa. Ahora la pregunta cambia: ¿cómo aplicamos esa maquinaria de redes neuronales al lenguaje real?",
                },
                sections: {
                    s00: { number: "00", label: "Bloques de Construcción" },
                    s01: { number: "01", label: "Entrada de Lenguaje" },
                    s02: { number: "02", label: "Muro de Escalabilidad" },
                    s03: { number: "03", label: "El Gran Avance" },
                    s04: { number: "04", label: "Exploración Empírica" },
                    s05: { number: "05", label: "Límites Estructurales" },
                    s06: { number: "06", label: "Estabilidad del Entrenamiento" },
                    s07: { number: "07", label: "El Camino Adelante" },
                    s08: { number: "08", label: "El Camino Adelante" },
                },
                s00: {
                    heading: "De los Bloques de Construcción al Lenguaje",
                    lead: "Ya hiciste la parte difícil. El capítulo de Redes Neuronales te dio perceptrones, retropropagación y por qué la profundidad desbloquea fronteras de decisión complejas. Este capítulo hace una nueva pregunta: ¿cómo alimentamos lenguaje real a esa red?",
                    p1: "Un MLP fluye entradas a través de capas ocultas, cada una aplicando una transformación no lineal, y luego produce una distribución de probabilidad mediante una salida softmax. La arquitectura que aprendiste se mantiene — solo cambia el dominio de entrada.",
                    figLabel1: "Arquitectura MLP · Esquema",
                    figHint1: "Una red feedforward: los tokens de entrada fluyen a través de capas ocultas hasta una distribución de salida softmax.",
                    p2: "En la lección XOR, la profundidad permitió fronteras de decisión curvas que una red plana nunca podría trazar. Para el lenguaje, el mismo principio escala: las capas apiladas componen patrones de caracteres simples en estructura de orden superior — subpalabras, palabras, significados.",
                    formulaCaption: "La misma fórmula MLP del capítulo de Redes Neuronales. La novedad aquí está en qué va en x — el desafío de este capítulo.",
                    calloutTitle: "La pregunta abierta",
                    calloutText: "La red está lista. El desafío es la representación: ¿cómo convertimos un símbolo discreto — el carácter 'a', la palabra 'gato' — en un vector numérico que la red pueda procesar? Esa pregunta define el resto de este capítulo.",
                    figLabel2: "Interactivo · No Linealidad y Fronteras de Decisión",
                    figHint2: "Viste XOR en el capítulo de Redes Neuronales. Alterna entre modelos aquí para ver cómo la profundidad maneja patrones progresivamente más complejos.",
                },
                s01: {
                    heading: "Alimentando Lenguaje a una Red Neuronal",
                    lead: "El enfoque más simple: toma los N tokens anteriores, convierte cada uno en un vector numérico, concaténalos y alimenta el resultado al MLP para predecir el siguiente token.",
                    p1: "Para alimentar caracteres a una red neuronal, primero necesitamos convertirlos en números. El método más directo es un",
                    p1H1: "vector one-hot",
                    p1Mid: ": una lista de ceros de la longitud del vocabulario, con un solo 1 en la posición de ese carácter. Con una ventana de contexto de tamaño N, concatenamos N de estos vectores para formar una entrada de dimensión",
                    p1H2: "N × V",
                    p1End: ", luego la pasamos por capas ocultas para producir una distribución de probabilidad sobre el siguiente token.",
                    formulaCaption: "La entrada al MLP es una concatenación de N vectores one-hot, uno por token de contexto.",
                    calloutTitle: "¿Qué significa la pérdida aquí?",
                    calloutP1: "La pérdida mide la sorpresa. Después de cada predicción, el modelo compara su probabilidad para cada posible siguiente carácter con lo que realmente vino después. Alta confianza en la respuesta correcta significa pérdida baja; confianza cercana a cero significa pérdida alta.",
                    calloutP2: "El entrenamiento minimiza esta sorpresa promedio a lo largo de millones de caracteres. Conoces este mecanismo del capítulo de Redes Neuronales — aquí opera sobre tokens de lenguaje.",
                    figLabel1: "Interactivo · Intuición de la Pérdida",
                    figHint1: "Arrastra el deslizador para establecer cuán seguro está el modelo en el token correcto. Observa cómo la pérdida de entropía cruzada explota cuando la confianza se acerca a cero.",
                    p2: "Esto marca un avance respecto a las tablas N-grama. En lugar de memorizar conteos exactos de co-ocurrencia, el modelo",
                    p2H1: "aprende una función",
                    p2End: "que mapea patrones de contexto a predicciones — una que puede generalizar a combinaciones nuevas.",
                    p3: "El MLP puede descubrir que ciertas secuencias de caracteres se comportan de manera similar, incluso si nunca vio el N-grama exacto antes. Las capas ocultas aprenden características internas que comprimen y abstraen los patrones de entrada brutos.",
                    calloutTitle2: "Mejora clave sobre los N-gramas",
                    calloutText2: "Los modelos N-grama asignan probabilidad cero a cualquier contexto nunca observado en el entrenamiento. Un MLP asigna probabilidad no nula a contextos no vistos porque aprende una función suave — no una tabla de búsqueda.",
                    figLabel2: "Interactivo · Paso Hacia Adelante del MLP",
                    figHint2: "Escribe un texto semilla corto y avanza por cada etapa del paso hacia adelante — desde tokens brutos hasta la distribución de probabilidad final.",
                },
                s02: {
                    heading: "El Problema con las Entradas One-Hot",
                    lead: "La codificación one-hot parece natural, pero crea graves problemas de escalabilidad que se vuelven catastróficos a medida que crecen los vocabularios.",
                    p1H1: "Explosión de dimensionalidad de entrada.",
                    p1: "Con un vocabulario a nivel de carácter de ~96 tokens y un contexto de 8 caracteres, el vector de entrada tiene 768 dimensiones — manejable. Pero con un vocabulario a nivel de palabra de 50.000 tokens y un contexto de 5 palabras, la entrada salta a 250.000 dimensiones. Solo la primera matriz de pesos tendría decenas de miles de millones de parámetros.",
                    p2H1: "Matrices de pesos de primera capa masivas.",
                    p2: "La matriz W₁ que conecta la entrada con la primera capa oculta tiene forma (N·V) × H, donde H es el tamaño oculto. Para vocabularios grandes, esta sola matriz domina todo el presupuesto de parámetros, haciendo el entrenamiento lento y prohibitivo en memoria.",
                    p3H1: "Sin noción de similitud.",
                    p3: "En el espacio one-hot, cada token está equidistante de todos los demás. Los vectores de \"cat\" y \"kitten\" están tan alejados como los de \"cat\" y \"quantum\". El modelo debe aprender cada relación desde cero, sin ningún prior estructural.",
                    formulaCaption: "Todos los vectores one-hot son equidistantes — el modelo no obtiene información sobre similitud semántica de la propia codificación.",
                    calloutTitle: "El muro de escalabilidad",
                    calloutText: "Estos tres problemas — explosión dimensional, matrices de pesos enormes y representaciones ortogonales — forman juntos un muro de escalabilidad. El MLP one-hot ingenuo simplemente no puede escalar a vocabularios del mundo real. Necesitamos una forma fundamentalmente mejor de representar tokens.",
                    figLabel1: "Interactivo · Tabla N-grama vs Parámetros MLP",
                    figHint1: "Arrastra el deslizador para aumentar el tamaño de contexto N. Observa cómo la tabla n-grama explota mientras los parámetros del MLP crecen modestamente — y nota cuántas celdas n-grama permanecen vacías.",
                },
                s03: {
                    heading: "El Cambio de Juego: Embeddings de Palabras",
                    lead: "En lugar de representar cada token como un vector one-hot disperso, aprendemos un vector denso y de baja dimensión para cada token del vocabulario. Estos se llaman embeddings.",
                    p1: "Un embedding es una tabla de búsqueda — una matriz E de forma V × D. Para obtener la representación del token t, seleccionamos la fila t-ésima de E. Es equivalente a multiplicar E por el vector one-hot, pero mucho más eficiente.",
                    formulaCaption: "Una búsqueda de embedding: seleccionar la fila t de la matriz E da un vector denso de D dimensiones.",
                    p2: "La idea clave es que",
                    p2H1: "cada dimensión del embedding captura una propiedad semántica latente",
                    p2End: ". Estas dimensiones no están diseñadas a mano — emergen automáticamente del entrenamiento. Una dimensión podría codificar \"animado vs. inanimado\", otra podría capturar \"tiempo verbal\".",
                    p3: "Dado que los embeddings son densos y continuos, los tokens similares se agrupan naturalmente en el espacio de embeddings. El modelo puede aprovechar esta estructura para",
                    p3H1: "generalizar entre tokens semánticamente relacionados",
                    p3End: ". Si el modelo ha aprendido algo sobre \"cat\", puede transferir parcialmente ese conocimiento a \"kitten\" porque sus vectores están cerca.",
                    p4: "Esto reduce drásticamente la dimensionalidad efectiva de entrada. En lugar de N × V (potencialmente cientos de miles), el MLP ahora recibe N × D (quizás unos pocos cientos) — órdenes de magnitud más pequeño, con información más rica.",
                    pullQuote: "Los embeddings transforman los tokens de símbolos aislados en puntos de un espacio semántico continuo, donde la proximidad codifica el significado. Esta sola idea desbloqué una nueva era en el modelado del lenguaje.",
                    figLabel1: "Ilustrativo · Espacio de Embeddings (Simplificado)",
                    figHint1: "Esta es una ilustración pedagógica. Haz clic en los tokens para explorar cómo los caracteres similares se agrupan.",
                },
                s04: {
                    heading: "Explorando Configuraciones MLP + Embeddings",
                    lead: "Con los embeddings en su lugar, el modelo de lenguaje MLP tiene varios hiperparámetros clave que controlan su capacidad, eficiencia y comportamiento.",
                    p1: "Las elecciones arquitectónicas principales incluyen la",
                    p1H1: "dimensión del embedding",
                    p1Mid1: "(cuántas características latentes por token), el",
                    p1H2: "tamaño de la capa oculta",
                    p1Mid2: "(cuántas neuronas en cada capa oculta), el",
                    p1H3: "número de capas ocultas",
                    p1End: "(profundidad de la red), y el tamaño de la ventana de contexto.",
                    p2: "Para entender cómo estas elecciones afectan el comportamiento del modelo, entrenamos muchos modelos MLP con diferentes configuraciones en el mismo conjunto de datos. Este barrido revela compromisos clave: embeddings más grandes capturan semántica más rica pero arriesgan sobreajuste, capas más anchas aumentan la capacidad pero ralentizan el entrenamiento.",
                    hyperparamCards: {
                        embDim: { title: "Dimensión del Embedding", desc: "Controla la riqueza de las representaciones de tokens. Valores más grandes capturan más matices semánticos pero requieren más datos." },
                        hiddenSize: { title: "Tamaño de la Capa Oculta", desc: "Determina el ancho computacional del modelo. Capas más anchas pueden detectar más patrones por capa, pero aumentan la memoria y el cómputo." },
                        numLayers: { title: "Número de Capas", desc: "Controla la profundidad representacional. Los modelos más profundos pueden componer características jerárquicamente, pero enfrentan desafíos de estabilidad." },
                        contextWindow: { title: "Ventana de Contexto", desc: "Cuántos tokens anteriores considera el modelo. Ventanas más grandes dan más información pero aumentan la dimensionalidad de entrada linealmente." },
                    },
                    figLabel1: "Interactivo · Temperatura Softmax",
                    figHint1: "Ajusta la temperatura para ver cómo agudiza o aplana la distribución de probabilidad sobre los siguientes tokens.",
                    calloutTitle: "Por qué importa la exploración sistemática",
                    calloutText: "No existe una configuración óptima única. La única forma de desarrollar intuición es explorar el espacio empíricamente y observar cómo cada elección afecta la pérdida, la perplejidad y la calidad de generación.",
                    figLabel2: "Interactivo · Explorador de Hiperparámetros",
                    figHint2: "Ajusta los deslizadores para explorar cómo la dimensión del embedding, el tamaño oculto y la tasa de aprendizaje afectan la pérdida de validación, la dinámica de entrenamiento y los embeddings aprendidos.",
                    p3: "El explorador interactivo te permite comparar modelos en estas dimensiones, visualizando pérdida de validación, perplejidad, estabilidad de entrenamiento, calidad de generación y el espacio de embeddings aprendido.",
                },
                s05: {
                    heading: "Nuevas Limitaciones de MLP + Embeddings",
                    lead: "Los embeddings resuelven el problema de representación, pero la arquitectura MLP en sí introduce limitaciones estructurales que ninguna cantidad de ajuste puede superar.",
                    p1H1: "Ventana de contexto de tamaño fijo.",
                    p1: "Un MLP debe recibir un número fijo de tokens de entrada. No puede atender dinámicamente a contextos más largos o más cortos — cada predicción usa exactamente N tokens anteriores, ni más ni menos. La información fuera de esta ventana es completamente invisible para el modelo.",
                    p2: "La consecuencia es grave para el lenguaje: los pronombres, las referencias y la continuidad temática dependen de contexto que puede estar muchos tokens atrás.",
                    figLabel1: "Interactivo · Ceguera de la Ventana de Contexto",
                    figHint1: "Arrastra el deslizador para ampliar la ventana de contexto. Observa cuándo 'Mary' (el referente) entra en el campo de visión — y nota cuán pequeña debe ser la ventana para ocultarla por completo.",
                    p3H1: "Las dependencias de largo alcance están fuera del alcance.",
                    p3: "El problema se agrava en textos más largos. En el lenguaje real, un pronombre puede referirse a un sustantivo introducido decenas de tokens antes. Ninguna ventana fija de tamaño práctico puede cerrar estos huecos de manera confiable.",
                    figLabel2: "Demo · Fallo en Dependencias de Largo Alcance",
                    figHint2: "Una oración de 19 palabras donde el pronombre 'she' se refiere a 'scientist' 15 tokens atrás. Compara cómo cambia la predicción del MLP a medida que crece la ventana.",
                    p4H1: "Significado del token dependiente de la posición.",
                    p4: "Dado que el MLP concatena embeddings de extremo a extremo, el mismo token en la posición 1 y en la posición 3 ocupa diferentes porciones del vector de entrada y activa diferentes columnas de W₁. El modelo aprende pesos completamente separados para cada posición.",
                    figLabel3: "Interactivo · Sensibilidad a la Posición",
                    figHint3: "Alterna 'the' entre la posición 1 y la posición 3. Las columnas resaltadas en W₁ muestran qué parámetros activa cada instancia — conjuntos completamente diferentes.",
                    p5H1: "Explosión de parámetros y dilución de señal.",
                    p5: "Incluso con embeddings, la primera matriz de pesos W₁ tiene forma (N · D) × H. Duplicar la ventana de contexto duplica el tamaño de esta capa. Al mismo tiempo, a medida que N crece, el embedding de cada token se reduce a una fracción más pequeña de la entrada total — diluyendo cada señal.",
                    figLabel4: "Interactivo · Cuello de Botella por Concatenación",
                    figHint4: "Cambia entre las vistas de Crecimiento de Parámetros y Dilución de Señal. Arrastra el deslizador de tamaño de contexto y observa cómo W₁ se expande — y la participación de cada token en la entrada se reduce.",
                    calloutTitle: "La misma causa raíz",
                    calloutText: "Las cuatro limitaciones comparten un origen común: el MLP trata todo su contexto como un solo vector plano. No tiene mecanismo para razonar sobre la estructura, el orden o la importancia relativa de tokens individuales. Superar esto requiere arquitecturas que procesen secuencias paso a paso, llevando adelante una memoria de lo que vino antes.",
                },
                s06: {
                    heading: "Desafíos Profundos de Entrenamiento para MLPs Grandes",
                    lead: "Hacer que los MLPs profundos realmente entrenen bien fue uno de los problemas prácticos más difíciles en la historia de las redes neuronales. Sin técnicas cuidadosas, las redes profundas simplemente no aprenden.",
                    panels: {
                        initialization: {
                            title: "Inicialización de Pesos",
                            preview: "Muy grandes y las activaciones explotan; muy pequeños y los gradientes se desvanecen.",
                        },
                        gradients: {
                            title: "Gradientes que se Desvanecen y Explotan",
                            preview: "Los gradientes se multiplican a través de las capas — si cada factor es < 1 o > 1, se desvanecen o explotan.",
                        },
                        batchnorm: {
                            title: "Normalización por Lotes",
                            preview: "Normaliza las activaciones para mantener las distribuciones internas estables durante el entrenamiento.",
                        },
                    },
                    p1H1: "Inicialización de pesos.",
                    p1: "Si los pesos se inicializan demasiado grandes, las activaciones explotan a través de las capas. Demasiado pequeños, y los gradientes se desvanecen antes de llegar a las capas tempranas. Los esquemas de inicialización adecuados (como Xavier o Kaiming) establecen la escala inicial basándose en las dimensiones de la capa para mantener una propagación de señal estable.",
                    formulaCaption1: "Inicialización Kaiming: los pesos se extraen de una Gaussiana escalada por el fan-in, manteniendo la varianza estable a través de capas ReLU.",
                    figLabel1: "Interactivo · Sensibilidad a la Inicialización",
                    figHint1: "Compara curvas de pérdida bajo diferentes escalas de inicialización. La inicialización bien escalada es crítica para la convergencia.",
                    p2H1: "Gradientes que se desvanecen y explotan.",
                    p2: "Durante la retropropagación, los gradientes se multiplican a través de cada capa. En una red profunda, si estos multiplicadores son consistentemente menores que 1, los gradientes se reducen exponencialmente (desvanecimiento). Si son mayores que 1, crecen exponencialmente (explosión). De cualquier manera, la red no aprende efectivamente.",
                    formulaCaption2: "La regla de la cadena a través de L capas: los gradientes son productos de Jacobianos por capa. Si cada factor es ligeramente < 1 o > 1, el producto se desvanece o explota.",
                    figLabel2: "Interactivo · Flujo de Gradientes entre Capas",
                    figHint2: "Alterna entre regímenes de gradientes que se desvanecen, estables y que explotan para ver cómo cambia la magnitud del gradiente por capa.",
                    p3: "Durante muchos años, entrenar redes de más de 2–3 capas fue extremadamente poco fiable. La combinación de la elección de la función de activación (ReLU reemplazó a Sigmoid/Tanh para capas ocultas), la inicialización adecuada y las técnicas de normalización fue esencial para un entrenamiento estable.",
                    p4H1: "Normalización por Lotes",
                    p4: "fue un avance clave. Al normalizar las activaciones dentro de cada capa para tener media cero y varianza unitaria (en un mini-lote), mantiene las distribuciones internas estables mientras la red entrena. Esto reduce drásticamente la sensibilidad a la inicialización y la tasa de aprendizaje, permitiendo el entrenamiento fiable de redes mucho más profundas.",
                    formulaCaption3: "Normalización por Lotes: normaliza las activaciones h usando estadísticas del lote (μ_B, σ²_B), luego reescala con parámetros aprendidos γ y β.",
                    calloutTitle: "Por qué BatchNorm lo cambió todo",
                    calloutText: "Antes de BatchNorm, entrenar redes profundas requería un ajuste meticuloso de hiperparámetros. Después, los profesionales podían entrenar redes de 10, 20 o incluso más de 100 capas de manera fiable. Actúa como un estabilizador que suaviza el paisaje de pérdida, permitiendo que el descenso de gradiente converja más rápido y de manera más fiable.",
                    figLabel3: "Interactivo · Efecto de la Normalización por Lotes",
                    figHint3: "Activa y desactiva BatchNorm para ver cómo estabiliza las distribuciones de activación entre capas.",
                },
                s07: {
                    heading: "El Camino Adelante",
                    lead: "El MLP demostró que las redes neuronales pueden aprender lenguaje. Su ventana fija reveló algo igualmente importante: aprender lenguaje bien requiere entender secuencias — no solo instantáneas.",
                    p1: "Los límites estructurales que acabas de explorar comparten una sola raíz: el MLP ve su contexto como un vector plano. Sin procesamiento paso a paso. Sin memoria de lo que vino antes. Sin forma de rastrear cómo el significado se acumula a través de los tokens.",
                    p2: "Esa limitación lleva naturalmente a un nuevo conjunto de preguntas:",
                    rnnQ1: "Ventana fija — ¿y si la red procesara un token a la vez en lugar de todos a la vez?",
                    rnnQ2: "Sin memoria — ¿y si cada paso pasara un estado oculto hacia el siguiente?",
                    rnnQ3: "Predicciones independientes — ¿y si cada salida informara la siguiente entrada?",
                    pullQuote: "El MLP mira una ventana. Lo que necesitamos es un modelo que emprenda un viaje — un token a la vez, construyendo una memoria acumulada de todo lo que ha visto.",
                    p3: "Esa es la Red Neuronal Recurrente. En lugar de leer una instantánea de tamaño fijo, una RNN lee un token, actualiza un estado oculto, lee el siguiente, actualiza de nuevo — llevando el hilo de la secuencia hacia adelante en cada paso.",
                    p4: "A pesar de estos límites, el framework MLP + Embeddings estableció conceptos que todo modelo de lenguaje moderno aún usa: representaciones de tokens aprendidas, jerarquías de características no lineales y entrenamiento de extremo a extremo basado en gradientes. Las capas de embedding y los bloques feedforward dentro de los Transformers son descendientes directos de las ideas de este capítulo.",
                },
                s08: {
                    heading: "Limitaciones Finales y el Camino por Delante",
                    lead: "Incluso con embeddings, arquitecturas profundas y técnicas de entrenamiento modernas, el MLP opera fundamentalmente sobre ventanas de tamaño fijo — y este techo define su era en la historia del modelado del lenguaje.",
                    p1: "El MLP procesa cada ventana de contexto de forma independiente. No tiene memoria de lo que vino antes de la ventana, ningún mecanismo para atender dinámicamente a tokens distantes, y ninguna forma de manejar secuencias de longitud variable sin relleno o truncamiento.",
                    p2: "Esto significa que los MLPs no pueden modelar dependencias de largo alcance — el tipo de estructura que hace que el lenguaje natural sea coherente a través de oraciones y párrafos.",
                    p3: "Estas limitaciones estructurales motivaron una serie de innovaciones arquitectónicas que definen la trayectoria moderna del modelado del lenguaje:",
                    p3H1: "Redes Neuronales Recurrentes (RNNs)",
                    p3Mid1: "introdujeron la memoria secuencial, procesando un token a la vez mientras mantienen un estado oculto.",
                    p3H2: "Arquitecturas convolucionales (como WaveNet)",
                    p3Mid2: "aplicaron convoluciones dilatadas para capturar patrones jerárquicos sobre secuencias. Y finalmente,",
                    p3H3: "Transformers",
                    p3End: "introdujeron la auto-atención — un mecanismo que permite a cada token atender directamente a cada otro token, independientemente de la distancia.",
                    pullQuote: "El MLP fue la primera arquitectura en demostrar que las redes neuronales podían aprender lenguaje — pero su ventana fija reveló que aprender lenguaje requiere arquitecturas que entiendan secuencias, no solo instantáneas.",
                    p4: "A pesar de estas limitaciones, el framework MLP + Embeddings estableció conceptos que siguen siendo fundamentales en todos los modelos de lenguaje modernos: representaciones de tokens aprendidas, jerarquías de características no lineales y entrenamiento de extremo a extremo basado en gradientes. Cada Transformer sigue usando capas de embedding y bloques MLP feedforward — las ideas introducidas aquí nunca desaparecieron; evolucionaron.",
                },
                cta: {
                    heading: "Continúa Explorando",
                    freeLabTitle: "Abrir Lab Libre",
                    freeLabDesc: "Experimenta con modelos MLP + Embeddings de forma interactiva. Entrena, visualiza embeddings y genera texto con diferentes hiperparámetros.",
                    transformerTitle: "Siguiente: Redes Neuronales Recurrentes",
                    transformerDesc: "Descubre cómo las RNNs superan la limitación de ventana fija procesando secuencias un token a la vez, llevando un estado oculto que actúa como memoria.",
                },
                footer: {
                    text: "De tablas de conteo a representaciones aprendidas — el modelo MLP + Embeddings marcó el momento en que el modelado del lenguaje se volvió verdaderamente neuronal.",
                    brand: "LM-Lab · Narrativa MLP + Embeddings",
                },
                oneHot: {
                    title: "Codificación One-Hot",
                    sparse: "Dispersa, de alta dimensión. Cada token está igualmente distante de todos los demás. Sin noción de similitud.",
                    learnedTitle: "Embeddings Aprendidos",
                    dense: "Denso, de baja dimensión. Las palabras similares (\"cat\" y \"mat\") obtienen vectores similares — el modelo puede generalizar.",
                },
                mlpDiagram: {
                    input: "Entrada",
                    inputDesc: "Tokens de contexto (one-hot o embeddings)",
                    hidden1: "Oculta 1",
                    hidden1Desc: "Características aprendidas",
                    hidden2: "Oculta 2",
                    hidden2Desc: "Patrones de orden superior",
                    output: "Salida",
                    outputDesc: "Probabilidades del siguiente token",
                },
                thinkFirst: {
                    xor: {
                        question: "Un modelo lineal solo puede dibujar líneas rectas. ¿Cuántas neuronas ocultas crees que se necesitan para separar 4 grupos tipo XOR?",
                        reveal: "¡Solo 2 neuronas en una capa oculta pueden resolver XOR — pruébalo a continuación!",
                    },
                    embedding: {
                        question: "Si pudieras representar cada carácter con solo 3 números en lugar de 96, ¿qué propiedades querrías que esos números capturen?",
                        reveal: "Los embeddings aprenden exactamente esto — vectores densos donde caracteres similares obtienen números similares, automáticamente.",
                    },
                    hyperparams: {
                        question: "¿Qué crees que importa más para la calidad de predicción: un embedding más grande o una capa oculta más ancha?",
                        reveal: "¡Depende de los datos! Usa el explorador a continuación para descubrirlo empíricamente.",
                    },
                    contextWindow: {
                        question: "El modelo ve 3 tokens de contexto. 'Mary caminó hacia el jardín, y ella...' — ¿Puede el modelo averiguar quién es 'ella'?",
                        reveal: "No — 'Mary' está 8 tokens atrás, muy fuera de una ventana de 3 tokens.",
                    },
                },
                guidedExperiments: {
                    title: "Experimentos Guiados — Prueba Estos",
                    bestConfig: {
                        title: "Encuentra la Mejor Configuración",
                        tryThis: "Ajusta los deslizadores para minimizar la pérdida de validación. ¿Qué hiperparámetro tiene el mayor impacto?",
                        observe: "Observa la forma de la curva de pérdida — ¿se estanca temprano o sigue mejorando?",
                    },
                    overfitting: {
                        title: "Detecta Sobreajuste",
                        tryThis: "Encuentra una configuración donde la pérdida de entrenamiento sea mucho menor que la de validación.",
                        observe: "La insignia de anomalía se ilumina y la métrica de brecha muestra la divergencia.",
                    },
                    embeddings: {
                        title: "Observa Cómo Aprenden los Embeddings",
                        tryThis: "Selecciona una configuración y desliza el control de instantáneas de entrenamiento en la pestaña Espacio de Embeddings.",
                        observe: "Los tokens pasan de ruido aleatorio a grupos estructurados a medida que avanza el entrenamiento.",
                    },
                    generation: {
                        title: "Genera y Compara",
                        tryThis: "Genera texto desde las mejores y peores configuraciones (pérdida más baja vs más alta).",
                        observe: "Nota cómo la calidad de predicción se correlaciona directamente con la pérdida de validación.",
                    },
                },
            },
            explorer: {
                loading: "Cargando configuraciones…",
                errorPrefix: "Error al cargar la cuadrícula MLP:",
                noConfigs: "No hay configuraciones MLP disponibles desde el backend.",
                onboarding: {
                    title: "Tour Rápido",
                    scatter: {
                        text: "Cada punto es un modelo entrenado. Haz clic en cualquier punto para seleccionarlo y ver sus métricas completas abajo. Los modelos más cerca de la esquina inferior izquierda tienen menor pérdida de validación (mejor rendimiento).",
                    },
                    sliders: {
                        text: "Usa estos deslizadores para explorar diferentes combinaciones de hiperparámetros. El explorador seleccionará automáticamente el modelo entrenado más cercano a tus configuraciones elegidas.",
                    },
                    metrics: {
                        text: "Observa cómo estas tarjetas de métricas se actualizan al seleccionar diferentes modelos. Busca las insignias de anomalía — señalan modelos con problemas de entrenamiento como sobreajuste o inestabilidad de gradientes.",
                    },
                    next: "Siguiente",
                    gotIt: "¡Entendido!",
                },
                sections: {
                    s01Title: "Visión General del Model Zoo",
                    s01Subtitle: "configuraciones completamente entrenadas — haz clic en cualquier punto para seleccionarlo y sincronizar los deslizadores.",
                    s02Title: "Configuración Seleccionada",
                    s02Subtitle: "Tarjetas de métricas, indicadores de anomalías y un resumen en lenguaje sencillo de la calidad de entrenamiento de este modelo.",
                    s03Title: "Espacio de Embeddings",
                    s03Subtitle: "Tokens del vocabulario proyectados a 2D mediante PCA. Desplázate por las instantáneas de entrenamiento para ver cómo emerge la estructura del ruido.",
                    s04Title: "Generación de Texto",
                    s04Subtitle: "Genera secuencias de caracteres desde el modelo seleccionado. Ajusta la temperatura y la longitud para explorar la distribución de salida.",
                    s05Title: "Diagnósticos Avanzados de Entrenamiento",
                    s05Subtitle: "Flujo de gradientes, salud de neuronas y patrones de sobreajuste a lo largo del entrenamiento completo.",
                },
                zoo: {
                    expandableTitle: "Model Zoo · {count} Configuraciones",
                    description: "Empieza aquí. Cada punto es un modelo completamente entrenado. Haz clic en cualquier punto para seleccionarlo y sincronizar los deslizadores. Usa los filtros para encontrar las mejores configuraciones, las peores o los valores atípicos.",
                },
                sliders: {
                    embeddingDim: "Dim. Embedding",
                    hiddenSize: "Tamaño Oculto",
                    learningRate: "Tasa de Aprendizaje",
                },
                config: { active: "Activo:", score: "puntuación" },
                metrics: {
                    valLoss: "Pérdida Val.",
                    trainLoss: "Pérdida Entren.",
                    loss: "Pérdida",
                    trainSmoothed: "Entren. (suavizado)",
                    perplexity: "Perplejidad",
                    random: "aleatorio:",
                    trainValGap: "Brecha Entren.–Val.",
                    params: "Parámetros",
                    compute: "Cómputo",
                    tooltips: {
                        valLoss: "Pérdida de validación: qué tan bien predice el modelo datos no vistos durante el entrenamiento. Menor = mejor. Esta es la métrica principal.",
                        trainLossOnly: "Solo pérdida de entrenamiento — pérdida de validación no disponible para esta configuración. La pérdida de entrenamiento puede ser engañosamente optimista.",
                        trainSmoothed: "Media del último ~10% de los valores de pérdida de entrenamiento registrados. El suavizado elimina el ruido por lote.",
                        perplexity: "Perplejidad ≈ exp(pérdida). Si la perplejidad = 20, el modelo es tan incierto como elegir aleatoriamente entre 20 tokens. Menor = mejor.",
                        randomPerplexity: "Perplejidad que lograría un modelo aleatorio uniforme. Cualquier modelo útil debería estar muy por debajo de esto.",
                        trainValGap: "Brecha Entren.–Val. = pérdida_val − pérdida_entren_suavizada. Positivo = sobreajuste. Negativo = saludable o subajuste. Valores > 0.3 son preocupantes.",
                        paramsCount: "Número total de pesos y sesgos aprendibles en esta configuración del modelo.",
                        compute: "Cómputo = parámetros × pasos de entrenamiento ({steps}k). Es un proxy determinista del coste computacional — independiente de la máquina.",
                        computeDetail: "{params} parámetros × {steps}k pasos. Los modelos más grandes cuestan más de entrenar pero no siempre generalizan mejor.",
                        score: "Puntuación de calidad compuesta — mayor es mejor. Calculada como cuánto mejoró esta configuración sobre la línea base aleatoria.",
                    },
                },
                anomalies: {
                    aboveRandom: "≥ Aleatorio",
                    overfitting: "Sobreajuste",
                    valLossUp: "Pérd. Val. ↑",
                    noConvergence: "Sin Convergencia",
                    unstableGrad: "∇ Inestable",
                    pplMismatch: "PPL ≠ exp(L)",
                    tooltips: {
                        aboveRandom: "La pérdida final está en o por encima de la línea base aleatoria — el modelo puede no haber aprendido patrones significativos.",
                        overfitting: "La brecha entren.–val. supera 0.3 — el modelo memoriza los datos de entrenamiento mejor de lo que generaliza.",
                        valLossUp: "La pérdida de validación seguía aumentando al final del entrenamiento — señal de inicio de sobreajuste.",
                        noConvergence: "La pérdida no disminuyó significativamente durante el entrenamiento — la tasa de aprendizaje puede ser demasiado alta o baja.",
                        unstableGrad: "Las normas de gradiente variaron >1000× durante el entrenamiento — indica inestabilidad de optimización.",
                        pplMismatch: "La perplejidad reportada no coincide con exp(pérdida). Esto puede indicar un problema en el pipeline de datos.",
                    },
                },
                summaries: {
                    aboveRandom: "Este modelo apenas supera al azar. Probablemente no aprendió patrones significativos — revisa la tasa de aprendizaje y la arquitectura.",
                    nonDecreasing: "La pérdida no disminuyó durante el entrenamiento. El modelo no convergió — la tasa de aprendizaje puede ser demasiado alta o baja.",
                    overfitting: "Este modelo sobreajusta — memoriza los datos de entrenamiento mejor de lo que generaliza. La brecha entre pérdida de entrenamiento y validación es grande.",
                    lossIncreasing: "La pérdida de validación seguía aumentando al final del entrenamiento — señal de sobreajuste tardío. El modelo entrenó demasiado tiempo.",
                    unstableGradients: "Las normas de gradiente variaron salvajemente durante el entrenamiento — la optimización fue inestable. Esto a menudo significa que la tasa de aprendizaje es demasiado alta.",
                    stillImproving: "El entrenamiento seguía mejorando en el último paso. Con más cómputo, este modelo podría converger más.",
                    balanced: "Este modelo entrena de forma estable y generaliza bien. Una configuración sólida y equilibrada.",
                    converged: "Entrenamiento completado. El modelo convergió con una brecha de generalización moderada.",
                },
                computeLabels: { minimal: "Mínimo", low: "Bajo", moderate: "Moderado", high: "Alto", veryHigh: "Muy Alto" },
                timeline: {
                    title: "Línea de Tiempo del Entrenamiento",
                    noData: "No hay datos de línea de tiempo disponibles.",
                    pts: "pts",
                    every: "cada",
                    steps: "pasos",
                    total: "total",
                    nonUniform: "no uniforme",
                    trend: "Tendencia:",
                    variance: "Varianza:",
                    converged: "Convergió ~",
                    tooltips: {
                        chart: "Curvas de pérdida a lo largo de los pasos de entrenamiento. Verde = pérdida de validación (principal). Morado = pérdida de entrenamiento. Rojo discontinuo = línea base aleatoria.",
                        pts: "Número de puntos de control de métricas registrados durante el entrenamiento. Más puntos = curvas más suaves e informativas.",
                        interval: "Se guardó una instantánea de métricas cada {interval} pasos de actualización de gradiente.",
                        totalSteps: "Total de actualizaciones de gradiente realizadas. Todas las configuraciones entrenan exactamente {steps}k pasos para una comparación justa.",
                        trend: "Dirección de la pérdida de validación en la segunda mitad del entrenamiento. Decreciente = aún aprendiendo. Plana = convergida. Creciente = inicio de sobreajuste.",
                        variance: "Varianza estadística de la pérdida de validación a lo largo del entrenamiento completo. Cercana a cero = entrenamiento estable.",
                        convergenceStep: "Paso de entrenamiento donde la pérdida de validación cayó por primera vez por debajo del 50% de su valor inicial.",
                    },
                    chart: {
                        randomBaseline: "línea base aleatoria",
                        train: "entren.",
                        valPrimary: "val. (principal)",
                        trainingSteps: "Pasos de Entrenamiento",
                    },
                },
                embeddingSpace: {
                    title: "PCA 2D · Deriva del Embedding",
                    tooltip: "Cada punto es un token del vocabulario, proyectado desde el espacio de embeddings aprendido a 2D mediante PCA. Usa el deslizador de instantáneas para ver cómo evolucionan los embeddings.",
                },
                generation: {
                    title: "Muestra Generada",
                    seedPlaceholder: "Texto semilla…",
                    generateButton: "Generar",
                    temp: "Temp",
                    tokens: "Tokens",
                    tempTooltip: "La temperatura controla la aleatoriedad. Baja (0.1) = determinista. Alta (2.0) = creativo pero caótico.",
                    tokensTooltip: "Número máximo de caracteres a generar. El modelo genera un carácter a la vez; más tokens = salida más larga pero más lenta.",
                    estPpl: "PPL est. ≈",
                    chars: "chars",
                    pressGenerate: "Pulsa Generar para producir texto desde el modelo seleccionado.",
                    pplTooltip: "Perplejidad = exp(pérdida). Esta es la perplejidad estimada del modelo en la distribución de entrenamiento — menor significa predicciones más seguras y fluidas.",
                },
                diagnostics: {
                    intro: "Estos diagnósticos revelan la dinámica interna del entrenamiento: flujo de gradientes, uso de neuronas y patrones de sobreajuste.",
                    gradNormLabel: "Norma de Gradiente por Pasos",
                    deadNeuronLabel: "Ratio de Neuronas Muertas por Pasos",
                    gradNormSection: "ⓘ Normas de Gradiente por Capa",
                    activationSection: "ⓘ Salud de Activaciones durante el Entrenamiento",
                    genGapSection: "ⓘ Mapa de Calor de Brecha de Generalización · Todas las Configuraciones",
                    tooltips: {
                        gradNorm: "La norma de gradiente es la magnitud global de las actualizaciones de pesos en cada paso de entrenamiento. Valores estables y moderados indican una optimización saludable.",
                        deadNeuron: "Fracción de neuronas que nunca se activan durante el entrenamiento. Una neurona 'muerta' siempre produce cero, sin contribuir al aprendizaje.",
                        gradNormLayer: "Muestra las magnitudes de gradiente por grupo de parámetros a través de las instantáneas de entrenamiento. Magnitudes equilibradas entre capas sugieren un aprendizaje estable.",
                        activationHealth: "Muestra estadísticas de saturación y neuronas muertas a lo largo del tiempo de entrenamiento. La saturación significa que las neuronas están atascadas cerca de los límites de la activación tanh (±1).",
                        genGap: "Diferencia entre pérdida de entrenamiento y validación en todas las configuraciones, promediada sobre las tasas de aprendizaje. Verde = el modelo generaliza bien. Rojo = sobreajuste.",
                    },
                },
                dataSource: "Datos reales de {count} configuraciones entrenadas · {steps}k pasos cada una · registradas cada {interval} pasos.",
                primaryValLoss: "Principal: pérdida de validación.",
                primaryTrainLoss: "Principal: pérdida de entrenamiento (val. no disponible).",
            },
            compareMode: {
                needMore: "Se necesitan al menos 2 configuraciones para comparar.",
                needAtLeastTwoConfigs: "Se necesitan al menos 2 configuraciones para comparar.",
                description: "Selecciona dos configuraciones para comparar lado a lado. El texto semilla del generador principal se sincroniza con ambas.",
                selectTwoConfigsToCompare: "Selecciona dos configuraciones para comparar lado a lado. El texto semilla del generador principal se sincroniza con ambas.",
                configLabel: "Config {label}",
                config: "Config",
                configA: "Config A",
                configB: "Config B",
                title: "Comparación Lado a Lado",
                seed: "Semilla:",
                editSeedHint: "(editar en el generador principal arriba)",
                editInMainGeneratorAbove: "(editar en el generador principal arriba)",
                selectAConfig: "Seleccionar una config…",
                selectConfigA: "Seleccionar Config A",
                selectConfigB: "Seleccionar Config B arriba",
                diffTitle: "B vs A — diferencias",
                diffSummary: "B vs A — diferencias",
                noTimelineData: "Sin datos de línea de tiempo.",
                steps: "Pasos",
                train: "entren.",
                val: "val.",
                trainingLoss: "Pérdida de Entrenamiento",
                embeddingSpace: "Espacio de Embeddings",
                generatedText: "Texto Generado",
                temperature: "T",
                generate: "Generar",
                generating: "Generando…",
                seedTextAboveWillBeUsed: "Se usará el texto semilla de arriba.",
                metrics: {
                    valLoss: "Pérd. Val.",
                    perplexity: "Perplejidad",
                    gap: "Brecha",
                    genGap: "Brecha Gen.",
                    score: "Puntuación",
                    params: "Parámetros",
                },
                panel: {
                    trainingLoss: "Pérdida de Entrenamiento",
                    embeddingSpace: "Espacio de Embeddings",
                    generatedText: "Texto Generado",
                    seedUsed: "Se usará el texto semilla de arriba.",
                    noTimeline: "Sin datos de línea de tiempo.",
                    tempLabel: "T=",
                    generateButton: "Generar",
                },
            },
            scatterPlot: {
                description: "Cada punto es un modelo entrenado. X = número de parámetros (coste), Y = pérdida de validación final (menor es mejor). Color = dimensión del embedding. La línea discontinua es la",
                paretoFrontier: "frontera de Pareto",
                paretoDesc: "— mejor pérdida para cada nivel de cómputo.",
                highlighted: "resaltados",
                filters: {
                    all: "Todos",
                    allTip: "Mostrar todas las configuraciones",
                    best: "Mejores ★",
                    bestTip: "Top 25% por puntuación compuesta",
                    worst: "Peores",
                    worstTip: "Bottom 25% por puntuación — mayor pérdida, menor calidad",
                    anomalies: "Anomalías",
                    anomaliesTip: "Configs con brecha de generalización > 0.3 o puntuación < 0.2",
                },
                legend: { paretoLine: "Frontera de Pareto" },
                footer: "{count} configuraciones · Haz clic en cualquier punto para seleccionar · Abajo-derecha = más cómputo, menos beneficio",
                axisX: "Parámetros",
                axisY: "Pérd. Val.",
            },
            embeddingDrift: {
                snapshotLabel: "Instantánea de entrenamiento",
                trainingSnapshot: "Instantánea de entrenamiento",
                stepLabel: "Paso",
                step: "Paso",
                loading: "Cargando embeddings…",
                phaseText: {
                    p0: "Inicialización aleatoria — los embeddings aún no tienen estructura.",
                    p1: "Entrenamiento temprano — los clústeres comienzan a formarse.",
                    p2: "Entrenamiento temprano-medio — las categorías de caracteres se vuelven distintas.",
                    p3: "Entrenamiento medio — el espacio de embeddings muestra estructura clara. Los tokens similares se agrupan.",
                    p4: "Entrenamiento tardío — la estructura se consolida, el ruido se reduce.",
                    p5: "Punto de control final — embeddings completamente entrenados. Esto es lo que el modelo usa para predecir.",
                },
                phases: {
                    "0": "Inicialización aleatoria — los embeddings aún no tienen estructura.",
                    "1": "Entrenamiento temprano — los clústeres comienzan a formarse.",
                    "2": "Entrenamiento temprano-medio — las categorías de caracteres se vuelven distintas.",
                    "3": "Entrenamiento medio — el espacio de embeddings muestra estructura clara. Los tokens similares se agrupan.",
                    "4": "Entrenamiento tardío — la estructura se consolida, el ruido se reduce.",
                    "5": "Punto de control final — embeddings completamente entrenados. Esto es lo que el modelo usa para predecir.",
                },
                snapshotUnavailable: "Instantánea no disponible — mostrando el punto de control más cercano disponible.",
            },
            embeddingViz: {
                loading: "Cargando embeddings…",
                waiting: "Esperando datos de embeddings…",
                dim1: "Dimensión 1 (PCA)",
                dim2: "Dimensión 2 (PCA)",
                tokens: "tokens",
                clickInfo: "Haz clic en cualquier token para resaltar sus vecinos más cercanos. Los tokens similares se agrupan en el espacio de embeddings aprendido.",
                clickToHighlight: "Haz clic en cualquier token para resaltar sus vecinos más cercanos. Los tokens similares se agrupan en el espacio de embeddings aprendido.",
                deselectInfo: "Haz clic en otro token o en \"{token}\" de nuevo para deseleccionar. Las líneas discontinuas conectan con los 4 vecinos más cercanos en el espacio de embeddings.",
                clickToDeselect: "Haz clic en otro token o en \"{token}\" de nuevo para deseleccionar. Las líneas discontinuas conectan con los 4 vecinos más cercanos en el espacio de embeddings.",
                categories: {
                    vowel: "Vocales",
                    vowels: "Vocales",
                    consonant: "Consonantes",
                    consonants: "Consonantes",
                    digit: "Dígitos",
                    digits: "Dígitos",
                    punctuation: "Puntuación",
                    whitespace: "Espacio / Especial",
                    spaceSpecial: "Espacio / Especial",
                },
            },
            nearestNeighbors: {
                title: "Vecinos Más Cercanos (Similitud Coseno)",
                loading: "Cargando datos de vecinos…",
                neighborsOf: "Vecinos de",
                noNeighborData: "No hay datos de vecinos para este token.",
                noData: "No hay datos de vecinos para este token.",
                selectPrompt: "Selecciona un token arriba para ver sus vecinos más cercanos por similitud coseno en el espacio de embeddings.",
            },
            snapshotDiagnostics: {
                noSnapshotData: "No hay datos de instantáneas disponibles.",
                noGradData: "No hay datos de norma de gradiente en las instantáneas.",
                noSatData: "No hay datos de saturación de activaciones en las instantáneas.",
                gradLegend: "Verde = gradientes pequeños · Amarillo/Rojo = gradientes grandes · Magnitudes consistentes entre capas indican un entrenamiento saludable.",
                saturatedLeft: "Activaciones saturadas (izquierda)",
                deadRight: "Neuronas muertas (derecha)",
                satLegend: "La saturación alta significa que muchas neuronas están fijadas en los extremos de tanh (±1). Las neuronas muertas nunca se activan. Ambas desperdician capacidad.",
                satNote: "La saturación alta significa que muchas neuronas están fijadas en los extremos de tanh (±1). Las neuronas muertas nunca se activan. Ambas desperdician capacidad.",
                stepHeader: "Paso",
                step: "Paso",
            },
            genGapHeatmap: {
                header: "oculto ↓ / emb →",
                axisLabel: "oculto ↓ / emb →",
                gapLabel: "Brecha:",
                legend: {
                    healthy: "< 0 (saludable)",
                    low: "0–0.1",
                    mid: "0.1–0.2",
                    medium: "0.1–0.2",
                    high: "0.2–0.3",
                    overfit: "> 0.3 (sobreajuste)",
                },
                note: "Cada celda promedia la brecha entren.–val. en todas las tasas de aprendizaje para ese par (emb_dim, hidden_size). Rojo = sobreajuste. Verde = generalización saludable.",
                description: "Cada celda promedia la brecha entren.–val. en todas las tasas de aprendizaje para ese par (emb_dim, hidden_size). Rojo = sobreajuste. Verde = generalización saludable.",
                configs: "configs (entre LRs)",
                avgGap: "brecha prom.=",
                bestLoss: "mejor pérdida=",
            },
        },
        neuralNetworks: {
            title: "Redes Neuronales y Deep Learning",
            description: "Una exploración desde primeros principios de las redes neuronales artificiales — del perceptrón a la retropropagación. Comprende cómo los parámetros aprendidos reemplazan al conteo y por qué las representaciones densas generalizan donde los N-gramas fallan.",
            hero: {
                badge: "Computación Neuronal",
            },
            freeLab: {
                title: "Playground de Redes Neuronales",
                description: "Experimenta libremente con perceptrones, funciones de activación, actualizaciones de pesos y dinámicas de entrenamiento.",
            },
            guidedExperiments: {
                title: "Experimentos Guiados",
                subtitle: "Cinco ejercicios rápidos para construir intuición",
                handVsTraining: {
                    title: "Construye tu Primera Neurona — A Mano, Luego con Entrenamiento",
                    doThis: "Establece x₁=1, x₂=0.5. Ajusta manualmente w₁, w₂, b hasta que la salida sea ≈ 0.8. Luego reinicia y entrena con objetivo=0.8.",
                    observeThis: "El entrenamiento encuentra valores similares automáticamente. El descenso de gradiente reemplaza la suposición manual.",
                },
                activationComparison: {
                    title: "Compara Funciones de Activación",
                    doThis: "Cambia entre Lineal, ReLU, Sigmoide y Tanh. Establece x₁=−2, x₂=2, w₁=1, w₂=1, b=0.",
                    observeThis: "Lineal pasa los negativos sin cambios. ReLU los pone a cero. Sigmoide y Tanh comprimen a rangos acotados.",
                },
                learningRateExtremes: {
                    title: "Rompe el Entrenamiento con Tasas de Aprendizaje Extremas",
                    doThis: "Cambia el modelo a Lineal. Establece objetivo=0.8. Entrena con η=0.05 (lento), luego η=1.0 (normal), luego η=2.0 (agresivo).",
                    observeThis: "η baja converge lentamente. η alta puede sobrepasarse y oscilar. El punto óptimo depende del modelo y los datos.",
                },
                convergenceBehavior: {
                    title: "Mira la Pérdida Converger Durante Muchos Pasos",
                    doThis: "Establece objetivo=0.9, η=1.0. Haz clic en Auto-Train ×10 repetidamente y observa el gráfico de pérdida.",
                    observeThis: "La pérdida baja rápido al principio, luego se estanca. Los primeros pasos son los más importantes.",
                },
                randomInitialization: {
                    title: "Mira por qué Importa la Iniciaización Aleatoria",
                    doThis: "Entrena al objetivo=0.5 con parámetros por defecto. Reinicia. Cambia w₁ a 2.0, entrena de nuevo. Compara la pérdida final.",
                    observeThis: "Diferentes puntos de partida llevan a diferentes soluciones. Las redes neuronales no son convexas; la inicialización importa.",
                },
            },
            sections: {
                artificialNeuron: { number: "02", label: "Ensamblaje" },
                nonLinearity: { number: "03", label: "Escalando" },
                findingDirection: { number: "04", label: "Corrección" },
                makingItLearn: { number: "05", label: "Entrenamiento" },
                trainingAtScale: { number: "06", label: "Escala" },
                overfittingTrap: { number: "07", label: "Sobreajuste" },
                fromNumbers: { number: "08", label: "Lenguaje" },
                playground: {
                    inputs: {
                        title: "Entradas",
                        desc: "Valores de características que se introducen en el perceptrón. Cada entrada se multiplica por su peso correspondiente antes de sumarse.",
                        x1: "Primer valor de entrada (x₁). Se multiplica por el peso w₁ antes de entrar al nodo de suma.",
                        x2: "Segundo valor de entrada (x₂). Se multiplica por el peso w₂ antes de entrar al nodo de suma.",
                    },
                    weights: {
                        title: "Parámetros",
                        desc: "Parámetros aprendibles que escalan cada entrada. El sesgo desplaza el umbral de activación independientemente de las entradas.",
                        w1: "Peso para la entrada x₁. Controla cuánto influye x₁ en la salida. Se actualiza por descenso de gradiente durante el entrenamiento.",
                        w2: "Peso para la entrada x₂. Controla cuánto influye x₂ en la salida. Se actualiza por descenso de gradiente durante el entrenamiento.",
                        bias: "Término de sesgo (b). Desplaza la suma ponderada, permitiendo que la neurona se active incluso cuando todas las entradas son cero.",
                    },
                    activation: {
                        title: "Función de Activación",
                        explorerTitle: "Interactivo · Funciones de Activación",
                        ariaLabel: "Gráfico de la función de activación {name}",
                        inputLabel: "Suma ponderada z (entrada a la activación)",
                        caption: "Cambia entre funciones de activación y arrastra el deslizador z para ver cómo cada una transforma la suma ponderada.",
                        desc: "Transformación no lineal aplicada tras la suma ponderada. Sin ella, apilar capas colapsaría en una única función lineal.",
                        linear: "Sin transformación — la salida es igual a la suma ponderada z. Útil como referencia, pero no puede modelar patrones no lineales.",
                        relu: "Unidad Lineal Rectificada. Devuelve max(0, z). Dispersa, eficiente y ampliamente usada en redes profundas.",
                        sigmoid: "Comprime la salida a (0, 1). Útil para salidas de probabilidad binaria, pero puede causar gradientes que desaparecen.",
                        tanh: "Comprime la salida a (−1, 1). Centrada en cero, a menudo preferida sobre sigmoid para capas ocultas.",
                        labels: {
                            relu: "ReLU",
                            sigmoid: "Sigmoide",
                            tanh: "Tanh",
                        }
                    },
                    training: {
                        title: "Entrenamiento",
                        desc: "Ajusta el objetivo y la tasa de aprendizaje, luego avanza paso a paso por el descenso de gradiente para minimizar la pérdida.",
                        target: "El valor de salida deseado (y). El modelo intenta minimizar la diferencia cuadrática entre su predicción y este objetivo.",
                        learningRate: "Tasa de aprendizaje (η). Controla el tamaño del paso en el descenso de gradiente. Muy alta causa inestabilidad; muy baja ralentiza la convergencia.",
                        step: "Ejecuta un paso de descenso de gradiente: calcula los gradientes y actualiza w₁, w₂ y b por −η × gradiente.",
                        auto: "Ejecuta 10 pasos de descenso de gradiente en secuencia para observar cómo evolucionan los parámetros y la pérdida.",
                        reset: "Reinicia todos los parámetros e historial de entrenamiento a sus valores iniciales.",
                        random: "Aleatoriza los pesos y el sesgo para explorar una región diferente del paisaje de pérdida.",
                        steps: "Número total de pasos de descenso de gradiente realizados en esta sesión de entrenamiento.",
                        stepIndex: "Número de paso en el registro del historial de entrenamiento.",
                        noData: "Sin datos de entrenamiento aún",
                        noDataHint: "Haz clic en \"Entrenar 1 Paso\" o \"Auto-Entrenar ×10\" para comenzar",
                        insightsTitle: "Perspectivas de Entrenamiento",
                        runInference: "Ejecuta inferencia para ver los datos de entrenamiento",
                        stats: {
                            finalLoss: { label: "Pérdida Final", desc: "El nivel de error al final del entrenamiento. Cuanto menor, mejor." },
                            steps: { label: "Pasos", desc: "Cuántas veces el modelo actualizó sus parámetros durante el entrenamiento." },
                            batchSize: { label: "Tamaño de Lote", desc: "Número de ejemplos procesados por paso de actualización de gradiente." },
                            learningRate: { label: "Tasa de Aprendizaje", desc: "Tamaño del paso en el descenso de gradiente. Muy alta causa inestabilidad; muy baja ralentiza la convergencia." },
                            parameters: { label: "Parámetros", desc: "Número total de pesos aprendibles en el modelo." },
                        },
                    },
                    visualization: {
                        sum: "Nodo de suma ponderada (Σ). Calcula z = w₁x₁ + w₂x₂ + b antes de aplicar la función de activación.",
                        output: "Predicción final ŷ = activación(z). Es el valor que la red produce tras aplicar la no linealidad.",
                        loss: "Pérdida de error cuadrático medio: L = (ŷ − objetivo)². Mide cuánto se aleja la predicción del objetivo deseado.",
                        activationNode: "Nodo de función de activación. Aplica la no linealidad seleccionada a la suma ponderada z.",
                        activationCurve: "Curva de la función de activación. El punto muestra la entrada z actual y su salida correspondiente f(z).",
                        equation: "Ecuación completa del paso hacia adelante: multiplica cada entrada por su peso, suma el sesgo y aplica la función de activación.",
                        lossCurve: "Pérdida a lo largo de los pasos de entrenamiento. Una curva descendente indica que el modelo está aprendiendo.",
                        lossCurveLabel: "Pérdida por pasos de entrenamiento",
                        lossTooltipTitle: "¿Qué es la Pérdida?",
                        lossTooltipErrorLabel: "Error de Predicción",
                        lossTooltipError: "La pérdida mide cuánto se \"sorprende\" el modelo. Una pérdida alta significa que está prediciendo mal con frecuencia.",
                        lossTooltipBenchmarkLabel: "El Punto de Referencia",
                        lossTooltipBenchmark: "Una predicción aleatoria pura daría una pérdida de ~4.56 (−ln(1/96)). Cualquier valor menor significa que el modelo ha aprendido algo.",
                        lossTooltipCaption: "La curva descendente muestra al modelo descubriendo lentamente patrones en tu texto.",
                    },
                    tabs: {
                        perceptron: "Visualiza el paso hacia adelante de una sola neurona: las entradas se escalan por pesos, se suman con un sesgo y pasan por una activación.",
                        activation: "Explora cómo la función de activación elegida transforma la suma ponderada z en la predicción final ŷ.",
                        gradients: "Inspecciona el flujo de gradientes por la regla de la cadena y observa exactamente cómo se actualizará cada parámetro.",
                        training: "Sigue la evolución de la pérdida y los parámetros a lo largo de los pasos para observar el descenso de gradiente en acción.",
                    },
                    gradients: {
                        visualizerTitle: "Interactivo · Retropropagación Paso a Paso",
                        forwardPass: "Paso hacia adelante: calcula z, aplica la activación y calcula la pérdida a partir de la predicción y el objetivo actuales.",
                        forwardPassLabel: "Paso Hacia Adelante",
                        chainRule: "Retropropagación mediante la regla de la cadena: descompone ∂L/∂w en un producto de gradientes locales a través de cada nodo.",
                        chainRuleLabel: "Gradientes (Regla de la Cadena)",
                        weightUpdate: "Actualización propuesta de parámetros: nuevo valor = valor anterior − η × gradiente. Se aplica al hacer clic en Entrenar 1 Paso.",
                        weightUpdateLabel: "Actualización de Pesos",
                        linearSum: "Pre-activación lineal: z = w₁x₁ + w₂x₂ + b. La suma ponderada bruta antes de la función de activación.",
                        linearSumLabel: "Lineal",
                        prediction: "Predicción ŷ = activación(z). La salida de la neurona tras aplicar la función de activación no lineal.",
                        predictionLabel: "Activación",
                        loss: "Pérdida L = (ŷ − objetivo)². Error cuadrático entre la predicción y el valor objetivo deseado.",
                        lossLabel: "Pérdida",
                        reset: "Reiniciar",
                        caption: "Avanza por el paso hacia adelante, la retropropagación y las actualizaciones de pesos para ver cómo aprende una neurona.",
                        buttonLabels: {
                            idle: "Correr Paso Adelante →",
                            forward: "Retropropagar →",
                            backward: "Actualizar Pesos →",
                            update: "Nuevo Paso Adelante →",
                        }
                    },
                    buttons: {
                        trainStep: "Entrenar 1 Paso",
                        autoTrain: "Auto-Entrenar ×10",
                        reset: "Reiniciar",
                        random: "Aleatorio",
                    },
                    tabLabels: {
                        perceptron: "Perceptrón",
                        activation: "Activación",
                        gradients: "Gradientes",
                        training: "Entrenamiento",
                    },
                    diagram: {
                        title: "Interactivo · Perceptrón",
                        ariaLabel: "Diagrama de flujo del perceptrón",
                        caption: "Ajusta las entradas, pesos y sesgo para ver cómo el perceptrón los transforma en una salida.",
                        inputX1: "Entrada x₁",
                        inputX2: "Entrada x₂",
                        weightW1: "Peso w₁",
                        weightW2: "Peso w₂",
                        biasB: "Sesgo b",
                        tooltipW1: "Peso w₁ = {val} — Controla cuánto influye la entrada x₁ en la suma",
                        tooltipW2: "Peso w₂ = {val} — Controla cuánto influye la entrada x₂ en la suma",
                        tooltipX1: "Entrada x₁ = {val} — La primera característica de entrada alimentada a la neurona",
                        tooltipX2: "Entrada x₂ = {val} — La segunda característica de entrada alimentada a la neurona",
                        tooltipSum: "Suma Ponderada z = {val} — Calculada como (w₁×x₁) + (w₂×x₂) + b",
                        tooltipBias: "Sesgo b = {val} — Desplaza el umbral de decisión; positivo = más fácil de activar, negativo = más difícil",
                        tooltipActivation: "Activación ReLU = {val} — ReLU(z) = max(0, z). Salida z si es positivo, de lo contrario 0",
                        tooltipOutput: "Salida Final = {val} — La predicción de la neurona tras aplicar ReLU a la suma ponderada",
                        breakdownTitle: "Desglose de Contribución",
                    },
                },
            },
        },
    },
    bigramNarrative: {
        hero: {
            eyebrow: "Comprendiendo los Modelos de Lenguaje",
            titlePrefix: "El Modelo",
            titleSuffix: "Bigrama",
            description: "Una exploración desde primeros principios del modelo estadístico de lenguaje más simple — y por qué sigue importando.",
            autoCompleteHint: "Este modelo predice un carácter a la vez. Intenta escribir."
        },
        problem: {
            title: "El Problema de la Predicción",
            lead: "El lenguaje es fundamentalmente secuencial. Cada palabra que lees ahora está influenciada por las palabras que vinieron antes.",
            p1: "Esta propiedad — que cada token en una secuencia lleva ",
            p1Highlight: "expectativas sobre lo que sigue",
            p2: " — es lo que hace el lenguaje tanto expresivo como predecible. También es lo que lo hace tan difícil de modelar computacionalmente.",
            p3: "El desafío central del modelado de lenguaje es engañosamente simple de enunciar:",
            quote: "Dado lo que ya hemos visto, ¿qué debería venir a continuación?",
            p4: "Esta pregunta ha impulsado décadas de investigación en ",
            h1: "lingüística computacional",
            h2: "teoría de la información",
            h3: "aprendizaje profundo",
            p5: ". Para construir un modelo que pueda responderla, necesitamos una forma de capturar la estructura estadística del lenguaje. Empecemos con el enfoque más simple posible.",
            label: "Fundamentos"
        },
        coreIdea: {
            label: "Idea Central",
            title: "La Idea Estadística Más Simple",
            lead: "¿Y si, en lugar de intentar comprender el significado, simplemente observáramos patrones?",
            p1: "Concretamente: ",
            h1: "¿con qué frecuencia un carácter sigue a otro?",
            p2: " Esta es la idea central detrás del modelo Bigrama. Ignora la gramática, la semántica y las dependencias de largo alcance por completo. Solo hace una pregunta: dado el token actual, ¿cuál es la distribución de probabilidad sobre el siguiente token?",
            caption: "El supuesto del Bigrama: el siguiente token depende solo del actual.",
            p3: "Modelamos P(x_{t+1} | x_t) — la probabilidad de ver un token siguiente particular dado solo el token que acabamos de observar. Nada más, nada menos. Esta simplificación radical es lo que hace al modelo tanto tratable como limitado.",
            calloutTitle: "Idea Clave",
            calloutP1: "El \"bi\" en Bigrama significa ",
            calloutH1: "dos",
            calloutP2: ". El modelo considera pares de tokens — el actual y el siguiente. No tiene memoria de nada anterior al token actual."
        },
        mechanics: {
            label: "Mecánica",
            title: "Construyendo una Tabla de Transición",
            lead: "Para aprender estas probabilidades, el modelo recorre un corpus de entrenamiento y cuenta cada par de tokens consecutivos.",
            p1: "Para cada token A, registra con qué frecuencia cada posible token B aparece inmediatamente después. Estos conteos forman una ",
            h1: "matriz",
            p2: " — una tabla bidimensional donde las filas representan el token actual y las columnas el siguiente. Cada celda contiene el número de veces que esa transición específica se observó en los datos de entrenamiento.",
            p3: "La visualización a continuación es un renderizado en vivo de esta matriz de transición. Las celdas más brillantes indican pares más frecuentes — patrones que el modelo ha aprendido de texto real.",
            dataSourceTitle: "¿De dónde vienen estos datos?",
            dataSourceP1: "Esta matriz se construyó entrenando en un corpus de texto real (en este caso, un ensayo de Paul Graham). El modelo recorrió todo el texto carácter por carácter, contando cada par que vio.",
            dataSourceP2: "Por ejemplo, si el texto contenía 'the' 1.000 veces, el modelo incrementó el conteo para 't→h' en 1.000 y 'h→e' en 1.000. Después de escanear todo el corpus, normalizó cada fila para crear probabilidades.",
            dataSourceP3: "Lo que ves abajo es el resultado final: una tabla de 96×96 donde cada uno de los 96 caracteres ASCII imprimibles tiene su propia fila, mostrando la distribución de probabilidad para qué carácter viene después.",
            calloutTitle: "Leyendo la Matriz",
            calloutP1: "Cada fila representa un carácter \"dado\". Cada columna representa el carácter \"siguiente\". El brillo de una celda codifica cuán probable es esa transición. Observa cómo algunas filas son casi uniformes (el modelo no está seguro) mientras otras tienen picos pronunciados (preferencias fuertes).",
            tinyMatrixLabel: "Matriz 5×5 simplificada · ['t', 'h', 'e', 'a', '·']",
            tinyMatrixHint: "Pasa el cursor por cualquier celda para ver la probabilidad exacta. Filas = carácter actual, Columnas = siguiente carácter.",
            tinyMatrixHover: "Pasa el cursor por una celda para ver su probabilidad",
            tinyMatrixColLabel: "siguiente carácter →",
            tinyMatrixRowLabel: "carácter actual →",
            tinyMatrixHigh: "frecuente",
            tinyMatrixLow: "poco frecuente",
            tinyMatrixRare: "muy raro / nunca",
        },
        normalization: {
            label: "Normalización",
            title: "De Conteos a Probabilidades",
            lead: "Los conteos brutos por sí solos no nos dicen mucho. Para hacer predicciones, necesitamos convertirlos en probabilidades.",
            p1: "Lo hacemos ",
            h1: "normalizando cada fila",
            p2: " de la matriz de conteos — dividiendo cada conteo por el total de transiciones desde el token de esa fila. Tras la normalización, cada fila suma 1.0, formando una distribución de probabilidad válida.",
            p3: "El modelo ahora puede hacer afirmaciones concretas: \"Después de la letra h, hay un 32% de probabilidad de que el siguiente carácter sea e, un 15% de que sea a, etc.\"",
            plainEnglishTitle: "En palabras simples",
            plainEnglish: "En palabras simples: Para hallar la probabilidad de la letra B después de la letra A, cuenta cuántas veces viste A→B y luego divide entre todas las veces que viste A seguida de cualquier carácter.",
            p4: "Pruébalo tú mismo abajo. Escribe cualquier texto para ver qué predice el modelo que vendrá a continuación — basado ",
            h2: "únicamente en el último carácter",
            p5: " de tu entrada."
        },
        normalizationViz: {
            context: "Ejemplo: Después de 't', ¿cuáles son las probabilidades de cada siguiente carácter?",
            step1Title: "Paso 1: Conteos Brutos",
            step2Title: "Paso 2: Dividir por el Total",
            step2Desc: "Cada conteo dividido por la suma de todos los conteos en la fila",
            step3Title: "Paso 3: Distribución de Probabilidad",
            animate: "Animar Conversión",
            reset: "Reiniciar"
        },
        sampling: {
            label: "Muestreo",
            title: "Generando Texto Nuevo",
            lead: "Una vez que tenemos una distribución de probabilidad, podemos hacer algo notable: generar texto completamente nuevo.",
            p1: "El proceso se llama ",
            h1: "muestreo autorregresivo",
            p2: ". Comienza con un carácter semilla, muestrea el siguiente de su distribución de probabilidad, luego usa ese nuevo carácter como semilla para el siguiente paso. Repite indefinidamente.",
            calloutTitle: "Temperatura",
            calloutP1: "El parámetro de ",
            calloutH1: "temperatura",
            calloutP2: " controla cuán \"creativa\" es la generación. A ",
            calloutH2: "temperaturas bajas",
            calloutP3: ", el modelo casi siempre elige el token más probable. A ",
            calloutH3: "temperaturas altas",
            calloutP4: ", muestrea más uniformemente — produciendo resultados sorprendentes y a menudo sin sentido.",
            tempP1: "Cómo muestreas importa tanto como lo que aprendiste. Un único parámetro de ",
            tempH1: "temperatura",
            tempP2: " escala los logits antes del paso final de softmax. Por debajo de 1.0, la distribución se afila — el modelo casi siempre elige su carácter mejor clasificado. Por encima de 1.0, la distribución se aplana — cada carácter tiene más oportunidades, a costa de la coherencia.",
            tempBridge: "Ahora prueba el playground de generación. El mismo modelo bigrama produce texto notablemente diferente a temperatura 0.1 versus 2.5 — no porque su conocimiento cambiara, sino porque su estrategia de muestreo lo hizo.",
            softmaxFigureLabel: "Temperatura Softmax · Conceptual",
            softmaxFigureHint: "Arrastra el control deslizante para ver cómo la temperatura redistribuye la misma distribución de probabilidad.",
            playgroundLabel: "Playground de Generación",
            playgroundHint: "Ajusta la temperatura y observa cómo afecta la creatividad del texto generado.",
            p3: "Genera texto a continuación y observa cómo un modelo con ",
            h2: "solo un carácter de memoria",
            p4: " produce texto que es estadísticamente plausible a nivel de carácter, pero sin significado en ningún nivel superior."
        },
        reflection: {
            label: "Reflexión",
            title: "Potencia y Limitaciones",
            lead: "El modelo Bigrama es poderoso precisamente por su simplicidad.",
            p1: "Requiere muy pocos parámetros — solo una matriz V × V, donde V es el tamaño del vocabulario. Entrena instantáneamente. Y proporciona una clara ",
            h1: "línea base probabilística",
            p2: " para la generación de lenguaje que todo modelo más sofisticado debe superar.",
            calloutTitle: "La Limitación Fundamental",
            calloutP1: "El modelo no tiene ",
            calloutH1: "memoria más allá de un solo token",
            calloutP2: ". No puede aprender que \"th\" suele ir seguido de \"e\", porque cuando ve \"h\", ya ha olvidado la \"t\". Captura co-ocurrencia local pero nada sobre palabras, frases o significado.",
            p3: "Esta limitación es exactamente lo que motiva la progresión hacia arquitecturas más sofisticadas: ",
            h2: "los N-gramas",
            p4: " extienden la ventana de contexto, ",
            h3: "los MLPs",
            p5: " aprenden representaciones densas, y ",
            h4: "los Transformers",
            p6: " atienden a toda la secuencia a la vez.",
            quote: "Cada modelo en este laboratorio se construye sobre la misma pregunta central: dado el contexto, ¿qué viene a continuación?"
        },
        // DEPRECATED: sección tokens movida a ngramNarrative.tokenization
        // Se mantiene aquí solo para compatibilidad hacia atrás - ya no se renderiza en la UI de BigramNarrative
        tokens: {
            label: "Representación",
            title: "Representando texto",
            lead: "Dividimos el texto en tokens.",
            charTitle: "Caracteres:",
            charDesc: "vocabulario pequeño, fácil de ver.",
            wordTitle: "Palabras:",
            wordDesc: "más expresivas, vocabulario enorme.",
            note: "Usamos caracteres aquí.",
            charLevelTitle: "Tokens a nivel de carácter",
            charLevelBody: "Vocabulario pequeño y fijo de ~96 símbolos ASCII imprimibles. Toda entrada posible es representable. Simple de implementar y visualizar — ideal para entender los fundamentos del modelado de lenguaje.",
            wordLevelTitle: "Tokens a nivel de palabra",
            wordLevelBody: "Unidades semánticas más ricas que transmiten más significado por token. Pero el vocabulario puede alcanzar 50.000–500.000 entradas, haciendo la matriz de transición enorme. Las palabras raras causan escasez; las palabras no vistas durante el entrenamiento causan fallos completos en inferencia.",
            charLimitations: "Los modelos a nivel de carácter tienen un vocabulario pequeño y manejable — pero deben aprender todo desde cero. No hay nociones preconstruidas de palabras, morfología o significado. El modelo debe descubrir que 't', 'h', 'e' juntos forman una palabra común puramente a partir de estadísticas de co-ocurrencia.",
            wordLimitations: "Los modelos a nivel de palabra son más expresivos pero enfrentan un problema fundamental de escalabilidad. El inglés tiene más de 170.000 palabras de uso común. Un modelo bigrama a nivel de palabra necesitaría una matriz de transición de 170.000 × 170.000 — casi 29.000 millones de celdas — la mayoría vacías. Este problema de escasez es una de las principales motivaciones para los modelos de lenguaje neurales.",
            whyCharHere: "Para este laboratorio, usamos tokens a nivel de carácter. El vocabulario se mantiene lo suficientemente pequeño como para visualizar toda la matriz de transición a la vez, haciendo el conocimiento aprendido del modelo directamente inspeccionable. Cada decisión de diseño que ves aquí escala directamente a modelos a nivel de palabra y subpalabra — solo cambia el tamaño del vocabulario."
        },
        counting: {
            title: "La idea Bigrama",
            lead: "Contar pares: actual -> siguiente. Más conteos = más probable.",
            builderTitle: "Constructor paso a paso",
            builderDesc: "Recorre el texto; cada par añade +1 a una celda.",
            p1: "La operación central es casi vergonzosamente simple: recorre el texto de entrenamiento un carácter a la vez, y para cada par consecutivo (carácter actual → siguiente carácter), incrementa un contador. Eso es todo. Después de escanear millones de caracteres, estos conteos codifican la estructura estadística del lenguaje.",
            p2: "El constructor paso a paso a continuación hace esto concreto. Observa cómo cada par de caracteres en el texto de entrada añade exactamente un conteo a la celda correspondiente en la matriz.",
            calloutTitle: "Por qué funciona el conteo",
            calloutText: "La Ley de los Grandes Números garantiza que a medida que crecen los datos de entrenamiento, las frecuencias observadas convergen a las probabilidades subyacentes reales del lenguaje."
        },
        matrix: {
            title: "La tabla de transición",
            lead: "Filas = token actual, columnas = siguiente.",
            desc: "Construye abajo, luego ve la matriz completa."
        },
        probabilities: {
            title: "Conteos a probabilidades",
            lead: "Normaliza cada fila al 100%.",
            desc: "El modelo lee la fila del último token y muestrea el siguiente.",
            inferenceIntro: "La herramienta a continuación te permite recorrer este proceso de inferencia paso a paso: elige cualquier carácter de contexto, selecciona cómo normalizar su fila — división simple o softmax — y luego muestrea para ver qué carácter predice el modelo. Prueba varios caracteres y observa cómo cambia la distribución según lo que el modelo vio más a menudo en el entrenamiento.",
            overlayTitle: "Conteos -> Probabilidades -> Muestreo",
            overlayDesc: "Elige token, normaliza fila, muestrea el siguiente.",
            step1: "1) Valores de fila",
            step2: "2) Normalizar",
            step3: "3) Muestrear siguiente token",
            currentToken: "Token actual",
            typeChar: "Escribe un carácter",
            normalizeSimple: "Normalización simple",
            softmax: "Softmax",
            sampleNext: "Muestrear siguiente token",
            mostLikely: "Más probable:",
            remaining: "Restante:",
            stochastic: "El muestreo es aleatorio."
        },
        limitations: {
            title: "Limitaciones",
            lead: "El Bigrama no tiene memoria—solo el último token.",
            desc: "Sin contexto largo. De ahí los N-gramas y las redes neuronales."
        },
        textToNumbers: {
            label: "Cómo los Ordenadores Ven el Texto",
            title: "Convirtiendo Texto en Números",
            lead: "Un ordenador no puede leer letras como tú. Necesita números que pueda almacenar y comparar.",
            p1: "Damos a cada carácter un número, como un número de asiento en un teatro. Ahora el modelo puede contar qué asiento numerado tiende a venir después.",
            bridge: "Una vez que el texto se convierte en números, podemos construir una tabla de conteos. Luego podemos convertir esa tabla en probabilidades para la siguiente letra.",
        },
        predictionExample: {
            label: "Véalo en acción",
            title: "Una predicción, paso a paso",
            lead: "Antes de explicar la matemática, veamos al modelo hacer una sola predicción. Elige cualquier carácter abajo.",
            inputLabel: "entrada",
            lookupLabel: "el modelo busca",
            step1: "Elige un carácter",
            step2: "Fila '{char}' en la tabla",
            step3: "Mejores predicciones",
            hint: "Haz clic en cualquier carácter para ver qué predice el modelo a continuación.",
        },
        predictionChallenge: {
            label: "Inténtalo",
            title: "¿Puedes pensar como el modelo?",
            lead: "Antes de revelar cómo funciona el modelo bigrama, intenta predecir qué viene después por ti mismo. Usa tu intuición del inglés.",
            prompt: "¿Qué carácter viene después?",
            score: "Puntuación",
            correct: "¡Correcto!",
            wrong: "La respuesta era '{answer}' —",
            next: "Siguiente →",
            finish: "Ver resultados →",
            perfect: "¡Puntuación perfecta! Piensas igual que el modelo.",
            good: "Buen trabajo — tu intuición coincide con las estadísticas.",
            tryAgain: "Los patrones del lenguaje pueden ser complicados. ¡Inténtalo de nuevo!",
            restart: "Intentar de nuevo",
        },
        cliffhanger: {
            label: "La Trampa",
            title: "Un Gran Problema",
            lead: "Este modelo solo recuerda una letra. Esa es una memoria muy pequeña.",
            p1: "Si ves 't' y luego 'h', quieres que el modelo recuerde ambas. Pero un modelo bigrama olvida la 't' en cuanto ve la 'h'.",
            hookLine: "¿Qué ocurre si dejamos que el modelo recuerde más de una letra?",
        },
        cta: {
            title: "Continuar Explorando",
            freeLabButton: "Abrir Lab Libre",
            freeLabDesc: "Cambia al modo Lab Libre para cambiar N, probar tus propias frases y ver dónde el modelo se queda en silencio.",
            nextTitle: "Siguiente: ¿Y si Recordamos Más?",
            nextDesc: "Conoce el modelo N-gram — una máquina de predicción que mira los últimos caracteres, no solo uno.",
        },
        footer: {
            text: "A continuación, haremos crecer esta idea hacia un modelo N-gram — una versión extendida que recuerda más de un carácter anterior.",
            brand: "LM-Lab · Modo Educativo"
        }
    },
    bigramBuilder: {
        description: "Construimos la matriz bigrama escaneando el texto carácter por carácter. Por cada par de caracteres consecutivos (actual → siguiente), incrementamos la celda [actual, siguiente]. Esta tabla captura con qué frecuencia un carácter es seguido por otro.",
        placeholder: "Escribe texto aquí...",
        hint: "Introduce algún texto para ver cómo se construye la matriz bigrama.",
        buttons: {
            build: "Construir Matriz",
            next: "Siguiente Paso",
            autoPlay: "Auto-Reproducir",
            pause: "Pausar",
            instant: "Completar",
            reset: "Reiniciar"
        },
        vocab: "Vocabulario educativo",
        normalized: "Texto normalizado:",
        empty: "(vacío tras filtrar)",
        skipped: "Mostrando los primeros {max} caracteres únicos por claridad (omitiendo {count} carácter(es) único(s)).",
        step1: "Paso",
        step2: "actualiza celda [",
        step3: "].",
        currentStep: "Paso Actual",
        updatingCell: "Actualizando celda en fila",
        updatingCellCol: "col",
        pressBuild: "Pulsa Construir Matriz y empieza a iterar sobre los pares de caracteres.",
        table: {
            curnxt: "act \\ sig"
        }
    },
    bigramWidgets: {
        nnComparison: {
            title: "Interactivo · Bigrama vs. Red Neuronal",
            bigramTitle: "Probabilidades del Bigrama (contando)",
            neuralTitle: "Pesos de la Red Neuronal (aprendido)",
            stats: {
                steps: "Pasos de entrenamiento:",
                distance: "Distancia:",
                match: "✓ Los pesos neuronales coinciden estrechamente con las probabilidades del bigrama"
            },
            buttons: {
                train: "Entrenar 1 Paso",
                auto: "Auto-Entrenar ×20",
                reset: "Reiniciar"
            },
            caption: "La red neuronal aprende pesos que convergen a las mismas probabilidades de transición que el modelo bigrama calcula al contar.",
            progression: "Instantáneas:",
            live: "En vivo",
            emotionalMoment: "Estos números aleatorios, entrenados con nada más que descenso de gradiente, aprendieron exactamente lo que el conteo nos dio.",
        },
        textToNumbers: {
            placeholder: "Escribe algo…",
            empty: "Empieza a escribir para ver los códigos de los caracteres…",
            tooltip: "código:"
        },
        pairHighlighter: {
            hint: "Pasa el ratón sobre un carácter para ver su par bigrama"
        },
        memoryLimit: {
            context: "Contexto:",
            chars: "caracteres",
            locked: "bloqueado",
            modelSees: "El modelo ve:",
            guessingNext: "adivinando el siguiente…",
            lockedNote: "Contexto-{size} disponible en el capítulo N-gram",
            ngramLink: "Modelo N-gram →",
            topPredictions: "Principales predicciones",
            correctAnswer: "Respuesta correcta \"{target}\" en el puesto #{rank}"
        },
        matrixOverlay: {
            dismiss: "Haz clic para descartar",
            after: "Después de",
            mostCommon: "el carácter siguiente más común es",
            tryHovering: "— intenta pasar el ratón sobre la fila",
            inMatrix: "en la matriz de abajo.",
            clickToDismiss: "clic para descartar"
        },
        heroAutoComplete: {
            placeholder: "e",
            after: "Después de “{input}”, probable sigue",
            hint: "Escribe un carácter para ver predicciones"
        },
        softmax: {
            title: "Temperatura Softmax · Conceptual",
            description: "La temperatura rediseña la distribución de probabilidad sin cambiar el ranking de los tokens. La temperatura baja agudiza la distribución; la temperatura alta la aplana.",
            label: "Temperatura",
            deterministic: "Determinista",
            neutral: "Neutral",
            chaotic: "Caótico",
            mode: {
                deterministic: { label: "Determinista", sub: "Siempre elige el token superior. Sin creatividad." },
                conservative: { label: "Conservador", sub: "Principalmente elige los tokens superiores con variedad ocasional." },
                neutral: { label: "Neutral", sub: "Muestreo estándar — equilibrio entre calidad y diversidad." },
                creative: { label: "Creativo", sub: "Explora opciones menos probables. Salida más sorprendente." },
                chaotic: { label: "Caótico", sub: "Casi uniforme — elige casi cualquier token al azar." },
            },
            presets: {
                deterministic: "Determinista",
                balanced: "Equilibrado",
                neutral: "Neutral",
                creative: "Creativo",
            },
            stats: {
                topToken: "Token superior",
                entropy: "Entropía",
                spread: "Dispersión",
                max: "del máx",
            },
            note: "La temperatura no cambia el conocimiento del modelo — solo cuán aleatoriamente muestrea de lo que sabe. El ranking de tokens sigue siendo el mismo; solo cambia la nitidez de la distribución.",
        }
    },
    ngramNarrative: {
        hero: {
            eyebrow: "Comprendiendo los Modelos de Lenguaje",
            titlePrefix: "¿Y si",
            titleSuffix: "recordamos más?",
            description: "El modelo bigrama solo podía mirar un carácter atrás. ¿Qué sucede cuando le damos dos? ¿Tres? ¿Cinco? La respuesta es tan fascinante como devastadora.",
        },
        moreContext: {
            label: "Más contexto",
            title: "Más allá de un solo carácter",
            lead: "Has visto que el modelo bigrama solo puede mirar un carácter atrás. ¿Y si le dejamos mirar dos? ¿Tres? ¿Cinco?",
            p1: "Un modelo N-grama mira los",
            p1Highlight: "N caracteres anteriores",
            p1End: " antes de adivinar el siguiente. Ejemplo: N=2 significa que puede ver dos caracteres de contexto.",
            p2: "Más contexto hace que las conjeturas sean más inteligentes. Después de \"qu\", el modelo puede esperar fuertemente una \"e\" — ha visto ese patrón muchas veces.",
            p3: "Pero más memoria tiene un coste oculto. Estamos a punto de observar cómo ese coste crece más rápido de lo que dicta tu intuición.",
            calloutTitle: "La suposición N-grama",
            calloutText: "La suposición clave: el siguiente carácter depende solo de los N caracteres anteriores. Todo lo anterior se olvida. Es como una ventana deslizante — y la pregunta es: ¿cuánto debe medir?",
        },
        contextWindow: {
            label: "Ventana de contexto",
            title: "Viendo más del pasado",
            lead: "La ventana de contexto es cuántos caracteres anteriores puede \"ver\" el modelo antes de hacer una conjetura.",
            caption: "A medida que la ventana se hace más grande, el modelo puede usar patrones más ricos. Pero el número de ventanas posibles crece extremadamente rápido.",
            hint: "Observa cómo crece el contexto a medida que aumenta N.",
            p1: "Cada aumento en N le da al modelo más pistas. También crea muchas más situaciones que el modelo podría necesitar recordar después.",
        },
        howItWorks: {
            label: "Mecánica",
            title: "Contando con contexto",
            lead: "El proceso de conteo es el mismo que en los bigramas — pero ahora, en lugar de contar parejas, contamos grupos más largos: el contexto de N caracteres más lo que viene después.",
            p1: "Para cada posición en el texto de entrenamiento, el modelo toma el",
            p1Highlight: "contexto de N caracteres",
            p1End: " y cuenta qué carácter le sigue. Después, usa esos conteos como una tabla de búsqueda: encuentra el contexto y lee el carácter siguiente habitual.",
            p2: "A medida que N crece, la tabla de conteo gana dimensiones. Con N=1 (bigrama), es una cuadrícula simple. Con N=2, imagina una pila de cuadrículas — una para cada contexto posible de dos caracteres. La tabla crece en todas direcciones.",
            bridge: "La tabla de transición anterior muestra filas individuales de esta tabla de búsqueda gigante. Pero, ¿cómo cambian realmente los conteos con contextos más largos? El widget de abajo compara el conteo de bigramas y trigramas lado a lado sobre el mismo texto de entrenamiento para que veas la diferencia directamente.",
        },
        improvement: {
            label: "Mejora",
            title: "La predicción se vuelve mejor",
            lead: "Aquí está la recompensa. Cuando el modelo ve más contexto, sus conjeturas se vuelven mucho más seguras y correctas.",
            example: "Después de \"h\", la siguiente letra no está clara. Después de \"th\", la \"e\" se vuelve muy probable. Después de \"the\", un espacio se vuelve muy probable.",
        },
        whyNotMore: {
            title: "¿Por qué no N=100?",
            lead: "Si más contexto mejora las predicciones, ¿por qué parar en 3 o 4? ¿Por qué no mirar los últimos 100 caracteres?",
            p1: "Porque cada carácter extra de contexto multiplica la tabla por el tamaño del vocabulario. Una tabla de bigrama tiene 9,216 entradas (96²). Un trigrama salta a 884,736 (96³). Un 4-grama alcanza más de 84 millones (96⁴). Ir a N=100 requeriría una tabla con más entradas que átomos en el universo observable. La siguiente sección hace esta explosión visceral.",
        },
        statistical: {
            label: "Naturaleza Estadística",
            title: "Un Modelo Puramente Estadístico",
            lead: "Los modelos N-gram no entienden el lenguaje. Son máquinas de conteo sofisticadas.",
            p1: "Cada predicción es una",
            p1Highlight: "búsqueda en tabla",
            p1End: " — el modelo encuentra el contexto coincidente en su tabla y devuelve la distribución de probabilidad almacenada. No hay parámetros aprendidos, ni gradientes, ni optimización.",
            p2: "Esto hace que los N-gramas sean extremadamente rápidos en inferencia y trivialmente interpretables: siempre puedes preguntar \"¿por qué el modelo predijo X?\" y rastrear la respuesta hasta ejemplos exactos de entrenamiento.",
            calloutTitle: "Sin Generalización",
            calloutText: "Si el modelo nunca ha visto un contexto particular en el entrenamiento, tiene cero información sobre lo que viene después. A diferencia de las redes neuronales, los N-gramas no pueden generalizar a partir de contextos similares — cada contexto se trata como completamente independiente.",
        },
        complexity: {
            label: "Complejidad",
            title: "El precio de la memoria",
            lead: "Aquí es donde las matemáticas se vuelven contra nosotros.",
            p1: "Con 96 caracteres posibles, cada carácter extra de contexto multiplica la tabla por 96. N=1: 96 contextos. N=2: 9.216. N=3: 884.736. N=4: 85 millones. N=5: más de 8 mil millones.",
            p1Highlight: " 884.736",
            p1End: ". Un 5-grama tiene más de 84 millones. La mayoría de estos contextos nunca aparecerán en ningún corpus de entrenamiento realista.",
            p2: "La mayoría de esos contextos nunca aparecen en texto real. Eso significa que la mayor parte de la tabla está vacía — esto se llama dispersión (sparsity) — y las filas vacías no pueden guiar las predicciones.",
            vocabCalloutTitle: "Y empeora mucho más con palabras",
            vocabCalloutText: "Este laboratorio usa caracteres (~96 posibles). Los modelos de lenguaje reales usan palabras en su lugar. Con 50.000 palabras, incluso una matriz de bigramas necesita 2.500 millones de celdas. Una tabla de trigramas necesitaría 125 billones. Las matemáticas se vuelven catastróficas extremadamente rápido.",
            comparisonLabel: "Comparativa N-Gram · Métricas del backend en vivo",
            comparisonHint: "Compara perplejidad, utilización de contexto y espacio de estados entre diferentes valores de N.",
            metricsLegend: {
                perplexity: "La perplejidad significa \"qué tan sorprendido está el modelo\" en promedio; cuanto más baja, mejores conjeturas y más confianza.",
                utilization: "La utilización del contexto indica qué parte de la enorme tabla se llenó realmente con el texto de entrenamiento; una utilización baja significa que muchos contextos nunca se vieron.",
                contextSpace: "El espacio de contexto indica cuántos contextos diferentes podrían existir en teoría; crece extremadamente rápido a medida que aumenta N.",
            },
        },
        tokenization: {
            intro: "Esta complejidad se vuelve catastrófica cuando pasamos de caracteres a palabras.",
            subsectionTitle: "Caracteres vs. Palabras: Un compromiso crítico",
            charTitle: "Tokens a nivel de carácter",
            charDesc: "Vocabulario pequeño y fijo (~96 caracteres ASCII). Toda entrada es representable. Simple de implementar y visualizar — ideal para comprender los fundamentos. Pero cada token casi no lleva significado semántico.",
            charExample: "Vocab: ~96 | Ejemplo: ['e', 'l', ' ']",
            wordTitle: "Tokens a nivel de palabra",
            wordDesc: "Unidades semánticamente ricas que transmiten significado por token. Pero el vocabulario explota a 50.000–500.000 entradas, haciendo la matriz de transición enorme. Las palabras raras causan dispersión; las palabras no vistas causan fallo completo.",
            wordExample: "Vocab: ~50.000 | Ejemplo: ['el', 'gato', 'se']",
            explosionIntro: "La explosión combinatoria a nivel de palabra hace que incluso los N-gramas simples sean computacionalmente inviables:",
            tableLabel: "Explosión N-gram a nivel de palabra · Matemática combinatoria",
            tableHint: "Asumiendo vocabulario básico de inglés de 50.000 palabras. La mayoría de las celdas estarían vacías (dispersas).",
            tableHeaders: {
                model: "Modelo",
                formula: "Fórmula",
                combinations: "Combinaciones",
                scientific: "Científico",
            },
            noteLabel: "Nota:",
            noteText: "Estos números asumen un vocabulario completo de 50.000 palabras en inglés. Los sistemas reales usan estrategias agresivas de poda, suavizado y retroceso para hacer esto manejable — pero el problema fundamental de escalado permanece.",
            languageP1: "Los modelos a nivel de palabra también son",
            languageH1: "rígidamente dependientes del idioma",
            languageP2: ". Un modelo tokenizado para palabras en inglés falla completamente cuando recibe entrada en español, requiriendo un vocabulario y matriz completamente nuevos. Los modelos a nivel de carácter, aunque menos ricos semánticamente por token, pueden manejar múltiples idiomas que comparten el mismo alfabeto.",
            multilingualCalloutTitle: "El problema multilingüe",
            multilingualCalloutText: "Un bigrama a nivel de palabra en inglés entrenado con 'the cat sat' no tiene idea qué hacer con 'el gato se sentó'. Cada palabra está fuera del vocabulario. Los modelos de caracteres evitan esto operando a un nivel más bajo y universal — aunque sacrifican densidad semántica en el proceso.",
        },
        vocabulary: {
            label: "Vocabulario",
            title: "Caracteres vs. Palabras",
            lead: "Usamos tokens a nivel de carácter en este laboratorio, pero los N-gramas del mundo real a menudo operan con palabras — haciendo la explosión aún peor.",
            p1: "Con un vocabulario de 50.000 tokens, incluso una",
            p1Highlight: " matriz bigrama necesita 2.500 millones de celdas",
            p1End: ". Una tabla de trigramas requeriría 125 billones de entradas. Por eso los N-gramas a nivel de palabra más allá de N=3 son esencialmente impracticables sin suavizado y poda agresivos.",
            p2: "Los modelos a nivel de carácter mantienen el vocabulario pequeño (~96), haciendo factible visualizar y explorar la tabla completa. Pero el compromiso es que los caracteres individuales casi no portan significado semántico.",
        },
        noUnderstanding: {
            label: "Limitaciones",
            title: "Sin verdadera comprensión",
            lead: "Los modelos N-gram capturan patrones de co-ocurrencia local pero no tienen noción de significado, gramática o coherencia de largo alcance.",
            p1: "El modelo trata \"el gato se sentó en\" y \"el perro se sentó en\" como contextos completamente no relacionados (para N < longitud de la oración). No puede reconocer que ambos involucran un animal sentado sobre algo.",
            p2: "Esta incapacidad de",
            p2Highlight: "generalizar entre contextos similares",
            p2End: " es lo que finalmente limita los modelos N-gram. Sin importar cuántos datos recojas, siempre habrá contextos válidos que el modelo nunca ha visto.",
            p3: "Esta limitación fundamental es exactamente lo que motiva la transición a enfoques neuronales — modelos que aprenden representaciones densas y continuas capaces de reconocer similitud entre contextos.",
        },
        deeperProblem: {
            label: "Limitaciones",
            title: "El problema más profundo",
            lead: "La explosión es un problema práctico — no puedes construir una tabla lo suficientemente grande. Pero hay un problema conceptual aún peor: incluso con datos infinitos, el conteo sigue fallando.",
            p1: "Imagina que el texto empieza con \"el gato se sentó en\". Si el modelo ha visto ese contexto exacto, puede predecir lo que sigue desde la memoria.",
            p2: "Ahora cambia una palabra: \"el perro se sentó en\". Un humano ve que es casi lo mismo. El modelo N-gram lo trata como una situación totalmente nueva.",
            p3: "Los N-gramas no tienen concepto de 'similar'. Los contextos 'el gato' y 'el perro' son tan distintos para el modelo como 'el gato' y 'xyzq'. Cada uno es una fila separada en la tabla, sin conexión.",
            infiniteData: {
                title: "Ni siquiera datos infinitos pueden ayudar",
                p1: "Supón que tuvieras texto de entrenamiento ilimitado — cada libro jamás escrito. ¿Podrías llenar la tabla? No. El lenguaje es creativo: la gente inventa oraciones nuevas constantemente. El número de secuencias posibles de 10 palabras supera con creces el número de oraciones jamás pronunciadas. Ningún corpus, por grande que sea, puede cubrir cada contexto válido.",
            },
            failureExamples: {
                title: "Cuando el conteo falla",
                typoLabel: "Errores tipográficos",
                typoText: "Un usuario escribe 'teh cat' en lugar de 'the cat'. El modelo nunca ha visto el contexto 'teh' y devuelve una distribución uniforme (aleatoria). Una tecla equivocada borra todo el conocimiento aprendido.",
                novelLabel: "Palabras nuevas",
                novelText: "Una palabra nueva entra al idioma — 'selfie', 'blockchain', 'vibe-check'. El modelo tiene cero entradas para cualquier contexto que contenga estas palabras. Ni siquiera puede adivinar que 'selfie' se comporta como otros sustantivos.",
            },
            calloutTitle: "Sin generalización",
            calloutText: "Si el modelo nunca ha visto una secuencia particular en el entrenamiento, no tiene nada que decir. No puede adivinar. No puede razonar por analogía. Simplemente se encoge de hombros. Esta es la limitación fundamental que motiva los enfoques neuronales.",
        },
        endOfCounting: {
            label: "Reflexión",
            title: "El Fin del Conteo",
            lead: "Hemos llegado al límite de lo que el conteo puede hacer.",
            p1: "Empezamos con bigramas, que recuerdan un carácter. Pasamos a N-gramas, que recuerdan más, y vimos mejorar las predicciones.",
            p2: "Luego nos topamos con dos muros. El muro de la explosión: la tabla crece demasiado rápido para llenarse. Más memoria multiplica la tabla una y otra vez.",
            p3: "El muro de la generalización: cada contexto es una isla. El modelo no puede compartir conocimiento entre contextos similares, por lo que falla con frases nuevas.",
            quote: "La era del conteo ha terminado. La era del aprendizaje comienza.",
            hookLine: "En el próximo capítulo, dejamos de contar. Empezamos a aprender.",
        },
        conclusion: {
            label: "Reflexión",
            title: "El Puente hacia Modelos Neuronales",
            lead: "Los modelos N-gram llevan el modelado estadístico del lenguaje a su extremo lógico — y revelan por qué se necesita un enfoque fundamentalmente diferente.",
            p1: "Hemos visto que aumentar el contexto mejora las predicciones pero desencadena una explosión exponencial en el espacio de estados. Esto no es un error — es una propiedad inherente de los modelos discretos basados en conteo.",
            p2: "El problema central es la representación: los N-gramas representan cada contexto como un punto aislado en un vasto espacio discreto. No hay noción de similitud entre contextos, no hay forma de compartir fuerza estadística entre patrones relacionados.",
            p3: "Los modelos neuronales de lenguaje resuelven esto mapeando tokens discretos en espacios vectoriales continuos donde contextos similares viven cerca unos de otros. Esto les permite generalizar de ejemplos vistos a contextos no vistos pero similares.",
            p4: "La progresión de Bigrama → N-gram → Red Neuronal no es solo histórica — refleja una comprensión cada vez más profunda de lo que significa modelar el lenguaje computacionalmente.",
            quote: "La maldición de la dimensionalidad no es un fallo de los N-gramas — es la razón por la que se inventaron las representaciones neuronales.",
        },
        cta: {
            title: "Continúa Explorando",
            labButton: "Abrir Lab Libre",
            labDesc: "Cambia al modo Lab Libre para acceso completo a la consola de inferencia N-gram, predictor paso a paso y generador de texto con tamaño de contexto ajustable.",
            neuralButton: "Siguiente: Del Conteo al Aprendizaje",
            neuralDesc: "Hemos llevado el conteo a su límite. Ahora construimos algo que aprende.",
        },
        generationBattle: {
            title: "Batalla de Generación",
            subtitle: "Misma semilla, diferente memoria",
            description: "Observa cómo el mismo texto inicial produce resultados dramáticamente diferentes a medida que crece la ventana de contexto del modelo.",
            columnHeader: "N = {n}",
            qualityLabels: {
                1: "Ruido aleatorio",
                2: "Emergen patrones de letras",
                3: "Aparecen fragmentos de palabras",
                4: "Frases reconocibles",
            },
            streaming: "Generando…",
            seedLabel: "Texto semilla",
            generateButton: "Generar Todo",
            regenerateButton: "Regenerar",
            tokensLabel: "{count} caracteres",
            emptyState: "Presiona Generar para iniciar la batalla",
            temperatureLabel: "temperatura",
            copyToClipboard: "Copiar al portapapeles",
        },
        footer: {
            text: "La era estadística ha terminado. Has visto lo que el conteo puede hacer — y dónde se rompe. Siguiente: modelos que aprenden.",
            brand: "LM-Lab · Modo Educativo",
        },
        predictingAfter: "Prediciendo el siguiente carácter después de:",
        readingChart: "Leyendo el gráfico",
        ui: {
            collapse: "contraer",
            expand: "expandir",
        },
        figures: {
            contextWindow: {
                label: "Ventana de contexto · Ejemplo de lenguaje natural",
                predictingAfter: "Prediciendo el siguiente carácter después de:",
                sees: "ve:",
                next: "¿siguiente?",
                contextSize: "Tamaño de contexto:",
                modelBestGuess: "Mejor predicción del modelo",
                confident: "{pct}% de confianza",
                candidates: "Candidatos:",
                n1hint: "Con solo 1 carácter, el modelo ve solo \"a\" — demasiado poco para reducir las opciones.",
                n2hint: "Dos caracteres dan \"za\" — aún ambiguo, pero empezando a formar patrones.",
                n3hint: "Tres caracteres revelan \"zza\" — el modelo empieza a reconocer fragmentos de palabras.",
                n4hint: "Cuatro caracteres muestran \"izza\" — señal fuerte de que probablemente es \"pizza\".",
                n5hint: "Cinco caracteres capturan \"pizza\" — el modelo sabe exactamente qué viene después.",
            },
            transitionExamples: {
                label: "Ejemplos de transición · Evidencia del corpus de entrenamiento",
                hint: "Amplía cualquier fila para ver pasajes reales del corpus donde se observó esta transición.",
            },
            countingComparison: {
                label: "Comparación de conteo · Bigrama vs. Trigrama",
                hint: "Mismo texto de entrenamiento, diferente granularidad. Observa cómo contextos más largos producen conteos más específicos.",
            },
            confidenceImprovement: {
                label: "Mejora de la confianza · Efecto de la longitud del contexto",
                hint: "Cada carácter extra de contexto agudiza la predicción.",
            },
            exponentialGrowth: {
                label: "Crecimiento exponencial · Tamaño de la tabla por N",
                hint: "Cada paso multiplica el conteo anterior por el tamaño del vocabulario.",
            },
            generalizationFailure: {
                label: "Fallo de generalización · Gato vs. Perro",
                hint: "Pasa el ratón por la columna derecha para ver qué devuelve el modelo para un contexto no visto.",
            },
            statisticalEra: {
                label: "Era estadística · Ruta de aprendizaje",
                hint: "La era del conteo ha terminado. Lo siguiente es algo fundamentalmente diferente.",
            },
            generationBattle: {
                label: "Batalla de generación · Comparación lado a lado",
                hint: "Cada columna usa el mismo texto semilla pero un tamaño de contexto diferente. Un contexto más largo produce resultados más coherentes — hasta que la dispersión toma el control.",
            },
            sparsityHeatmap: {
                label: "Mapa de dispersión · Densidad de tabla por N",
                hint: "Cambia entre valores de N para ver qué tan rápido se vacía la tabla de probabilidades.",
            },
            infiniteTable: {
                label: "Cobertura de datos · El problema de datos infinitos",
                hint: "Arrastra el deslizador para ver cuánto de cada tabla N-grama se puede llenar con datos de entrenamiento reales.",
            },
            typoBreaker: {
                label: "Rompe el modelo · Fallo con errores tipográficos y palabras nuevas",
                hint: "Escribe una palabra mal escrita o nueva para ver cómo el modelo N-grama pierde toda confianza.",
            },
        }
    },
    ngramPedagogy: {
        primer: {
            title: "¿Qué es un {name}?",
            isEdu: {
                p1: "Imagina que intentas adivinar la siguiente letra que alguien escribirá. Un modelo <0>{name}</0> mira las últimas <1>{length}</1> letra{suffix} y pregunta: <2>\"Basado en lo que acabo de ver, ¿qué suele venir después?\"</2>",
                n1: "Con solo 1 carácter de memoria, el modelo esencialmente adivina a ciegas basándose solo en la frecuencia.",
                n2: "Dos caracteres de contexto son suficientes para aprender patrones simples como 'qu' → 'e', 'u', pero no mucho más.",
                nSmall: "Con {n} caracteres, el modelo comienza a capturar fragmentos de palabras cortos — pero el número de contextos posibles ya es {count}.",
                nLarge: "En N={n}, el modelo teóricamente tiene un rico contexto local — pero almacenar cada combinación posible de {n} caracteres requiere miles de millones de entradas."
            },
            isFree: {
                p1: "Un {name} condiciona sobre los últimos <0>{length}</0> token{suffix}. El espacio de contexto crece como |V|<sup>{n}</sup>."
            },
            liveWindow: "Ventana de contexto en vivo"
        },
        growth: {
            title: "Crecimiento de contexto",
            body: "Mira cómo la ventana de historia visible se expande a medida que aumenta N. Más contexto permite suposiciones más certeras — pero también implica exponencialmente más posibilidades."
        },
        transitions: {
            title: "Ejemplos de transición",
            isEduBody: "En lugar de una tabla gigante, tracemos algunas transiciones a través de la frase <0>the qui</0>. Cada fila muestra: \"dado este contexto, el siguiente carácter fue...\" — además de evidencia real del corpus de entrenamiento.",
            isFreeBody: "Ejemplos de transición de <0>the qui</0> con evidencia del corpus.",
            matches: "{count} coincidencia{suffix}",
            searching: "Buscando datos de entrenamiento...",
            noMatches: "No se encontraron coincidencias en el corpus de muestra.",
            corpusEvidence: "Evidencia del corpus",
            noMatchesExpanded: {
                title: "Sin coincidencias en la muestra",
                explanation: "La muestra del corpus de entrenamiento no contiene esta transición exacta. Esto es esperado — no todos los N-gramas posibles aparecen en un corpus finito. Este es el problema de la dispersión.",
                hint: "Intenta expandir una fila diferente, o reduce N para ver más coincidencias.",
            },
        },
        explosion: {
            title: "Explosión Combinatoria",
            body1: "Un modelo {n}-gram con V={vocabSize} caracteres necesitaría almacenar probabilidades para cada contexto posible de {n} caracteres. Eso es:",
            entries: "{count} entradas",
            body2: "Más de {billionCount} combinaciones. La mayoría nunca se observarían en los datos de entrenamiento, haciendo la tabla astronómicamente dispersa e impráctica.",
            limitReached: "Límite de escalado clásico alcanzado"
        },
        comparison: {
            title: "Comparación de modelos",
            isEduBody: "A medida que N crece, la perplejidad baja (el modelo mejora prediciendo localmente) — pero la utilización del contexto se desploma porque la mayoría de los contextos posibles nunca se ven en el entrenamiento.",
            isFreeBody: "Métricas del backend por N. Menor perplejidad = mejor ajuste local.",
            quality: "Calidad (↑ = menor ppl)",
            utilization: "Utilización"
        },
        limitations: {
            title: "Limitaciones clave",
            items: {
                context: {
                    title: "Contexto limitado",
                    isEdu: "Incluso con N=5, el modelo olvida todo lo anterior a esos 5 caracteres. Nunca podrá aprender que un párrafo trata sobre cocina solo porque vio la palabra 'receta' diez oraciones atrás.",
                    isFree: "Incluso N=5 captura solo 5 tokens de historia. Las dependencias a largo plazo permanecen invisibles."
                },
                scalability: {
                    title: "Escalabilidad exponencial",
                    isEdu: "Cada carácter extra de contexto multiplica el tamaño de la tabla por el tamaño del vocabulario (~96×). Pasar de N=3 a N=4 significa ~96× más filas que almacenar.",
                    isFree: "El espacio de contexto crece como |V|^N. Los requisitos de almacenamiento y datos se vuelven inmanejables para N > 4."
                },
                vocabulary: {
                    title: "Explosión de vocabulario",
                    isEdu: "Si usáramos palabras en lugar de caracteres, el vocabulario saltaría de ~96 a decenas de miles — haciendo que incluso una tabla de bigramas sea enorme.",
                    isFree: "Los N-gramas a nivel de palabra enfrentan tamaños de vocabulario de más de 50k, lo que hace que las tablas sean imprácticas incluso para N pequeñas."
                }
            }
        },
        story: {
            title: "La historia de los N-gramas",
            subtitle: "Por qué más contexto parecía la respuesta — y por qué no fue suficiente",
            steps: {
                s1: {
                    title: "El cuello de botella del bigrama",
                    body: "Empezamos con la idea más simple: predecir el siguiente carácter usando solo el anterior. Pero un modelo bigrama tiene la memoria de un pez — olvida inmediatamente todo excepto la última letra."
                },
                s2: {
                    title: "Una extensión natural",
                    body: "La solución obvia es mirar más historia. Un trigrama mira 2 caracteres anteriores, un 4-grama mira 3, y así sucesivamente. Cada paso le da al modelo un contexto local más rico y predicciones notablemente mejores."
                },
                s3: {
                    title: "El coste de la memoria",
                    body: "Pero hay un truco. Cada carácter extra de contexto multiplica el número de estados posibles por el tamaño del vocabulario. Un trigrama con 96 caracteres ya tiene 884.736 contextos posibles. La mayoría nunca se observan en el entrenamiento — la tabla se vuelve astronómicamente dispersa."
                },
                s4: {
                    title: "El muro de escalado",
                    body: "Para N=5, necesitaríamos más de 8 mil millones de entradas en la tabla. Ningún conjunto de datos es lo suficientemente grande como para llenar esa tabla de manera significativa. Esta es la razón fundamental por la que los N-gramas fueron finalmente reemplazados por modelos neuronales que pueden generalizar a través de contextos similares."
                }
            }
        }
    },
    challenge: {
        badge: "DESAFÍO",
        solvedBadge: "RESUELTO",
        checkButton: "Comprobar",
        skip: "Saltar",
        showHint: "Mostrar pista",
        hideHint: "Ocultar pista",
    },
    neuralNetworkNarrative: {
        sections: {
            discovery: { number: "01", label: "La Chispa" },
            fromNumbers: { number: "08", label: "Lenguaje" },
        },
        narratorTooltips: {
            learning: "Aprender = ajustar pesos para que las respuestas sean cada vez menos incorrectas.",
            weights: "Los pesos deciden cuánto importa cada entrada.",
            activation: "Una activación es la 'compuerta' no lineal que deja a las redes doblar líneas en curvas.",
            nonLinearity: "No linealidad = la razón por la que las redes profundas pueden hacer más que líneas rectas.",
            relu: "ReLU = max(0, x). Deja pasar lo positivo y corta lo negativo.",
            parameters: "Parámetros = los números que se aprenden (pesos + sesgos).",
            gradient: "Gradiente = hacia dónde está cuesta abajo (la dirección que reduce la pérdida más rápido).",
            loss: "Pérdida = qué tan equivocado está el modelo.",
            epoch: "Época = una pasada por todos los datos de entrenamiento.",
            batch: "Lote = un grupo pequeño de ejemplos procesados juntos.",
            step: "Paso = una actualización de pesos.",
            contextWindow: "Ventana de contexto = el fragmento de caracteres previos que el modelo puede ver.",
        },
        discovery: {
            heading: "Enseñemos a una Máquina a Aprender",
            lead: "El conteo chocó contra un muro. ",
            leadHighlight: "Los N-gramas no pueden compartir conocimiento entre patrones similares",
            leadEnd: " y sus tablas explotan con cada carácter extra de contexto. Necesitamos un enfoque completamente diferente — uno que no memorice, sino que descubra.",
            bigramBridge: "¿Recuerdas el modelo bigrama? Contaba cuántas veces una letra sigue a otra. Cuando escribías \"th\", buscaba cuántas veces aparecía cada letra después de \"th\" en el texto de entrenamiento. Pero por dentro, las letras son solo números — 't' podría ser 19, 'h' podría ser 7. El modelo bigrama no hacía matemáticas con esos números. Solo los usaba como direcciones dentro de una tabla gigante.",
            bigramQuestion: "¿Y si, en vez de una tabla de búsqueda, de verdad calculáramos algo con esos números? ¿Y si pudiéramos tomar los números de 't' y 'h', hacer un poco de matemáticas y obtener una predicción de lo que viene después?",
            letterDemoLabel: "Interactivo · De Letras a Números",
            letterDemoHint: "Elige un par de letras y observa cómo se convierten en números que atraviesan un cálculo simple. Esta es la idea central de una red neuronal.",
            hookP1: "La idea es esta: en lugar de una tabla gigante, le damos a la máquina unos pocos números que puede ajustar — y dejamos que ",
            hookP1Highlight: "aprenda mirando ejemplos",
            hookP1End: ". No memoriza frases enteras: aprende reglas simples que funcionan en muchos casos.",
            hookP2: "Imagina que quieres predecir cuánto tarda tu trayecto al colegio. Sabes dos cosas: la distancia (8 km) y el nivel de tráfico (3 en una escala de 1 a 10). Con solo esos dos números, ¿cómo harías una predicción del tiempo de viaje?",
            p1: "Empecemos con algo sencillo: toma 8 (distancia) y 3 (tráfico). Prueba distintas formas de juntarlos y mira cómo cambia el resultado.",
            fig1Label: "Interactivo · Explorador de Operaciones",
            fig1Hint: "Prueba cada operación. Observa cómo la suma ponderada te da más control — puedes ajustar cuánto contribuye cada entrada.",
            p2: "Ahora esos dos números representan mediciones reales de tu trayecto diario. La suma ponderada te da un tiempo de viaje predicho en minutos. Ajustando los pesos, controlas cuánto contribuye la distancia y el tráfico a la predicción.",
            fig2Label: "Interactivo · Deslizadores de Peso",
            fig2Hint: "Arrastra los pesos. Un peso de 2 significa que esa entrada importa el doble. Un peso de 0 la ignora por completo. Los pesos negativos invierten la contribución.",
            p3: "Los pesos pueden ser cualquier número — mayor que 2 o menor que −1 — solo limitamos el deslizador para que no se desmadren los números. Un peso alto en distancia significa que cada kilómetro suma mucho tiempo. Un peso negativo significaría que más distancia reduce el tiempo (físicamente absurdo — pero el modelo no sabe física, solo sigue las matemáticas).",
            p4: "Y un último truco. ¿Qué pasa si ambas mediciones son cero — vives en el colegio y no hay tráfico — pero aún necesitas 5 minutos para salir por la puerta? O al revés: incluso con un trayecto decente, siempre llegas temprano. Ese 'desplazamiento por defecto' es el sesgo: un empujón constante que mueve el tiempo predicho hacia arriba o hacia abajo.",
            fig3Label: "Interactivo · Añadiendo Sesgo",
            fig3Hint: "El sesgo desplaza toda la salida hacia arriba o abajo. Un sesgo positivo hace que la neurona sea 'ansiosa' — dispara incluso con entradas débiles. Un sesgo negativo la hace reticente.",
            calloutTitle: "Acabas de construir una neurona",
            calloutText: "Suma ponderada + sesgo. Eso es todo. Cada red neuronal del mundo — desde la más simple hasta GPT-4 — está construida con unidades que hacen exactamente esto. El resto es escala y arquitectura ingeniosa.",
            bridge: "Ya tienes una unidad de cómputo: entradas × pesos + sesgo = salida. Pero ahora mismo es solo una fórmula. Juntemos todas las piezas y veámosla funcionar.",
            letterDemo: {
                title: "De Letras a Números",
                step1: "Empieza con dos letras",
                step2: "Cada letra tiene un número (su posición en el alfabeto)",
                step3: "Ahora calcula: multiplica cada una por un peso y añade un sesgo",
                step4: "Este puntaje ayuda a predecir la siguiente letra",
                showComputation: "Ver el cálculo →",
                scoreFor: "puntaje de predicción para",
                insight: "Con pesos distintos obtendrías puntajes distintos. El trabajo de la red es encontrar pesos que produzcan buenas predicciones. Eso es aprender.",
            },
            operations: {
                title: "Explorador de Operaciones",
                inputLabel: "Entradas",
                addBtn: "Sumar",
                multiplyBtn: "Multiplicar",
                weightedSumBtn: "Suma Ponderada",
                resultPrefix: "Resultado",
                weightNote: "Los pesos están fijos en 1.0 por ahora — los controlarás en el siguiente paso.",
            },
            weights: {
                title: "Entradas Ponderadas",
                inputLabel1: "x₁ (distancia en km)",
                inputLabel2: "x₂ (nivel de tráfico)",
                weightLabel: "Peso",
                biasLabel: "desplazamiento por defecto",
                sumLabel: "Suma Ponderada",
                formula: "Tiempo de trayecto predicho",
                contributionLabel: "Desglose de contribuciones",
                outputLabel: "Tiempo predicho",
                hint: "Arrastra los pesos para ver cómo la importancia de cada entrada cambia la salida.",
            },
            bias: {
                title: "Añadiendo Sesgo",
                biasLabel: "Sesgo (b)",
                resultLabel: "Salida (z)",
                active: "Activa",
                barelyActive: "Apenas activa",
                inactive: "Inactiva",
                hint: "Sesgo positivo = ansiosa por disparar. Sesgo negativo = reticente.",
            },
            challenge1: {
                question: "Cambia a Suma Ponderada y pon x₁ = 8, x₂ = 3. ¿Qué resultado obtienes cuando ambos pesos son 1?",
                hint: "Con pesos en 1, la suma ponderada es simplemente una suma normal.",
                success: "¡Exacto! 1×8 + 1×3 = 11. Pesos en 1 significa que cada entrada contribuye por igual — igual que una suma normal.",
            },
            challenge2: {
                question: "Haz que el tráfico domine la predicción. ¿Puedes ajustar los pesos para que el tráfico represente aproximadamente el 70% del tiempo predicho?",
                hint: "Prueba a subir w₂ y bajar w₁. Compara las dos barras (w₁·x₁ vs w₂·x₂).",
                success: "Bien. Los pesos son controles de volumen: puedes hacer que un factor tape al otro. Eso es exactamente lo que hace una neurona cuando aprende qué importa.",
            },
            inputsFixedTitle: "Las entradas son datos, los pesos son aprendibles",
            inputsFixed: "Algo crucial: la distancia y el nivel de tráfico son mediciones — no puedes cambiarlas. Lo único que PUEDES cambiar son los pesos. Esta es la regla fundamental de las redes neuronales: las entradas son datos fijos, los pesos son las perillas que el modelo aprende a ajustar.",
            countingVsLearning: {
                title: "Contar vs Aprender",
                countingCol: "N-grama (Conteo)",
                learningCol: "Red Neuronal (Aprendizaje)",
                row1Label: "Cómo funciona",
                row1Counting: "Cuenta cuán a menudo aparecen los patrones en el texto",
                row1Learning: "Calcula una predicción usando pesos y entradas",
                row2Label: "Qué almacena",
                row2Counting: "Una tabla gigante de conteos — una entrada por patrón",
                row2Learning: "Un pequeño conjunto de números (pesos + sesgo) que codifican conocimiento",
                row3Label: "Patrones nuevos",
                row3Counting: "Si no ha visto el patrón, no tiene respuesta",
                row3Learning: "Puede hacer una estimación razonable combinando lo que sabe",
                row4Label: "Escalabilidad",
                row4Counting: "La tabla explota exponencialmente con el tamaño del contexto",
                row4Learning: "El mismo pequeño conjunto de pesos, sin importar cuántos ejemplos",
            },
            predict1: "Antes de probar — ¿qué operación crees que te da más control sobre el resultado?",
            predict2: "¿Qué pasa si pones un peso a cero? Intenta predecirlo antes de arrastrar.",
            predict3: "Si ambas entradas son cero, ¿cuál debería ser la salida? ¿Y si quieres un valor por defecto distinto de cero?",
        },
        hero: {
            eyebrow: "Capítulo 3 · Del Conteo al Aprendizaje",
            titlePrefix: "Redes",
            titleSuffix: "Neuronales",
            description: "El conteo chocó contra un muro — los N-gramas no pueden generalizar a patrones no vistos. ¿Y si, en lugar de memorizar cada combinación, pudiéramos construir una máquina que aprende de ejemplos?",
            recap: "← Anteriormente: descubriste que los modelos estadísticos alcanzan su límite. Ahora construyamos algo fundamentalmente diferente.",
        },
        history: {
            title: "La Historia de las Redes Neuronales",
            summary: "De 1943 al aprendizaje profundo moderno — una historia de avances, inviernos y persistencia.",
            subtitle: "Ocho décadas de innovación, reveses y triunfo",
            p1: "En 1943, McCulloch y Pitts propusieron que una célula cerebral podía modelarse como una puerta lógica: recibe señales y, si son lo suficientemente fuertes, dispara. Demostraron que redes de estas unidades podían computar cualquier cosa. Esto era teoría pura — aún no existían computadoras para probarlo. Pero la semilla fue plantada: la inteligencia podía ser mecánica.",
            p2: "En 1958, Frank Rosenblatt construyó el Perceptrón Mark I en Cornell — la primera máquina que aprendía de la experiencia. Pesando 5 toneladas y usando fotocélulas como entradas, ajustaba sus propios parámetros para reconocer formas simples. The New York Times lo llamó 'el embrión de una computadora electrónica que [la Marina] espera que pueda caminar, hablar, ver, escribir, reproducirse y ser consciente de su existencia.' El bombo era real.",
            p3: "En 1969, Minsky y Papert demostraron que los perceptrones de una sola capa tenían límites fundamentales. No podían aprender XOR — un patrón simple que cualquier niño podía captar. La financiación se secó de la noche a la mañana. El Invierno de la IA duró casi dos décadas. Los investigadores abandonaron el campo. Las redes neuronales se convirtieron en una historia de advertencia.",
            p3_5: "Pero la idea se negó a morir. A lo largo de los años 70, un puñado de investigadores siguió trabajando en la oscuridad. La idea clave — que se podían entrenar redes multicapa propagando errores hacia atrás a través de las capas — fue descubierta independientemente por varios grupos. Tendría que esperar hasta 1986 para abrirse paso.",
            p4: "En 1986, Rumelhart, Hinton y Williams publicaron su artículo sobre la retropropagación — el algoritmo que mostró que las redes multicapa podían aprender. Las matemáticas habían existido desde los años 70, pero ahora eran prácticas. Las capas ocultas lo cambiaron todo. El deshielo comenzó, lentamente.",
            p5: "Tomó otros 25 años, conjuntos de datos masivos y la revolución de las GPU antes de que el aprendizaje profundo conquistara el mundo. ImageNet 2012. AlphaGo 2016. GPT-3 2020. Pero la semilla plantada en 1943 nunca dejó de crecer — solo necesitaba tiempo, escala y cómputo para florecer.",
        },

        artificialNeuron: {
            title: "Ensamblándolo Todo",
            lead: "Construiste las piezas — pesos, suma, sesgo. Ahora conectémoslas en una sola unidad y veámosla calcular. Esta es la neurona artificial: el átomo de toda red neuronal.",
            p1: "Abajo tienes todo lo que acabas de aprender en un diagrama interactivo. Arrastra los deslizadores para cambiar entradas, pesos y sesgo — y observa cómo cada uno afecta la salida final en tiempo real.",
            p1Highlight: "peso",
            p1End: "",
            p2: "La neurona multiplica cada entrada por su peso, las suma, añade el sesgo y luego pasa el resultado por una función de activación (aquí, ReLU — que simplemente recorta los negativos a cero). El desglose de contribuciones muestra exactamente de dónde viene cada parte de la salida.",
            formulaCaption: "Multiplica cada entrada por su peso, suma todo, añade el sesgo, luego aplica una función de activación f. Esta es la operación atómica de toda red neuronal.",
            p3: "Con los pesos y el sesgo correctos, una sola neurona puede",
            p3Highlight: "trazar una línea recta a través de los datos y clasificar todo a un lado como A y al otro como B",
            p3End: ". El entrenamiento es cómo la neurona encuentra esos números correctos — partiendo de suposiciones aleatorias y mejorando paso a paso.",
            calloutTitle: "¿Qué son los parámetros?",
            calloutText: "Los pesos y sesgos juntos se llaman parámetros. Al inicio son ruido aleatorio. Al final codifican todo lo que la red ha aprendido — almacenado simplemente como una lista de números decimales.",
            formalizeParagraph: "En matemáticas, todo lo que acabas de explorar se puede escribir en una sola línea:",
            formulaCaptionMoved: "Multiplica cada entrada por su peso, suma todo, añade el sesgo, luego pásalo por una función de activación f. Esta es la operación atómica de toda red neuronal.",
            bridgeToScaling: "Una neurona puede calcular una suma ponderada y disparar (o no). Eso es poderoso — pero también limitado. ¿Qué pasa cuando juntamos muchas de estas unidades?",
            walkthrough: {
                title: "Desglosándolo con un ejemplo real",
                scenarioTitle: "Escenario:",
                scenarioText: "Una neurona intenta predecir tu tiempo de trayecto.",
                intro: "Considera dos entradas: la distancia al colegio (x₁) y el nivel de tráfico (x₂). Veamos cómo hace una predicción.",
                step1: "Empieza con las entradas",
                step2: "Multiplica cada entrada por su peso",
                step2Desc: "Los pesos determinan la importancia. Aquí, la distancia importa mucho (w₁ es alto) y el tráfico importa menos (w₂ es pequeño).",
                step2Hint: "La distancia aportó 1.2 puntos; el tráfico solo 0.18 puntos.",
                step3: "Suma las entradas ponderadas (Σ)",
                step3Hint: "Σ (sigma) solo significa “sumarlo todo.”",
                step4: "Añade el sesgo",
                step4Desc: "El sesgo es el empuje base. Un sesgo positivo activa más fácil; un sesgo negativo hace a la neurona más exigente.",
                step4Hint: "Un sesgo negativo reduce la puntuación antes de la activación.",
                step5: "Aplica la función de activación",
                step5Desc: "La activación decide qué tan fuerte “dispara” la neurona. ReLU deja pasar positivos y recorta negativos a 0.",
                step5Hint: "Como 0.88 es positivo, pasa sin cambios.",
                resultTitle: "Salida final",
                resultTextPart: "La neurona produce",
                resultDesc: "Esto podría interpretarse como una predicción segura de un trayecto corto.",
                finalNote: "Eso es todo lo que hace una neurona: multiplicar por pesos, sumar sesgo y aplicar una activación.",
            },
            biological: {
                title: "Biología vs Máquina",
                subtitle: "Inspirada en la naturaleza, pero mucho más simple",
                bioLabel: "Neurona Biológica",
                artLabel: "Neurona Artificial",
                dendrites: "Las dendritas reciben señales de otras neuronas",
                cellBody: "El cuerpo celular procesa las señales entrantes",
                axon: "El axón transmite la señal de salida",
                synapse: "Las sinapsis conectan neuronas con intensidades variables",
                inputsArt: "Entradas (números que se alimentan)",
                weightsArt: "Pesos (importancia de cada entrada)",
                sumArt: "Suma ponderada + sesgo",
                activationArt: "Función de activación (disparar o no)",
                caveat: "El parecido es intencional pero superficial. Las neuronas reales son sistemas electroquímicos complejos con temporización, inhibición y plasticidad. Las neuronas artificiales son una simplificación matemática que captura solo una idea: señales de entrada, cálculo, señal de salida.",
            },
            predict4: "¿Puedes trazar el camino de las entradas a la salida en tu cabeza antes de verlo animado?",
            perceptronLabel: "Interactivo · El Perceptrón",
            perceptronHint: "Haz clic en cada capa para ver cómo las entradas fluyen a través de pesos, sesgo y activación. Esta es la neurona artificial completa.",
        },
        parallelNeurons: {
            title: "Interactivo · Neuronas en Paralelo",
            neuronCount: "{n} neurona(s)",
            sameInputs: "Mismas entradas",
            multipleOutputs: "Múltiples salidas",
            reluToggle: "ReLU",
            reluOn: "On",
            reluOff: "Off",
            inactiveTitle: "Neuron is inactive",
            inactiveDesc: "ReLU clipped it to 0",
            inactiveBadge: "Inactive (ReLU → 0)",
            inactiveSummary: "{neurons} produced a negative value, so ReLU clipped the output to 0.",
            insightOne: "1 neurona → 1 salida. Solo puede calcular una cosa.",
            insightMultiple: "{n} neuronas → {n} salidas. Cada neurona aprende algo diferente de los mismos datos.",
            hint: "Añade neuronas y activa/desactiva ReLU para ver cómo múltiples neuronas procesan las mismas entradas de forma independiente.",
        },
        decisionBoundary: {
            title: "Interactivo · Límite de Decisión",
            hint: "Arrastra los deslizadores de peso para mover la línea de decisión. Prueba ambos escenarios — simple y XOR.",
            simpleBtn: "Simple (separable)",
            complexBtn: "Complejo (XOR)",
            biasLabel: "sesgo",
            accuracyLabel: "Precisión",
            classA: "Clase A",
            classB: "Clase B",
            insightLinearPerfect: "Una neurona, una línea — y separa perfectamente los dos grupos. Esto es lo que puede hacer una sola neurona.",
            insightLinearTry: "Arrastra los deslizadores para encontrar una línea que separe azul de rojo. Una sola neurona puede resolver esto.",
            insightXor: "No importa cómo muevas la línea, no puedes separar los grupos. Una línea recta no es suficiente. Este es el problema XOR — y por eso necesitamos más neuronas.",
        },
        nonLinearity: {
            title: "¿Y Si Añadimos Más Neuronas?",
            lead: "Una neurona solo puede trazar una línea recta. ¿Qué pasa cuando combinamos varias? Vamos a descubrirlo — paso a paso.",
            linearProblem: "Esta es la primera sorpresa: si simplemente apilas capas de neuronas sin nada especial entre ellas, no obtienes nada nuevo. ",
            linearProblemHighlight: "Dos capas colapsan en una. Diez capas colapsan en una.",
            linearProblemEnd: " Es como apilar lupas — simplemente se combinan en una sola ampliación. Pruébalo:",
            stackingIntro: "Añade capas abajo, luego activa la función de activación para ver la diferencia.",
            stackingLabel: "Interactivo · Apilando Capas",
            stackingHint: "Añade capas y observa: sin función de activación, el efecto combinado siempre es una línea recta. Con ReLU, cada capa añade una curva.",
            stackingOutro: "Sin funciones de activación, la profundidad es una ilusión. La red sigue siendo solo una gran operación lineal — sin importar cuántas capas añadas.",
            stacking: {
                title: "Demo de Apilado de Capas",
                layerCount: "{n} capas",
                addRelu: "Añadir ReLU",
                stillLinear: "¡Sigue siendo una línea recta!",
                bendCount: "¡{n} curvas!",
                hint: "Las capas lineales colapsan. La no linealidad es lo que hace útil la profundidad.",
            },
            activationIntro: "La solución es una idea pequeña: después de la suma de cada neurona, aplica una función no lineal. Esto rompe el colapso. Cada capa ahora añade una curva genuina. Explora las funciones de activación más comunes:",
            activationLabel: "Interactivo · Funciones de Activación",
            activationHint: "Haz clic en cada función para comparar formas. ReLU es la opción por defecto en redes modernas — simple pero efectiva.",
            p3: "Diferentes funciones tienen diferentes personalidades.",
            p3Highlight: "ReLU deja pasar los positivos y elimina los negativos. Sigmoide comprime todo entre 0 y 1. Tanh comprime entre -1 y 1.",
            p3End: "La elección importa: ReLU hizo prácticas las redes profundas al evitar el problema de los gradientes que desaparecen.",
            parallelIntro: "Ahora añadamos más neuronas. En lugar de una sola neurona que produce una sola salida, pon varias lado a lado — todas mirando las mismas entradas, cada una con sus propios pesos y sesgo.",
            parallelOutro: "Cada neurona aprende a detectar un patrón diferente en los mismos datos. Esto se llama una capa — un grupo de neuronas trabajando en paralelo. Una salida se convierte en muchas.",
            whyALine: "Pero ¿qué hace realmente cada neurona? Piensa en ella como una pregunta de sí o no: ¿está este punto por encima o por debajo de mi línea? La neurona calcula su suma ponderada, y el resultado es positivo (sí) o negativo (no). Esa línea divisoria es la frontera de decisión de la neurona.",
            whyALineDetail: "Por ejemplo: '¿El tiempo de viaje es más de 30 minutos?' Una neurona, una pregunta, una línea recta dividiendo el espacio en dos. Múltiples neuronas hacen múltiples preguntas — y combinando sus respuestas, podemos describir regiones mucho más complejas.",
            boundaryIntro: "Así es como se ve en la práctica. Una sola neurona traza una línea recta por los datos y dice \"todo a este lado es A, todo al otro lado es B.\" Pruébalo — arrastra los pesos para mover la línea:",
            boundaryOutro: "Empieza con el escenario simple — una línea es suficiente. Luego cambia al modo XOR e intenta alcanzar el 100% de precisión. Verás que es imposible con una sola neurona.",
            xorChallenge: {
                question: "Cambia al modo XOR. Prueba todas las combinaciones de pesos y sesgo. ¿Puedes llegar al 100% de precisión?",
                hint: "No importa cómo inclines o desplaces la línea, algunos puntos rojos y azules quedan en el lado equivocado. XOR no se puede resolver con una sola línea recta.",
                success: "¡Exacto — no puedes! Una neurona = una línea. XOR necesita al menos dos líneas para separar los cuatro puntos. Por eso necesitamos varias neuronas trabajando juntas.",
            },
            layerIntro: "XOR demostró que una capa no es suficiente. ¿Y si apilamos capas — una tras otra — para que la salida de una sea la entrada de la siguiente?",
            peak2: "Esto dejó estancado al campo durante veinte años.",
            reflection1: "Una neurona, una línea. Dos neuronas, dos líneas. ¿Qué pasa con cien?",
            whatIf1Title: "¿Y si apilaras 100 capas sin activación?",
            whatIf1Desc: "Una demostración con álgebra matricial de que cualquier número de capas lineales colapsa en una.",
            whatIf1Text: "Cada capa lineal es simplemente una multiplicación de matrices: salida = W · entrada. ¿Dos capas? Eso es W₂ · (W₁ · entrada) = (W₂ · W₁) · entrada. El producto de dos matrices es simplemente otra matriz. Así que dos capas = una capa. ¿Cien capas? Sigue siendo una sola matriz.",
            whatIf1MatrixLabel: "Multiplicación de matrices — las capas colapsan",
            whatIf1Conclusion: "No importa cuántas capas apiles, sin no linealidad entre ellas, toda la red colapsa en una sola multiplicación de matrices. La profundidad es una ilusión. Este es el problema del colapso lineal — y por eso las funciones de activación son innegociables.",
            xorSolverIntro: "Ahora viene la recompensa. ¿Recuerdas el problema XOR que una neurona no podía resolver? Con dos neuronas y activación ReLU, la red puede trazar dos líneas de frontera — creando una banda que separa las clases. Alterna entre los modos para ver la diferencia:",
            xorSolverOutro: "Dos neuronas con ReLU resolvieron lo que una neurona nunca pudo. Cada neurona oculta traza una línea; la neurona de salida combina sus respuestas. Este es el poder fundamental de las redes neuronales: piezas simples, combinadas con no linealidad, pueden resolver problemas complejos.",
            deadNeuronIntro: "Ahora que entiendes los gradientes, hay una trampa con ReLU: si la pre-activación de una neurona es siempre negativa, ReLU la recorta a cero — y gradiente cero significa aprendizaje cero. La neurona está permanentemente muerta. Este es el problema de la 'ReLU moribunda'.",
            summaryCalloutTitle: "La receta hasta ahora",
            summaryCalloutText: "Toma neuronas (suma ponderada + sesgo). Añade funciones de activación para desbloquear la no linealidad. Ponlas en paralelo para obtener una capa. Apila capas en serie para obtener profundidad. Esa es la arquitectura de toda red neuronal.",
        },
        xorSolver: {
            title: "Interactivo · XOR Resuelto con ReLU",
            hint: "Alterna entre lineal (sin activación) y ReLU para ver cómo dos neuronas con activación pueden resolver el problema XOR.",
            linearBtn: "Sin Activación",
            reluBtn: "Con ReLU",
            classA: "Clase A",
            classB: "Clase B",
            accuracy: "Precisión",
            networkLabel: "Red",
            insightLinear: "Una sola línea recta nunca puede separar el patrón XOR. No importa dónde la dibujes, algunos puntos quedan en el lado equivocado. Este es el límite de una sola neurona lineal.",
            insightRelu: "Dos neuronas ocultas con ReLU crean dos líneas de frontera. Juntas forman una banda — la región en forma de diamante que separa correctamente los cuatro grupos. Este es el poder de la no linealidad.",
        },
        divergence: {
            title: "Interactivo · ¿Qué Pasa Sin Tasa de Aprendizaje?",
            hint: "Alterna entre gradiente completo (lr=1) y una tasa pequeña (lr=0.01) para ver la diferencia dramática.",
            fullBtn: "Gradiente completo (η = 1)",
            smallBtn: "Pasos pequeños (η = 0.01)",
            exploded: "¡La pérdida explotó! 💥",
            converged: "Convergió suavemente ✓",
            insightFull: "Con η = 1, restamos el gradiente completo. El primer paso sobrepasa el mínimo tan brutalmente que el siguiente lo sobrepasa aún más. La pérdida se dispara al infinito. Esto es divergencia.",
            insightSmall: "Con η = 0.01, cada paso es una pequeña fracción del gradiente. La pérdida baja suavemente hacia cero. Los pesos convergen a buenos valores. Por eso existe la tasa de aprendizaje.",
        },
        bioVsArtificial: {
            intro: "La neurona artificial fue inspirada directamente por cómo funcionan las células cerebrales reales. McCulloch y Pitts estudiaron neuronas biológicas en 1943 y notaron un patrón: las señales llegan por las dendritas, se procesan en el cuerpo celular, y si la señal total es suficientemente fuerte, la neurona dispara una salida por el axón. Preguntaron: ¿podemos construir un modelo matemático que haga lo mismo?",
            bioTitle: "Neurona Biológica",
            artTitle: "Perceptrón Artificial",
            dendrites: "Dendritas",
            soma: "Cuerpo celular",
            axon: "Axón",
            terminals: "Terminales",
            synapses: "Sinapsis",
            inputs: "Entradas",
            weights: "Pesos",
            sumActivation: "Suma + σ",
            output: "Salida",
            map: {
                dendritesBio: "Las dendritas reciben señales de otras neuronas",
                dendritesArt: "Las entradas (x₁, x₂, ...) reciben datos",
                synapsesBio: "Las sinapsis fortalecen o debilitan señales",
                synapsesArt: "Los pesos (w₁, w₂, ...) amplifican o reducen entradas",
                somaBio: "El cuerpo celular suma todas las señales entrantes",
                somaArt: "Sumación: Σ(wᵢ · xᵢ) + sesgo, luego activación σ",
                axonBio: "El axón dispara si la señal supera el umbral",
                axonArt: "Salida ŷ — la predicción de la neurona",
            },
        },
        weightImpact: {
            title: "Interactivo · Cómo un Peso Cambia la Pérdida",
            hint: "Arrastra el deslizador de peso y observa la cadena completa actualizarse: entrada × peso + sesgo → σ → salida → pérdida.",
            introText: "Ahora que sabemos medir el error, podemos hacer la pregunta clave: si cambiamos un peso ligeramente, ¿la pérdida sube o baja? Tracemos a través de una neurona real para averiguarlo.",
            bridge: "Lo acabas de ver con tus propios ojos: un pequeño cambio en el peso cambia la pérdida. Si la pérdida subió, debemos mover el peso en la otra dirección. Si bajó, seguimos. Esta idea es exactamente lo que captura la derivada. Veámoslo como gráfico:",
            nudgeTitle: "¿Qué pasa si cambiamos el peso en +0.1?",
            shouldDecrease: "Aumentar w empeoró la pérdida → debemos DISMINUIR el peso",
            shouldIncrease: "Aumentar w mejoró la pérdida → debemos AUMENTAR el peso",
            atMinimum: "Estamos en (o muy cerca de) el mínimo. No se necesita ajuste.",
            insight: "Este es todo el truco del entrenamiento: probar un cambio pequeño, ver si la pérdida mejora o empeora, y ajustar. La derivada automatiza esto para todos los pesos simultáneamente.",
        },
        lossDerivative: {
            title: "Interactivo · La Derivada como Gráfico",
            hint: "Arrastra el peso y ve la curva de pérdida. La pendiente de la línea tangente ES la derivada.",
            introText: "La misma idea que acabamos de explorar — cambiar un peso y ver si la pérdida sube o baja — se puede visualizar como una curva. Cada valor posible de peso tiene una pérdida correspondiente. La derivada en cualquier punto es la pendiente de esta curva.",
            showNudge: "🔍 Muéstrame las mates: cambiar w en 0.01",
            hideNudge: "Ocultar detalles",
            changeRatio: "Δpérdida / Δw =",
            positiveSlope: "Pendiente positiva → aumentar w aumenta la pérdida → mover w a la IZQUIERDA",
            negativeSlope: "Pendiente negativa → aumentar w disminuye la pérdida → mover w a la DERECHA",
            zeroSlope: "Pendiente ≈ 0 → ¡estamos en el mínimo!",
            insight: "La derivada te dice exactamente en qué dirección ajustar cada peso. ¿Derivada positiva? Disminuye el peso. ¿Negativa? Auméntalo. Esta es toda la base del entrenamiento.",
        },
        flatGradient: {
            title: "Avanzado: ¿Qué Pasa si la Derivada es Cero?",
            desc: "El problema del gradiente evanescente — por qué algunas neuronas dejan de aprender por completo.",
            intro: "Si la derivada es cero, el peso recibe actualización cero. No hay aprendizaje. Esto no es solo teórico — es uno de los problemas más importantes en aprendizaje profundo.",
            vizTitle: "Interactivo · Zonas de Saturación del Sigmoid",
            vizHint: "Arrastra el valor de entrada. En las zonas rojas, la derivada es casi cero — la neurona está 'saturada' y no puede aprender.",
            mathTitle: "Las matemáticas detrás de la saturación",
            mathExplain: "Cuando z es muy grande o muy negativo, σ(z) está cerca de 0 o 1. Entonces σ(z)(1 − σ(z)) ≈ 0. La derivada se desvanece. En una red profunda, estas derivadas diminutas se multiplican capa por capa — 0.01 × 0.01 × 0.01 = 0.000001.",
            solution: "Por eso ReLU reemplazó a sigmoid en redes profundas. La derivada de ReLU es exactamente 1 para entradas positivas — el gradiente fluye sin cambios.",
            stuck: "ATASCADA",
            learning: "APRENDIENDO",
            slow: "LENTA",
            flatExplain: "El sigmoid está saturado aquí. La derivada es casi cero, así que las actualizaciones de peso serán insignificantes. La neurona no puede aprender de esta entrada.",
            healthyExplain: "El sigmoid está en su zona activa. La derivada es suficientemente grande para actualizaciones significativas.",
            slowExplain: "La derivada es pequeña pero no cero. El aprendizaje ocurrirá, pero muy lentamente.",
        },
        backpropZero: {
            title: "Interactivo · Retropropagación con Derivada Cero",
            hint: "Mueve z a las zonas de saturación (lejos de 0) y observa σ'(z) colapsar a cero — matando toda la cadena de gradientes.",
            intro: "Viste que la derivada del sigmoid llega a cero en las zonas de saturación. ¿Pero qué significa eso realmente para el aprendizaje? Tracemos la cadena completa de retropropagación. Si CUALQUIER término es cero, todo el gradiente es cero.",
            stuck: "σ'(z) ≈ 0 → la cadena de gradientes está rota → el peso no puede actualizarse. ¡Esta neurona está atascada!",
            working: "σ'(z) es suficientemente grande → el gradiente fluye → el peso puede actualizarse normalmente.",
        },
        batchChallenge: {
            question: "Desafío: En la demo de entrenamiento de arriba, intenta poner la tasa de aprendizaje muy alta (ej. 0.3) con un solo ejemplo. ¿Puedes hacer que la pérdida AUMENTE en vez de disminuir? ¿Por qué pasa eso?",
            hint: "Piensa en qué pasa cuando el modelo ve solo un ejemplo inusual. Si ese ejemplo es muy diferente del promedio, el gradiente empuja los pesos demasiado lejos — sobrepasando el mínimo.",
            success: "¡Exacto! Con un lote pequeño y tasa de aprendizaje alta, un solo valor atípico puede empujar los pesos tan lejos que la pérdida total sube. Por eso usamos mini-lotes y tasas de aprendizaje cuidadosas.",
        },
        batchComparison: {
            title: "Interactivo · Por Qué Importa el Tamaño del Lote",
            hint: "Observa los 3 tamaños de lote entrenar simultáneamente. Rojo (lote=1) es ruidoso; amarillo (lote=4) es más suave; verde (lote=TODOS) es un camino limpio.",
            introText: "¿Por qué no entrenar con un solo ejemplo a la vez? Imagina que intentas aprender la estatura promedio de 12 personas. Si solo miras a una persona por paso, una persona muy alta distorsionará tu estimación. Veamos los 3 tamaños de lote lado a lado:",
            outroText: "Esta inestabilidad con lotes pequeños es un anticipo de un problema más profundo: si tus datos de entrenamiento no son representativos, tu modelo aprenderá los patrones equivocados. Esto se llama sobreajuste.",
            insightStart: "Pulsa 'Paso' o 'Ejecutar todos 20' para empezar. Los tres modelos empiezan desde la misma predicción errónea (155 cm) e intentan encontrar la media real.",
            insightMid: "Nota la línea roja (lote=1) rebotando salvajemente. La línea amarilla (lote=4) es más suave. La verde (lote=TODOS) toma el camino más directo.",
            insightEnd: "Los tres se acercan, pero lote=1 tomó un zigzag caótico mientras lote=TODOS fue directo. En la práctica, lote=TODOS es demasiado costoso para grandes datasets, así que mini-lotes (4, 32, 64) son el equilibrio ideal.",
        },
        matrixMultiply: {
            title: "Avanzado: Una Capa ES una Multiplicación de Matrices",
            desc: "Mira cómo una capa de red neuronal es realmente solo multiplicación de matrices — la operación que las GPUs están diseñadas para hacer en paralelo.",
            insight: "Una capa ES una multiplicación de matrices. Cada entrada se multiplica por cada peso simultáneamente. Las GPUs están diseñadas para hacer millones de estas en paralelo — por eso las redes neuronales corren en tarjetas gráficas.",
            coreOp: "La operación central",
            formalTitle: "Notación formal",
            formalDesc: "En notación vectorial, una sola capa calcula y = x·W + b. La matriz de pesos W transforma la entrada x en la salida y. El sesgo b desplaza el resultado. Cada neurona de salida j calcula un producto punto de la entrada con su columna de W:",
            sumExplain: "Cada salida yⱼ es la suma de todas las entradas multiplicadas por los pesos correspondientes en la columna j, más un sesgo. Es exactamente el patrón 'multiplicar, sumar, añadir sesgo' de la neurona individual — pero hecho en paralelo para todas las salidas a la vez.",
            dimTitle: "Las dimensiones importan",
            dimExplain: "Las dimensiones internas deben coincidir: x tiene n características, W tiene n filas. El tamaño de salida m lo determina el número de columnas de W — eso es cuántas neuronas hay en la capa.",
            stackTitle: "Apilando capas: redes profundas",
            stackDesc: "Una red profunda es simplemente varias multiplicaciones de matrices en secuencia, con una no-linealidad (como ReLU) después de cada una. La no-linealidad es crucial — sin ella, apilar capas colapsaría en una sola multiplicación de matrices (ya que AB = C para cualquier matrices A, B).",
            stackNote: "Cada σ es una función de activación aplicada elemento a elemento. Sin ella, W₁·W₂·W₃ = W_combinada — la red colapsaría a una sola capa sin importar cuántas apiles. La no-linealidad es lo que hace útil la profundidad.",
            scaleTitle: "Escala del mundo real",
        },
        trainValSplit: {
            title: "Interactivo · División Entrenamiento / Validación",
            hint: "Haz clic en 'Dividir' para ver cómo se dividen los datos en conjuntos de entrenamiento y validación. El modelo solo entrena con los puntos rellenos.",
            trainLabel: "Entren.",
            valLabel: "Val.",
            trainArrow: "El modelo entrena con estos",
            valArrow: "El modelo se evalúa con estos",
            splitBtn: "Dividir los datos →",
            resetBtn: "↺ Recombinar",
        },
        activationDeriv: {
            title: "Funciones de Activación y Sus Derivadas",
            expandableTitle: "Avanzado: derivadas de activación y gradientes evanescentes",
            hint: "Compara cómo cada función de activación transforma su entrada (izquierda) y cómo se comporta su derivada (derecha). Zonas rojas = gradiente evanescente.",
            derivLabel: "derivada",
            vanishingWarning: "Zona de gradiente evanescente detectada",
            sigmoidNote: "La derivada de Sigmoid alcanza un máximo de 0.25 y cae a casi cero para |x| grandes. En redes profundas, estos gradientes diminutos se multiplican entre sí, haciendo casi imposible entrenar las primeras capas.",
            tanhNote: "Tanh tiene una derivada más fuerte que sigmoid (máximo en 1.0), pero aún se desvanece para |x| grandes. Mejor que sigmoid, pero ReLU evita el problema por completo.",
            reluNote: "La derivada de ReLU es exactamente 1 para entradas positivas — los gradientes fluyen sin cambios. Por eso ReLU hizo prácticas las redes profundas.",
        },
        deadNeuron: {
            title: "El Problema de la Neurona Muerta",
            hint: "Un sesgo muy negativo hace que ReLU siempre dé cero. Arrastra el sesgo hacia arriba para revivir la neurona.",
            outputsLabel: "Salida ReLU para diferentes entradas",
            deadLabel: "Esta neurona está muerta — nunca aprenderá.",
            aliveLabel: "¡La neurona está viva y respondiendo a las entradas!",
            partialLabel: "Parcialmente activa — algunas entradas pasan.",
            deadExplain: "Con un sesgo tan negativo, la pre-activación siempre es negativa. ReLU la recorta a cero. Gradiente cero significa aprendizaje cero.",
            aliveExplain: "Los valores de pre-activación positivos pasan por ReLU, produciendo salidas y gradientes distintos de cero.",
        },
        vowelTeaser: {
            title: "Vista Previa: Una Neurona Por Vocal",
            hint: "Un vistazo a lo que construiremos en §07 — una red que reconoce vocales.",
            desc: "5 vocales (a, e, i, o, u). Una neurona de salida por vocal. Al introducir una letra, cada neurona devuelve lo probable que cree que su vocal sea la siguiente.",
            forward: "Construiremos esto de verdad cuando lleguemos a De Números a Lenguaje.",
            inputNodeLabel: "neurona",
            inputValueLabel: "letra",
        },
        stepEpochBatch: {
            title: "Pasos, Épocas y Lotes",
            hint: "Observa cómo los datos fluyen por la red en lotes. Un pase completo por todos los datos = una época.",
            stepLabel: "Paso",
            epochLabel: "Época",
            batchLabel: "Lote",
            dataLabel: "{n} ejemplos de entrenamiento",
            batchSizeLabel: "tamaño de lote = {n}",
            epochProgress: "Progreso de época",
            shortcutsHint: "Atajos: ←/→ paso · Espacio reproducir/pausar",
            play: "▶ Reproducir",
            pause: "⏸ Pausar",
            stepBtn: "Paso →",
            reset: "↺ Reiniciar",
            complete: "¡3 épocas completas! La red ha visto cada ejemplo 3 veces.",
        },
        gradientNoise: {
            title: "Ruido del Gradiente vs Tamaño de Lote",
            hint: "Lotes más grandes dan gradientes más suaves pero cada paso procesa más datos. Lotes más pequeños son más ruidosos pero actualizan pesos más frecuentemente por época. Compara las curvas para ver el compromiso.",
            batchSizeLabel: "Tamaño de lote",
            trueGradient: "gradiente real",
            batchGradient: "gradiente del lote",
            noise1: "Lote de 1 (SGD): cada flecha es de un solo ejemplo. Muy ruidoso — cada una apunta en una dirección diferente.",
            noise8: "Lote de 8: algo de promediado suaviza el ruido, pero las flechas aún se dispersan alrededor de la dirección real.",
            noise32: "Lote de 32: un buen equilibrio. Las flechas se agrupan cerca del gradiente real con ruido moderado.",
            noise256: "Lote de 256: gradientes muy suaves, casi alineados. Pero cada paso es costoso de calcular.",
            noiseFull: "Lote completo: una flecha perfecta. Sin ruido, pero extremadamente lento — calcula el gradiente sobre TODOS los ejemplos.",
        },
        overfittingPlay: {
            title: "El Patio de Juegos del Sobreajuste",
            hint: "Tres modelos, mismos datos. Solo uno generaliza bien a nuevos puntos no vistos. Haz clic en 'Probar' para descubrirlo.",
            underfit: "Subajuste",
            overfit: "Sobreajuste",
            optimal: "Óptimo",
            showTest: "🧪 Probar con datos no vistos",
            hideTest: "Ocultar datos de prueba",
            testInsight: "¡Mira las precisiones de prueba! El modelo sobreajustado saca 100% en entrenamiento pero solo 54% en datos nuevos — peor que aleatorio para dos clases. El óptimo sacrifica algo de precisión de entrenamiento (88%) pero generaliza mucho mejor (85% en prueba). El subajustado es malo en ambos — demasiado simple para aprender el patrón.",
        },
        findingDirection: {
            title: "¿Podemos Corregir una Mala Predicción?",
            lead: "Hemos construido una neurona. Pero con pesos aleatorios, sus predicciones son completamente erróneas. ¿Podemos descubrir cómo arreglarlos — sin probar cada combinación posible?",
            peak3: "TIENE que haber una forma mejor.",
            reflection2: "Acabas de medir algo invisible — cuánto un número afecta a otro a través de una cadena de operaciones.",
            whatIf2Title: "¿Y si la derivada es cero en todas partes?",
            whatIf2Text: "Entonces la red no puede aprender en absoluto. Derivada cero significa 'no se detectó cambio' — los pesos no tienen idea de en qué dirección moverse. Esto se llama gradiente evanescente, y plagó las primeras redes profundas hasta que ReLU y la inicialización cuidadosa lo solucionaron.",
        },
        howItLearns: {
            title: "Cómo Aprende una Red",
            lead: "Tenemos una neurona que calcula: toma entradas, multiplica por pesos y lo suma. Pero ",
            leadHighlight: "esos pesos empiezan como números aleatorios",
            leadEnd: " — así que las respuestas son completamente equivocadas. Aquí está el reto: ¿puedes descubrir cómo arreglarlos?",
            phaseA: {
                p1: "Hagámoslo concreto. Imagina que queremos predecir cuánto tardas en llegar al trabajo. Las entradas son hechos fijos: distancia = 5 km y tráfico = 7. Queremos que la respuesta correcta sea 30 minutos. Pero la neurona empieza con pesos aleatorios (w₁ = 4, w₂ = 3) y un sesgo aleatorio — el tiempo fijo de “ponerte en marcha”, como subirte al coche y arrancar. Así que la primera predicción sale muy mal.",
                hint: "El modelo predice minutos como w₁ × distancia + w₂ × tráfico + sesgo. Con parámetros aleatorios, la predicción es incorrecta.",
                p2: "Las entradas son datos fijos. Lo único que podemos cambiar son los pesos y el sesgo. Entonces, ¿cómo ajustarías TÚ w₁, w₂ y b para que la predicción se acerque a 30 minutos? Pruébalo:",
            },
            phaseB: {
                legacyConcrete: "Hagámoslo concreto. Supón que sabemos la respuesta correcta: cuando las entradas son 1 y 2, la salida debería ser 3. Pero ahora mismo el modelo tiene pesos aleatorios (w₁ = 4, w₂ = 3), así que calcula 4×1 + 3×2 = 10. Está muy lejos — debería ser 3, no 10.",
                intro: "El primer paso más natural: ¿qué pasa si simplemente cambiamos un peso y vemos qué sucede? Usa los deslizadores abajo para ajustar w₁ y w₂. Intenta que la salida sea igual a 3.",
                nudgeHint: "Arrastra los deslizadores de peso y observa cómo cambia la salida. Nota cuál peso tiene más efecto.",
                discovery: "¿Lo notaste? Cuando cambias w₁ en 1, la salida cambia en 1 (porque x₁ = 1). Pero cuando cambias w₂ en 1, la salida cambia en 2 (porque x₂ = 2). El efecto de cada peso depende de su entrada. w₂ es el doble de sensible que w₁.",
            },
            phaseC: {
                intro: "Acabas de descubrir algo poderoso: cada peso tiene un efecto distinto en la salida. Veamos exactamente por qué. Toma el ejemplo más simple posible: si z = x + y, ¿qué pasa con z cuando x sube en 1?",
                derivativeHint: "Alterna entre suma y multiplicación. Cambia x e y para ver cómo cambia el resultado.",
                nameIt: "Para la suma (x + y = z), cuando x sube en 1, z siempre sube en 1 — sin importar y. Decimos que la derivada es 1. Significa: \"por cada unidad que cambia x, z cambia exactamente 1 unidad\". Para la multiplicación (x × y = z), cuando x sube en 1, z sube en y. La derivada es y — ¡el efecto de x depende de qué tan grande sea y! Esta idea — medir cuánto una cosa afecta a otra — es la base de cómo aprenden las redes neuronales.",
            },
            phaseD: {
                intro: "En una neurona real, las operaciones están encadenadas: primero multiplicas por un peso y luego sumas un sesgo. Si cambiamos x al principio, el cambio se propaga por cada paso. Mira cómo sucede:",
                chainHint: "Mueve el deslizador de x y observa cómo el cambio se propaga por cada operación.",
                nameIt: "Para encontrar el efecto total, multiplicas los efectos individuales a lo largo de la cadena. En nuestro ejemplo: multiplicar por 3 tiene un efecto de 3, sumar 1 tiene un efecto de 1. Total: 3 × 1 = 3. A esto se le llama la regla de la cadena — y funciona sin importar cuántas operaciones apiles. ¿Una red con millones de operaciones? La misma idea: multiplicar efectos locales, paso a paso, desde el final hacia el principio.",
            },
            phaseE: {
                intro: "Conocemos la pérdida — ahora ¿en qué dirección debemos mover cada peso para reducirla? La pendiente de la curva de pérdida nos lo dice:",
                dirHint: "Prueba los tres escenarios para ver la lógica: muy alto, muy bajo y correcto.",
                rule: "La lógica es hermosa en su sencillez: si la derivada es positiva (aumentar el peso hace la salida más grande) y la salida ya es demasiado alta — baja el peso. Si la salida es demasiado baja y la derivada es positiva — sube el peso. En resumen: muévete siempre en contra de la dirección que empeora las cosas. Esta idea está detrás de todo el entrenamiento de redes neuronales.",
            },
            phaseF: {
                intro: "Volvamos a nuestro ejemplo. La salida es 10, queríamos 3, así que el error es 10 − 3 = 7. Pero hay un problema sutil con usar errores crudos...",
                lossHint: "Mira por qué los errores crudos son problemáticos y cómo elevar al cuadrado lo soluciona.",
                named: "A este error al cuadrado lo llamamos pérdida. Es un solo número que nos dice qué tan equivocado está el modelo. Cuanto mayor la pérdida, peor la predicción. Nuestro objetivo es hacer la pérdida lo más pequeña posible.",
            },
            phaseG: {
                intro: "Ahora tenemos todo lo que necesitamos. Juntemos todo y hagamos un paso completo de entrenamiento: calcular la salida, medir la pérdida, calcular los gradientes y actualizar los pesos.",
                calcHint: "Avanza por las cinco fases de una sola iteración de entrenamiento.",
            },
            naming: {
                title: "Nombrando lo que acabas de aprender",
                text: "Calcular la salida es el pase hacia adelante. Elevar el error al cuadrado nos da la pérdida. Calcular cómo cada peso afecta la pérdida nos da los gradientes (el pase hacia atrás). Actualizar pesos restando el gradiente es descenso de gradiente. El ciclo completo — adelante, pérdida, atrás, actualizar — se llama retropropagación. ¡Acabas de hacerlo a mano!",
            },
            phaseH: {
                intro: "Un paso nos acercó, pero aún no llegamos. ¿Qué pasa si repetimos este proceso una y otra vez? Cada paso empuja los pesos un poco más cerca de los valores correctos.",
                repeatHint: "Haz clic en 'Entrenar un paso' o usa auto-entrenamiento para ver la pérdida disminuir con el tiempo.",
                outro: "¿Lo notaste? La pérdida bajó rápido al principio y luego se ralentizó. Los primeros pasos mejoran mucho porque los pesos están lejos del objetivo. Los pasos posteriores hacen ajustes pequeños. Pero hay un control oculto que determina qué tan rápido o lento sucede esto...",
            },
            phaseI: {
                intro: "La tasa de aprendizaje (se escribe como η, la letra griega 'eta') controla qué tan grande es cada paso. Después de calcular el gradiente, no saltamos toda la cantidad — tomamos una fracción. Esa fracción es la tasa de aprendizaje.",
                lrLabel: "Interactivo · Explorador de Tasa de Aprendizaje",
                lrHint: "Prueba los tres preajustes y luego usa el deslizador personalizado para encontrar el punto dulce. Observa con atención la curva de pérdida.",
                outro: "Demasiado pequeña y el entrenamiento avanza a paso de tortuga. Demasiado grande y explota. La tasa de aprendizaje es una de las decisiones más importantes al entrenar una red neuronal — y no hay una fórmula perfecta. Hay que experimentar.",
            },
            phaseJ: {
                intro: "Veamos la imagen completa del aprendizaje. Abajo hay un mapa de todas las combinaciones posibles de pesos. Azul oscuro significa baja pérdida (bien). Rojo significa alta pérdida (mal). Observa cómo los pesos viajan desde su punto inicial aleatorio hacia una buena solución.",
                trajectoryLabel: "Interactivo · Paisaje de Pesos",
                trajectoryHint: "El punto traza la ruta de los pesos durante el entrenamiento. La línea verde punteada muestra todas las combinaciones de pesos que dan la salida correcta. Observa cómo el punto 'baja la pendiente' hacia baja pérdida.",
                outro: "Esto es descenso de gradiente en acción — los pesos siguen la pendiente del paisaje de pérdida, moviéndose siempre hacia menor pérdida. La tasa de aprendizaje controla qué tan grande es cada paso en este paisaje.",
            },
            gradientMeaning: "¿Qué significan esos números del gradiente? Si el gradiente para w₁ es +14, significa: aumentar w₁ en 1 aumentaría la pérdida en 14. Eso es malo — así que disminuimos w₁ en su lugar. El signo te dice la dirección; el tamaño te dice qué tan sensible es la pérdida a ese peso.",
            namingTransition: "Paremos un momento y pongámosle nombres a todo lo que acabas de aprender.",
            fullVisualizer: "Ver el visualizador interactivo completo de retropropagación",
            learningRate: {
                title: "La Tasa de Aprendizaje",
                tooSmall: "Demasiado lenta",
                justRight: "Buena",
                tooLarge: "Demasiado rápida",
                custom: "η personalizada",
                lossOverTime: "Pérdida a lo largo de los pasos",
                lossValue: "Pérdida",
                play: "▶ Entrenar",
                running: "Entrenando...",
                reset: "Reiniciar",
                watchPrompt: "Pulsa Entrenar para ver qué ocurre con esta tasa de aprendizaje.",
                verdictDiverge: "¡La pérdida explotó!",
                explainDiverge: "La tasa de aprendizaje es demasiado grande. Cada paso se pasa del mínimo y empeora las cosas. Los pesos rebotan en vez de converger.",
                verdictConverge: "¡Convergencia suave!",
                explainConverge: "La tasa de aprendizaje está bien elegida. Cada paso avanza de forma constante hacia el mínimo. Los pesos se estabilizan en buenos valores.",
                verdictSlow: "Aún lejos de la respuesta...",
                explainSlow: "La tasa de aprendizaje es demasiado pequeña. Cada paso apenas mueve los pesos. Harían falta miles de pasos para converger. El entrenamiento es muy lento.",
            },
            trajectory: {
                title: "Paisaje de Pesos",
                lowLoss: "Baja pérdida",
                highLoss: "Alta pérdida",
                play: "▶ Ver entrenamiento",
                running: "Entrenando...",
                reset: "Reiniciar",
                hint: "El mapa de calor muestra la pérdida para cada combinación (w₁, w₂). La ruta blanca traza cómo el descenso de gradiente mueve los pesos desde el punto inicial (punto rojo) hacia una buena solución.",
            },
            predictionError: {
                title: "Predicción vs Realidad",
                expected: "Real (objetivo)",
                got: "Predicho",
                error: "Error",
                offBy: "Ajusta los pesos y el sesgo para acercar la predicción al objetivo.",
                challenge: "Desafío: iguala el tiempo real de trayecto",
                challengeDesc: "El trayecto real es 30 min. Ajusta w₁, w₂ y el sesgo hasta que tu predicción esté dentro de 1 minuto.",
                sensitivity: "Cambiar {w} en 1 → la salida cambia en {n}",
                comparison: "Predicho vs real",
                success: "¡Perfecto! Error < 1 min — el modelo ha aprendido los pesos correctos.",
            },
            nudge: {
                title: "¿Qué Pasa Si Ajustamos un Peso?",
                w1Sensitivity: "Cuando w₁ cambia en 1, la salida cambia en 1 (porque x₁ = 1).",
                w2Sensitivity: "Cuando w₂ cambia en 1, la salida cambia en 2 (porque x₂ = 2).",
                effectOfW1: "Sensibilidad de w₁",
                effectOfW2: "Sensibilidad de w₂",
                perUnit: "por unidad de cambio",
                perfect: "¡Lo encontraste! La salida es igual al objetivo.",
                keepTrying: "Sigue ajustando para alcanzar el objetivo de 3.",
                challengeW1: "Predice: si w₁ sube en 1, ¿cuánto cambia la salida?",
                challengeW2: "Predice: si w₂ sube en 1, ¿cuánto cambia la salida?",
                guessCorrect: "¡Correcto! La salida cambia exactamente en {n}. Este número es la sensibilidad — o derivada — de la salida respecto a este peso.",
                guessWrong: "No exactamente. La respuesta es {n}. La salida cambia exactamente en x₁ (o x₂) porque eso es por lo que se multiplica.",
                sensitivityNaming: "Estos números — cuánto cambia la salida por unidad de peso — se llaman sensibilidades. En cálculo tienen un nombre formal: derivadas.",
                formalTitle: "Notación formal (∂/∂w)",
                formalText: "En cálculo, la derivada de la salida respecto a un peso se escribe ∂salida/∂w. Mide exactamente lo que acabas de calcular: cuánto cambia la salida cuando el peso cambia una cantidad pequeña.",
                formalNote: "El símbolo ∂ (derivada parcial) se usa porque la salida depende de múltiples pesos simultáneamente.",
            },
            derivative: {
                title: "Midiendo la Sensibilidad",
                question: "¿Qué pasa si x sube en 1?",
                before: "Antes",
                after: "Después (x + 1)",
                zChanged: "z cambió en",
                thisIs: "Esta es la derivada",
                addExplain: "Para la suma, la derivada siempre es 1 — x siempre cambia z exactamente en 1, sin importar y.",
                mulExplain: "Para la multiplicación, la derivada es igual a y (actualmente {y}). ¡El efecto de x depende de qué tan grande sea y!",
                meterLabel: "sensibilidad",
                meterLabelRevealed: "derivada",
                sensitivityLabel: "La sensibilidad de z a x",
                revealedNote: "Los matemáticos llaman a este número la derivada. Lo descubriste simplemente preguntando: ¿qué cambia?",
            },
            chainRule: {
                title: "Encadenando Operaciones",
                ifXChanges: "Si x sube en 1, ¿qué pasa en cada paso?",
                totalEffect: "Efecto total de x en el resultado (regla de la cadena: multiplicar las derivadas):",
                explanation: "Si x cambia en 1, el resultado cambia en {w}. Lo encontramos multiplicando las derivadas locales: {w} × 1 = {w}.",
                startBtn: "▶ Ejecutar propagación",
                nextBtn: "Siguiente paso →",
                resetBtn: "↺ Reiniciar",
            },
            parabola: {
                title: "Paisaje de Pérdida",
                hint: "Arrastra el punto a lo largo de la curva para ver cómo cambia la pendiente. La pendiente le dice al modelo hacia dónde moverse.",
                weightLabel: "Peso",
                lossLabel: "Pérdida",
                slopeLabel: "Pendiente",
                slopePositive: "Pendiente positiva → mover peso a la IZQUIERDA para reducir pérdida",
                slopeNegative: "Pendiente negativa → mover peso a la DERECHA para reducir pérdida",
                slopeZero: "Pendiente ≈ cero — ¡estás en el mínimo!",
                watchGD: "▶ Ver descenso de gradiente",
                running: "Descendiendo...",
                dragHint: "Arrastra el punto en la curva, o presiona el botón para ver el descenso de gradiente en acción.",
            },
            gradientDir: {
                title: "¿En Qué Dirección Moverse?",
                tooHigh: "Salida muy alta",
                tooLow: "Salida muy baja",
                justRight: "Correcta",
                outputTooHigh: "La salida es {output} — mayor que el objetivo {target}. Necesitamos bajarla.",
                outputTooLow: "La salida es {output} — menor que el objetivo {target}. Necesitamos subirla.",
                derivativeIs: "La derivada es",
                positive: "positiva",
                negative: "negativa",
                posExplain: "Aumentar este peso aumentaría la salida aún más — empeorando las cosas.",
                negExplain: "Aumentar este peso aumentaría la salida — que es lo que necesitamos.",
                soDecrease: "Así que disminuimos el peso — nos movemos en dirección opuesta a la derivada.",
                soIncrease: "Así que aumentamos el peso — nos movemos en dirección opuesta a la derivada.",
                perfect: "¡La salida coincide con el objetivo!",
                perfectExplain: "La derivada es cero — no se necesita ajuste. Los pesos ya son correctos.",
                rule: "La regla: siempre mover el peso en dirección opuesta a su derivada.",
            },
            lossMotive: {
                title: "¿Por Qué Elevar al Cuadrado?",
                ourExample: "Nuestro modelo produce 10, queríamos 3. El error es:",
                problem: "¿Pero qué pasa si algunos errores son positivos y otros negativos?",
                example1: "Predicción muy alta",
                example2: "Predicción muy baja",
                sumRaw: "Suma de errores crudos",
                cancelOut: "¡Los errores se cancelan! La suma es 0 aunque ambas predicciones están equivocadas por 7.",
                solution: "La solución: elevar los errores al cuadrado. Esto hace todo positivo.",
                squaringFix: "Ambos dan 49 — sin cancelación. Elevar al cuadrado también penaliza más los errores grandes que los pequeños.",
                lossLabel: "La Pérdida",
                lossExplain: "Este solo número nos dice qué tan equivocado está el modelo. Nuestro objetivo: hacerlo lo más pequeño posible.",
                alternativesTitle: "Alternativas de Función de Pérdida",
                mseDesc: "Error cuadrático. Penaliza mucho los errores grandes. Gradiente suave en todas partes.",
                maeDesc: "Error absoluto. Trata todos los errores igual. Gradiente plano (±1).",
                rawDesc: "Error crudo. Positivos y negativos se cancelan. Inútil para entrenar.",
                alternativesNote: "MSE es el estándar para regresión porque su gradiente escala con el tamaño del error — errores grandes reciben correcciones grandes. MAE es más robusto a valores atípicos pero más difícil de optimizar.",
            },
            neuronCalc: {
                title: "Un Paso Completo de Entrenamiento",
                step: "Paso {n} de {total}",
                next: "Siguiente",
                prev: "Anterior",
                before: "Pérdida antes",
                after: "Pérdida después",
                s1Title: "1. Pase Hacia Adelante",
                s1Desc: "Calcula la salida usando los pesos actuales.",
                s3Title: "2. Calcular la Pérdida",
                s3Desc: "Eleva el error al cuadrado para obtener un solo número que mida qué tan equivocados estamos.",
                s6Title: "3. Calcular Gradientes",
                s6Desc: "¿Cuánto contribuye cada peso a la pérdida? El gradiente nos lo dice.",
                gradExplain: "Ambos gradientes son positivos — aumentar cualquier peso aumentaría la pérdida. Así que debemos disminuir ambos.",
                s7Title: "4. Actualizar Pesos",
                s7Desc: "Resta una pequeña fracción del gradiente de cada peso. Esto los mueve hacia mejores valores.",
                s8Title: "5. ¿Mejoró?",
                s8Better: "¡La pérdida disminuyó! Un paso más cerca de la respuesta correcta.",
                iteration: "Iteración {n}",
                resetAll: "Reiniciar todo",
                trainAgain: "Entrenar de nuevo ↻",
                lossOverTime: "Pérdida por iteración",
            },
            repeated: {
                title: "Aprendizaje a lo Largo del Tiempo",
                oneStep: "Entrenar un paso",
                auto: "Auto-entrenar (30 pasos)",
                training: "Entrenando...",
                reset: "Reiniciar",
                converged: "¡El modelo ha convergido! La salida ahora está muy cerca del objetivo.",
            },
            batchingTransition: "Has visto cómo un ejemplo fluye a través de la red. Pero los conjuntos de datos reales tienen miles o millones de ejemplos. Entrenar con ellos uno por uno tomaría una eternidad. La solución: lotes.",
            batching: {
                title: "La Revolución de los Mini-Lotes",
                lead: "Procesar ejemplos uno a la vez es dolorosamente lento. Entrenar en todo el conjunto de datos a la vez es impráctico. Los mini-lotes resuelven ambos problemas — y el ruido que introducen resulta ser una característica, no un error.",
                p1: "Calcular gradientes un ejemplo a la vez es ineficiente. Las GPUs modernas procesan cientos en paralelo. En lugar de actualizar tras cada ejemplo, promediamos gradientes de un pequeño lote — típicamente 32 a 256 — y actualizamos una vez por lote. Esto es descenso de gradiente por mini-lotes.",
                p2: "El tamaño del lote controla un compromiso fundamental. Tamaño 1 (SGD) produce gradientes ruidosos. Conjunto de datos completo produce gradientes suaves pero es lento y puede sobreajustar. Los mini-lotes equilibran gradientes estables con cómputo eficiente.",
                p3: "El ruido no es solo necesario — es útil. Los gradientes ruidosos ayudan a escapar de mínimos locales y mejoran la generalización en datos no vistos.",
                calloutTitle: "Por qué el ruido ayuda",
                calloutText: "El ruido en los gradientes no es solo un mal necesario — es una característica. Los lotes pequeños introducen aleatoriedad que ayuda al optimizador a explorar el paisaje de pérdida más a fondo, escapando de mínimos locales poco profundos y encontrando soluciones que generalizan mejor a datos nuevos.",
                conclusion: "El aprendizaje profundo moderno estandariza en mini-lotes de 32–256 ejemplos. Los lotes más grandes entrenan más rápido por época pero pueden generalizar peor. Los lotes más pequeños son más ruidosos pero a menudo encuentran mejores soluciones.",
                visual1Label: "Interactivo · Ruido de Gradiente vs Tamaño de Lote",
                visual1Hint: "Arrastra el deslizador de tamaño de lote para ver cómo varían las estimaciones de gradiente. Los lotes pequeños producen vectores de gradiente dispersos; los lotes grandes convergen cerca de la dirección del gradiente verdadero.",
                visual2Label: "Curvas de Pérdida · Comparación de Tamaños de Lote",
                visual2Hint: "Tres ejecuciones de entrenamiento simuladas con diferentes tamaños de lote. Rojo (lote=1) es ruidoso pero explora bien. Verde (lote=32) equilibra estabilidad y exploración. Azul (lote completo) es suave pero lento.",
            },
            workedExample: {
                title: "Un Ejemplo Concreto",
                intro: "Veamos a una sola neurona aprender de un ejemplo, paso a paso.",
                step1Title: "Valores Iniciales",
                step1Text: "Empezamos con pesos aleatorios (w=0.5), un sesgo (b=-0.2) y un ejemplo (x=1.0, objetivo=0.8).",
                step2Title: "1. Paso hacia Adelante",
                step2Text: "La neurona calcula w*x + b = 0.3. Tras la sigmoide, la predicción es 0.57.",
                step3Title: "2. Cálculo de la Pérdida",
                step3Text: "La predicción (0.57) es menor que el objetivo (0.8). El error es 0.05.",
                step4Title: "3. Retropropagación",
                step4Text: "Calculamos cómo cambiar w para reducir ese error. El gradiente nos dice que aumentemos w.",
                step5Title: "4. Actualización",
                step5Text: "Ajustamos el peso ligeramente. Nuevo w = 0.61. ¡La predicción está más cerca!"
            },
            workedForward: "Paso hacia adelante",
            workedUpdateNote: "Este ciclo completo — adelante, pérdida, atrás, actualización — se repite muchas veces durante el entrenamiento.",
        },
        watchingItLearn: {
            title: "Entrenamiento en Acción",
            lead: "La teoría es una cosa. Verlo suceder es otra. La demostración a continuación ejecuta pasos de entrenamiento reales en una sola neurona.",
            p1: "Pulsa el botón de entrenamiento y observa. La pérdida debería bajar. La predicción debería acercarse al objetivo. Cada clic ejecuta un ciclo de paso hacia adelante, retropropagación y actualización de pesos.",
            p2: "Presta atención a cómo cambian los pesos. Los primeros pasos producen grandes cambios porque los gradientes son pronunciados. Los pasos posteriores producen refinamientos minúsculos. Esto es el descenso de gradiente en acción.",
            alertTitle: "¡La pérdida está aumentando!",
            alertText: "Cuando la tasa de aprendizaje es demasiado alta, el descenso de gradiente puede sobrepasar el mínimo y hacer que la pérdida diverja. Prueba a reducir η por debajo de 2.0 para una convergencia estable.",
            landscapeTitle: "Paisaje de pérdida",
            landscapeDesc: "El mapa de calor muestra cómo varía la pérdida en función del peso y el sesgo. Entrena arriba y observa cómo la trayectoria desciende hacia el valle de baja pérdida.",
            terminologyIntro: "Antes de continuar, aclaremos algunos términos que verás en todas partes en el aprendizaje automático.",
            termStep: "Paso (Step)",
            termStepDesc: "Una actualización de pesos. Alimenta un lote de ejemplos, calcula la pérdida, calcula gradientes, actualiza pesos. Listo.",
            termEpoch: "Época (Epoch)",
            termEpochDesc: "Un recorrido completo por todos los datos de entrenamiento. Si tienes 1.000 ejemplos y un tamaño de lote de 100, una época = 10 pasos.",
            termBatch: "Lote / Mini-lote",
            termBatchDesc: "Un lote es el número de ejemplos de entrenamiento que la red procesa antes de actualizar sus pesos una vez. Procesar todo a la vez es demasiado costoso, así que dividimos los datos en trozos pequeños.",
            textDemoHint: "Observa cómo la ventana de contexto se desliza por el texto. Cada posición crea un ejemplo de entrenamiento: la ventana es la entrada, el siguiente carácter es el objetivo.",
            supervisedLearning: "Este enfoque — donde conocemos la respuesta correcta para cada ejemplo de entrenamiento — se llama aprendizaje supervisado. El modelo 'supervisa' su propia corrección comparando predicciones con objetivos conocidos.",
        },
        makingItLearn: {
            title: "Haciendo que Aprenda",
            lead: "Conoces la dirección. Conoces el tamaño. Ahora juntemos todo — calculemos la pérdida, sigamos el gradiente y veamos cómo los pesos mejoran paso a paso.",
            peak4: "Acabas de hacer lo que tardó cuarenta años en descubrirse.",
            peak5: "Mira cómo baja la pérdida. La máquina está aprendiendo.",
            reflection3: "Cada paso es pequeño. Pero miles de pasos pequeños en la dirección correcta pueden resolver problemas que ningún humano podría programar a mano.",
            whatIf3Title: "¿Y si la tasa de aprendizaje es exactamente 0?",
            whatIf3Text: "Los pesos nunca cambian. El gradiente se calcula, pero se multiplica por cero antes de aplicarse. La red queda congelada en su inicialización aleatoria para siempre — literalmente no puede aprender. Por eso η > 0 es esencial.",
        },
        training: {
            sectionTitle: "Entrenamiento: De Un Paso a Miles",
            sectionLead: "Ya viste un paso de entrenamiento. Ahora vamos a repetirlo, ajustarlo y ver cómo los pesos encuentran su camino hacia una solución.",
            repeatedIntro: "Un paso nos acercó, pero aún no llegamos. ¿Qué pasa si repetimos este proceso una y otra vez? Cada paso empuja los pesos un poco más cerca de los valores correctos.",
            repeatedChallenge: {
                question: "¿Cuántos pasos necesita la pérdida para llegar casi a cero? Observa la curva — ¿cuándo se ralentiza la mejora?",
                hint: "La pérdida baja rápido al principio porque los gradientes son pronunciados. Los pasos posteriores hacen ajustes mínimos. Esto es típico del descenso de gradiente.",
                success: "¡La pérdida converge! Los primeros pasos hicieron grandes mejoras; los últimos refinaron. Este patrón de 'rápido luego lento' es universal en el entrenamiento de redes neuronales.",
            },
            divergenceIntro: "Pero espera — en el paso de entrenamiento anterior, solo restamos una pequeña fracción del gradiente. ¿Qué pasa si restamos el gradiente completo? Vamos a averiguarlo:",
            lrIntro: "La tasa de aprendizaje (η) controla qué tan grande es cada paso. Después de calcular el gradiente, no saltamos toda la cantidad — tomamos una fracción. Esa fracción es la tasa de aprendizaje.",
            lrChallenge: {
                question: "¿Puedes encontrar la tasa de aprendizaje que converge más rápido sin divergir? ¿Qué η llega a baja pérdida en menos pasos?",
                hint: "Prueba primero los tres preajustes. Demasiado pequeña = avance lento. Demasiado grande = la pérdida explota. El punto óptimo está en algún lugar intermedio.",
                success: "¡Lo encontraste! El η óptimo equilibra el tamaño del paso con la estabilidad. Esta es una de las decisiones de hiperparámetros más importantes en el aprendizaje profundo.",
            },
            trajectoryIntro: "Veamos la imagen completa del aprendizaje. Abajo hay un mapa de todas las combinaciones posibles de pesos. Azul oscuro significa baja pérdida. Rojo significa alta pérdida. Observa cómo los pesos viajan desde su punto inicial aleatorio hacia una buena solución.",
            terminologyIntro: "Antes de continuar, aclaremos algunos términos que verás en todas partes en el aprendizaje automático.",
            liveIntro: "La teoría es una cosa. Verlo suceder es otra. La demostración a continuación ejecuta pasos de entrenamiento reales en una sola neurona.",
            liveP1: "Pulsa el botón de entrenamiento y observa. La pérdida debería bajar. La predicción debería acercarse al objetivo. Cada clic ejecuta un ciclo de paso hacia adelante, retropropagación y actualización de pesos — el mismo proceso que acabas de construir a mano, pero en vivo.",
            liveDemoLabel: "Interactivo · Entrenamiento en Vivo",
            liveDemoHint: "Haz clic en 'Entrenar' para ejecutar un paso de entrenamiento. Observa cómo los pesos se actualizan y la pérdida disminuye en tiempo real.",
            supervisedTitle: "¿Qué es el aprendizaje supervisado?",
            supervisedDef: "Aprendizaje supervisado = entrenamiento con respuestas correctas conocidas. Cada ejemplo es un par (entrada, respuesta correcta). El trabajo de la red es encontrar pesos que mapeen entradas a respuestas correctas en todos los pares.",
            supervisedExamplesTitle: "Más allá del lenguaje: el aprendizaje supervisado está en todas partes",
            supervisedCard1Input: "Imagen",
            supervisedCard1Output: "Gato / Perro",
            supervisedCard2Input: "Email",
            supervisedCard2Output: "Spam / No",
            supervisedCard3Input: "Radiografía",
            supervisedCard3Output: "Limpio / Tumor",
            supervisedExample1: "Clasificación de imágenes — entrada: una foto; respuesta correcta: \"gato\" o \"perro\". La red aprende qué patrones de píxeles corresponden a cada etiqueta.",
            supervisedExample2: "Detección de spam — entrada: un correo electrónico; respuesta correcta: \"spam\" o \"no spam\". La red aprende qué patrones de palabras señalan correo no deseado.",
            supervisedExample3: "Diagnóstico médico — entrada: una radiografía; respuesta correcta: \"tumor presente\" o \"limpio\". La red aprende las características visuales que usan los radiólogos.",
            supervisedNote: "No todo el aprendizaje es supervisado. El aprendizaje no supervisado encuentra estructura sin etiquetas. El aprendizaje auto-supervisado genera sus propias etiquetas a partir de los datos — que es exactamente cómo se entrenan los modelos de lenguaje como GPT. Veremos esos enfoques más adelante.",
            textDemo: {
                title: "Datos de Entrenamiento del Texto",
                windowSize: "Ventana de contexto",
                step: "Paso {n} de {total}",
                epoch: "Época {n}",
                play: "▶ Reproducir",
                pause: "⏸ Pausar",
                stepBtn: "⏭ Paso",
                reset: "🔄 Reiniciar",
                speed: "Velocidad",
                epochNote: "Un recorrido por los datos = 1 época. En el entrenamiento real, repetimos cientos de veces.",
                shortcutsHint: "Atajos: ←/→ paso · Espacio reproducir/pausar",
            },
        },
        trainingAtScale: {
            title: "Entrenamiento a Escala",
            lead: "Una neurona, un ejemplo, un paso. Esa es la versión de juguete. El entrenamiento real procesa miles de ejemplos en lotes, repite durante muchas épocas y debe evitar una trampa peligrosa: el sobreajuste.",
            multiNeuronTeaser: "Todo lo que hemos hecho con una sola neurona se extiende a redes con miles. Cada neurona recibe su propio gradiente, todos actualizados simultáneamente. Las matemáticas son las mismas — solo aplicadas en paralelo a través de cada peso en la red.",
            multiNeuronTeaser2: "En la siguiente sección, verás una red real con 27 neuronas de salida prediciendo caracteres. Pero primero, asegurémonos de que nuestro proceso de entrenamiento es lo suficientemente robusto para manejar esa escala.",
            reflection4: "La brecha entre la pérdida de entrenamiento y la pérdida de validación es la brecha entre memorizar y comprender.",
        },
        toyPredictor: {
            title: "Predictor de Vocales",
            hint: "Una pequeña red de 5 neuronas que aprende a predecir la siguiente vocal. Observa cómo cambian los pesos mientras entrena.",
            inputLabel: "Vocal de entrada (haz clic para seleccionar)",
            predictionLabel: "Predicciones después de \"{v}\"",
            targetTag: "objetivo",
            weightsLabel: "Matriz de pesos (5×5)",
            lossLabel: "Pérdida",
            stepCount: "Paso {n}",
            trainOne: "Entrenar 1 paso",
            autoTrain: "▶ Auto-entrenar",
            stop: "⏸ Detener",
            reset: "↺ Reiniciar",
            converged: "¡La red aprendió el patrón! Cada vocal predice correctamente la siguiente en la secuencia.",
        },
        beatMachine: {
            title: "Vence a la Máquina",
            hint: "¿Puedes predecir el siguiente carácter mejor que una red bigrama entrenada? 10 rondas, tú vs la máquina.",
            you: "Tú",
            network: "Red",
            round: "Ronda {n}/{total}",
            contextLabel: "Contexto",
            prompt: "¿Qué carácter viene después?",
            yourGuess: "Tu predicción",
            networkPredictions: "Predicciones de la red",
            next: "Siguiente ronda →",
            seeResults: "Ver resultados",
            youWin: "¡Le ganaste a la máquina!",
            networkWins: "La red gana esta ronda.",
            summary: "La red usa probabilidades de bigramas aprendidas de miles de ejemplos de texto. Siempre elige el carácter estadísticamente más probable.",
            playAgain: "↺ Jugar de nuevo",
        },
        contextLimit: {
            title: "Limitaciones de la Ventana de Contexto",
            hint: "Observa cómo la precisión de predicción cambia con el tamaño del contexto. Más contexto = mejores predicciones.",
            windowLabel: "Ventana de contexto:",
            contextWindow: "contexto",
            predictNext: "predecir",
            modelSees: "El modelo ve:",
            predicts: "predice →",
            trueAnswer: "Respuesta real",
            insight1: "Con solo 1 carácter de contexto, el modelo no puede distinguir 'q' después de 'the ' vs 'q' después de cualquier otra cosa. Trata todas las q's igual.",
            insight2: "Dos caracteres ayudan: 'qu' es mucho más informativo que solo 'u'. Pero los patrones de largo alcance siguen siendo invisibles.",
            insight3: "Tres caracteres capturan patrones comunes como 'tho' → 'u' (thought). Pero para entender verdaderamente el contexto, necesitamos más — y eso es lo que las capas ocultas y los embeddings proporcionan.",
        },
        fromNumbers: {
            title: "De Números a Letras",
            lead: "Hemos estado trabajando con números abstractos. Pero ¿recuerdas el modelo bigrama? Predecía el siguiente carácter. ¿Pueden nuestras neuronas hacer eso?",
            vowelPatternIntro: "Queremos enseñar a una red diminuta un patrón simple: después de 'a' viene 'e', después de 'e' viene 'i', después de 'i' viene 'o', después de 'o' viene 'u', y después de 'u' viene 'a' otra vez. Cinco vocales ciclando en orden — suficientemente simple para nosotros, pero la red tiene que descubrirlo desde cero.",
            bigramCallback: "En el capítulo de bigramas, contamos frecuencias de pares de caracteres para predecir el siguiente. Ahora haremos lo mismo — pero en vez de contar, la red aprenderá los patrones ajustando pesos.",
            toyIntro: "Antes de abordar el alfabeto completo de 27 caracteres, empecemos en pequeño. Cinco vocales. Una neurona por vocal. Una red tan pequeña que puedes ver cada peso individual.",
            toyOutro: "Esa pequeña red acaba de aprender a predecir la siguiente vocal a partir de nada más que números aleatorios y descenso de gradiente. El mismo proceso escala a cualquier número de caracteres.",
            encodingIntro: "Pero espera — las neuronas solo entienden números. ¿Cómo alimentamos letras a una red? Necesitamos una forma de convertir caracteres en números.",
            encodingCaveat: {
                title: "Una nota sobre codificaciones",
                text: "Las redes neuronales reales no usan la posición alfabética como entrada — eso implica que 'z' es de alguna manera 26× más que 'a'. Veremos mejores codificaciones (embeddings) en el capítulo MLP, donde cada carácter obtiene su propio vector aprendido.",
            },
            challengeIntro: "¿Crees que entiendes los patrones? Intenta vencer a la red. Ha aprendido estadísticas de bigramas de miles de ejemplos — ¿puede tu intuición igualar sus tablas de probabilidad?",
            contextLimitIntro: "Nuestra red de una sola capa tiene una limitación fundamental: solo puede ver un carácter a la vez. ¿Qué pasa cuando la respuesta depende de más contexto?",
            mlpBridge: "Para arreglar esto, necesitamos dos cosas: más contexto y una forma más inteligente de representar caracteres. Más contexto significa mirar 2, 3 o más caracteres anteriores. Representaciones más inteligentes significa aprender qué tienen en común los caracteres. Eso son los embeddings — y eso es el capítulo MLP.",
            trainingDataIntro: "Primero, veamos de dónde vienen los datos de entrenamiento. Cada posición en el texto se convierte en un ejemplo: ",
            trainingDataIntroHighlight: "la ventana de contexto es la entrada",
            trainingDataIntroEnd: ", el siguiente carácter es el objetivo.",
            p1: "Si tenemos 27 caracteres posibles (a–z más espacio), necesitamos 27 neuronas de salida — cada una produce una puntuación para su carácter. Haz clic en diferentes caracteres de entrada para ver cómo la red distribuye sus predicciones.",
            networkViz: {
                label: "Interactivo · Diagrama de Red",
                arch: "1 entrada → 27 salidas",
                inputPrompt: "Haz clic en un carácter de entrada",
                topRawScores: "Puntuaciones brutas (logits)",
                logitsNote: "Estos son logits — puntuaciones brutas, NO probabilidades. Observa que pueden ser negativos y no suman 1.",
                hint: "Haz clic en diferentes entradas para ver cómo la red distribuye sus puntuaciones brutas entre 27 salidas.",
            },
            softmaxMath: {
                title: "Mates: Por qué softmax(Wx) Recupera la Tabla de Bigramas",
                desc: "Un resultado hermoso: la matriz de pesos óptima W de 27×27 codifica exactamente las log-probabilidades de bigramas.",
                intro: "Aquí está la conexión matemática notable. Nuestra red calcula softmax(W·x) donde W es una matriz 27×27 y x es un vector one-hot que selecciona una fila. La probabilidad del carácter j siguiendo al carácter i es:",
                explain: "Cuando x es un vector one-hot para el carácter i, el producto matricial W·x simplemente selecciona la fila i de W. Así que Wᵢⱼ es el logit (puntuación bruta) para el carácter j dada la entrada i. Tras el entrenamiento, el Wᵢⱼ óptimo converge a log P(j|i) — el logaritmo de la probabilidad bigrama. Softmax luego exponencia y normaliza, recuperando la distribución bigrama exacta.",
                note: "Por eso la red neuronal y la tabla de conteo dan la misma respuesta: con 27 entradas y 27 salidas, la matriz de pesos tiene exactamente 27×27 = 729 parámetros — el mismo número de entradas que la tabla de bigramas.",
            },
            p2: "Estas puntuaciones brutas — llamadas logits — no suman 1. No son probabilidades todavía. Necesitamos una función que convierta cualquier lista de números en una distribución de probabilidad válida.",
            softmaxHint: "Alterna entre logits brutos y probabilidades softmax. Prueba el deslizador de temperatura para ver cómo agudiza o aplana la distribución.",
            p3: "Ahora tenemos un sistema completo: introduce una ventana de contexto de caracteres, calcula 27 puntuaciones, aplica softmax y obtén una distribución de probabilidad sobre el siguiente carácter.",
            p4: "Aquí está el resultado asombroso. Entrena esta red neuronal de una sola capa con el mismo texto que el modelo de bigramas usó para contar...",
            comparisonLabel: "Red Neuronal vs Tabla de Bigramas",
            comparisonHint: "Observa cómo las probabilidades aprendidas por la red neuronal convergen hacia los mismos valores que la tabla de frecuencias de bigramas.",
            p5: "¡Converge exactamente a las mismas probabilidades que la tabla de frecuencias de bigramas! La red neuronal aprende lo que el conteo habría dado.",
            whyCalloutTitle: "¿Por qué el mismo resultado?",
            whyCalloutText: "Con un solo carácter de entrada y sin capas ocultas, la solución matemáticamente óptima ES la tabla de bigramas. La arquitectura limita lo que se puede aprender. Para superar al bigrama, necesitamos cambios estructurales: ventanas de contexto más grandes, capas ocultas y una forma más inteligente de representar caracteres.",
            peak6: "Números aleatorios aprendieron lo que el conteo nos dio.",
            p6: "Esto es hermoso y limitante a la vez. Para superar al bigrama, necesitamos ventanas de contexto más grandes, capas ocultas y una forma más inteligente de representar caracteres. Eso es exactamente lo que el siguiente capítulo ofrece.",
            multiNeuron: {
                title: "27 Neuronas de Salida",
                inputLabel: "Entrada: \"th\" → prediciendo siguiente carácter",
                logitsLabel: "Puntuaciones brutas (logits) — NO suman 1",
            },
            softmax: {
                title: "Transformación Softmax",
                rawBtn: "Logits Brutos",
                softmaxBtn: "Después de Softmax",
                sumLabel: "Suma",
                rawHint: "Los logits brutos pueden ser cualquier número — positivos, negativos, grandes, pequeños. NO son probabilidades.",
                softmaxHint: "Softmax convierte cualquier lista de números en una distribución de probabilidad que suma 1. Menor temperatura = más aguda, mayor = más plana.",
                neuronsLabel: "neuronas",
                probsLabel: "probabilidades",
                logitsLabel: "logits",
            },
        },
        bridge: {
            title: "El Puente: De Tablas a Parámetros",
            lead: "Aquí está la recompensa. Una red neuronal de una sola capa entrenada para predecir el siguiente carácter converge exactamente a las mismas probabilidades que una tabla de conteo de bigramas. Contar y aprender llegan a la misma respuesta.",
            p1: "Un modelo de bigramas almacena un conteo por cada par de caracteres. Una red neuronal almacena parámetros compartidos que codifican conocimiento sobre todos los pares a la vez. Cuando añades una capa oculta, la red va más allá: aprende que las vocales se comportan de manera similar, que ciertos grupos de consonantes comparten patrones. El conocimiento sobre la 'a' se transfiere a la 'e' porque activan neuronas similares.",
            p2: "La visualización a continuación muestra ambos sistemas lado a lado.",
            p2Highlight: "Observa cómo las predicciones de la red neuronal convergen hacia la tabla de bigramas",
            p2End: " — y luego la superan, porque los parámetros aprendidos generalizan donde los conteos brutos no pueden.",
            insightTitle: "De Tablas a Representaciones",
            insightText: "Una tabla de bigramas almacena 9.216 conteos independientes. Una red neuronal con una pequeña capa oculta almacena menos parámetros — pero organizados para que caracteres similares compartan estructura. Esta es la semilla de la idea que se convierte en word embeddings, atención y modelos de lenguaje modernos.",
            p3: "Este puente — del conteo al aprendizaje — es el salto conceptual más importante en el modelado del lenguaje. Todo lo que sigue se basa en él.",
            explanation: {
                title: "Del Conteo al Aprendizaje",
                text: "Una tabla N-gram necesita una nueva fila para cada contexto posible. Una red neuronal aprende pesos compartidos que pueden manejar contextos que NUNCA ha visto antes al notar similitudes."
            }
        },
        overfitting: {
            label: "El Problema del Sobreajuste",
            heading: "El Riesgo del Sobreajuste",
            lead: "Una red que entrena perfectamente en cada ejemplo puede fallar completamente con datos nuevos. Memorizó en lugar de aprender. Esto es el sobreajuste — uno de los conceptos más importantes en todo el aprendizaje automático.",
            p1: "Cuando una red entrena, la pérdida disminuye y las predicciones mejoran. El instinto natural es seguir — entrenar más, reducir la pérdida lo máximo posible. Pero esto lleva a una trampa: la red puede lograr un error casi nulo en los ejemplos de entrenamiento sin aprender nada general. Memoriza los patrones específicos de los datos que vio, incluyendo el ruido y las peculiaridades, y se vuelve inútil con ejemplos nuevos.",
            p2: "Piensa en un estudiante preparándose para un examen. Un estudiante memoriza cada respuesta de cada problema de práctica sin entender los conceptos subyacentes. Otro estudiante aprende los principios y puede aplicarlos a nuevos problemas. En el examen de práctica, ambos sacan nota perfecta. En el examen real con preguntas diferentes, solo el segundo estudiante tiene éxito. El primer estudiante sobreajustó al conjunto de práctica.",
            p3: "La solución es una división entrenamiento/validación. Reserva una porción de los datos — digamos el 20% — que el modelo nunca ve durante el entrenamiento. Mide el rendimiento tanto en el conjunto de entrenamiento (datos de los que aprende el modelo) como en el conjunto de validación (datos reservados). La pérdida de entrenamiento siempre disminuye. La pérdida de validación sigue una curva en U: mejora mientras el modelo aprende patrones reales, luego empeora cuando empieza a memorizar ruido específico del entrenamiento.",
            p4: "La complejidad del modelo amplifica este compromiso. Un modelo pequeño tiene dificultades para ajustarse incluso a los datos de entrenamiento (subajuste). Un modelo del tamaño adecuado se ajusta a los datos de entrenamiento y generaliza a datos nuevos. Un modelo enorme con muchos más parámetros de los necesarios memoriza perfectamente el conjunto de entrenamiento pero falla con los datos de validación (sobreajuste). Más capacidad no siempre es mejor.",
            p5: "¿Cómo combatimos el sobreajuste? Más datos de entrenamiento diluyen el efecto de memorización. Las técnicas de regularización penalizan la complejidad del modelo. La parada temprana detiene el entrenamiento cuando la pérdida de validación deja de mejorar. El Dropout, el aumento de datos y BatchNorm ayudan. La clave: la pérdida de validación es la única métrica honesta. Un modelo puede engañarte con un rendimiento de entrenamiento perfecto siendo completamente inútil en la práctica.",
            conclusion: "El sobreajuste es la razón por la que dividimos los datos, por la que vigilamos de cerca las métricas de validación, y por la que los modelos más grandes no siempre son mejores. Todo profesional del ML aprende esta lección — generalmente viendo cómo un modelo entrena hasta un rendimiento 'perfecto' y luego falla espectacularmente con datos reales. El explorador MLP que verás a continuación detecta el sobreajuste automáticamente, pero ahora sabes qué significa y por qué importa.",
            callout1Title: "Por qué no podemos simplemente minimizar la pérdida de entrenamiento",
            callout1Text: "Llevar la pérdida de entrenamiento a cero es fácil — solo memoriza cada ejemplo de entrenamiento. Pero el objetivo no es aprobar un examen que ya has visto. Es predecir patrones que nunca has encontrado. La pérdida de validación es la única medida honesta de si un modelo ha aprendido algo real.",
            callout2Title: "La prueba de generalización",
            callout2Text: "Un modelo que funciona bien con los datos de entrenamiento pero mal con los de validación ha fallado la prueba de generalización. Aprendió el ruido, no la señal. En ML, el conjunto de validación es el juez definitivo — son los únicos datos que el modelo no ha visto y con los que no puede hacer trampa.",
            visual1Label: "Comparación · Buen Ajuste vs Sobreajuste",
            visual1Hint: "Los mismos datos de entrenamiento, dos modelos diferentes. El modelo sobreajustado logra error cero de entrenamiento ajustando una curva compleja a cada punto. Pero con datos de prueba nuevos (círculos huecos), falla. El modelo de buen ajuste acepta algo de error de entrenamiento pero generaliza correctamente.",
            visual2Label: "Interactivo · Pérdida de Entrenamiento vs Validación en el Tiempo",
            visual2Hint: "Arrastra el deslizador de épocas para ver cómo evolucionan las pérdidas de entrenamiento y validación. La pérdida de entrenamiento siempre disminuye. La pérdida de validación forma una curva en U — mejorando, luego empeorando cuando comienza el sobreajuste. El punto óptimo de parada es donde la pérdida de validación es más baja.",
            statusUnderfitting: "Aún aprendiendo",
            statusOptimal: "Óptimo",
            statusOverfitting: "Sobreajuste",
        },
        powerAndLimits: {
            title: "Poder, Límites y Qué Viene Después",
            lead: "Una sola neurona traza líneas rectas. Ese es tanto su poder como su límite.",
            p1: "Considera el problema XOR: cuatro puntos en un plano 2D donde las esquinas opuestas comparten una etiqueta. Ninguna línea recta puede separarlos.",
            p1Highlight: "Una sola neurona fallará en XOR sin importar cuánto la entrenes.",
            p1End: "Esto fue demostrado en 1969 y congeló la investigación en redes neuronales durante casi dos décadas.",
            p2: "La solución es simple: apilar neuronas en capas. Una capa oculta de solo dos neuronas puede resolver XOR. La primera capa divide el espacio en regiones curvas; la segunda las combina. Una red con una capa oculta suficientemente grande puede aproximar cualquier función continua — el Teorema de Aproximación Universal.",
            p3: "Pero una sola neurona o una red poco profunda sigue procesando una entrada de tamaño fijo. No tiene memoria a través de pasos de tiempo ni forma de enfocarse en las partes más relevantes de su contexto. Para el lenguaje, esto importa: los pronombres se refieren a sustantivos muchos tokens atrás. Una ventana fija no puede salvar esa brecha de manera confiable.",
            p4: "Los bloques de construcción que has aprendido — sumas ponderadas, activaciones, retropropagación, descenso de gradiente — son los mismos bloques dentro de cada sistema de IA moderno. El siguiente paso es apilarlos en un perceptrón multicapa y aplicarlos directamente al lenguaje.",
            calloutTitle: "Siguiente: Modelo de Lenguaje MLP",
            calloutText: "En el próximo capítulo, reemplazamos la tabla de búsqueda N-gram con una red neuronal que utiliza embeddings densos y pesos aprendidos. Verás a un MLP generalizar más allá de las coincidencias exactas y producir mejor texto con menos parámetros.",
        },
        cta: {
            title: "Continúa el Viaje",
            subtitle: "Nuestra red igualó perfectamente al bigrama. Pero para superarlo, necesitamos más contexto — y una forma más inteligente de representar caracteres. Eso es exactamente lo que ofrecen los embeddings.",
            whatsNextTitle: "Qué viene en el capítulo MLP",
            whatsNext1: "Más contexto — alimentar la red con los últimos 3–5 caracteres en lugar de solo uno",
            whatsNext2: "Embeddings — representar cada carácter como un vector denso sobre el que la red puede razonar",
            whatsNext3: "Redes más profundas — capas ocultas que componen patrones simples en estructura compleja",
            labButton: "Abrir Lab Libre",
            labDesc: "Experimenta con perceptrones, activaciones y entrenamiento en el playground interactivo.",
            mlpButton: "Siguiente: Construyendo un Modelo de Lenguaje",
            mlpDesc: "Apila neuronas en capas, añade embeddings y construye un modelo de lenguaje real a nivel de caracteres.",
        },
        footer: {
            text: "Del conteo al aprendizaje — ahora entiendes los bloques básicos de las redes neuronales. Siguiente: apílalos en capas y aplícalos al lenguaje.",
            brand: "LM-LAB · Modo Educativo"
        }
    }
};
