import { TranslationDictionary } from './types';

export const es: TranslationDictionary = {
    common: {
        language: "Idioma",
        loading: "Cargando...",
        error: "Error",
        comingSoon: "Próximamente",
        backToProjects: "Volver a Proyectos",
        toggleLanguage: "Cambiar idioma",
        code: "Código",
        liveDemo: "Demo en Vivo",
        viewCaseStudy: "Ver Caso de Estudio",
    },
    nav: {
        home: "Inicio",
        projects: "Proyectos",
        lab: "Laboratorio",
        notes: "Notas",
    },
    projects: {
        hero: {
            badge: "Investigación y Desarrollo",
            titlePrefix: "Construyendo la",
            titleSuffix: "Frontera Digital.",
            description: "Una colección curada de mi trabajo en sistemas distribuidos, infraestructura de IA y computación de alto rendimiento.",
        },
        flagship: {
            badge: "Proyecto Insignia",
            featured: "Destacado",
            liveDemo: "Demo en Vivo Disponible",
            title: "LM-Lab",
            description: "Una plataforma interactiva para explorar arquitecturas de modelos de lenguaje desde primeros principios. Visualiza matrices de transición, sondea dinámicas de inferencia y genera texto — todo impulsado por un backend FastAPI en vivo con PyTorch.",
            highlights: {
                inference: {
                    title: "Inferencia en Vivo",
                    desc: "Predicción del siguiente carácter en tiempo real con distribuciones de probabilidad",
                },
                matrix: {
                    title: "Matriz de Transición",
                    desc: "Mapa de calor interactivo de las probabilidades bigrama aprendidas",
                },
                generation: {
                    title: "Generación de Texto",
                    desc: "Genera texto con temperatura configurable y seguimiento paso a paso",
                },
            },
            cta: {
                explorer: "Abrir Laboratorio",
                architecture: "Ver Arquitectura",
                demo: "Ejecutar Demo Interactiva",
            },
        },
        experiments: {
            title: "Experimentos Seleccionados",
            items: {
                distriKv: {
                    title: "Distri-KV",
                    desc: "Un almacén clave-valor distribuido implementado en Go, con consenso Raft y sharding.",
                },
                neuroVis: {
                    title: "NeuroVis",
                    desc: "Herramienta de visualización interactiva para activaciones de redes neuronales en tiempo real.",
                },
                autoAgent: {
                    title: "Auto-Agent",
                    desc: "Un framework de agente autónomo ligero enfocado en tareas de codificación.",
                },
            },
        },
    },
    notes: {
        hero: {
            est: "EST. 2024",
            archive: "ARCHIVO DE INVESTIGACIÓN",
            titlePrefix: "El Cuaderno de",
            titleSuffix: "Ingeniería",
            description: "Exploraciones en <strong class='text-primary'>inteligencia distribuida</strong>, topología de alta dimensión y la mecánica del software moderno.",
        },
        featured: {
            badge: "ÚLTIMA INVESTIGACIÓN",
            readTime: "{minutes} min de lectura",
            figure: "Figura 1.0: Visualización del Espacio Latente",
        },
        grid: {
            title: "Entradas Anteriores",
        },
        backToNotes: "Volver a Notas",
        noteNotFound: "Nota no encontrada",
    },
    lab: {
        bigram: "Bigrama",
        ngram: "N-Gram",
        mlp: "MLP",
        transformer: "Transformer",
        neuralNetworks: "Redes Neuronales",
        shell: {
            allModels: "Volver al Lab",
        },
        active: "Lab. Activo",
        waking: "Despertando",
        serverWarning: {
            title: "ARRANQUE EN FRÍO DETECTADO",
            subtitle: "PROTOCOLO DE CONTENCIÓN ACTIVO",
            message: "El servidor está despertando de su hibernación. Las instancias gratuitas de Render se apagan tras inactividad — sí, lo hosteo en un servidor gratis porque soy un estudiante sin un duro.",
            donate: "Si la espera de 30s te resulta insoportable, invítame a un café para que pueda pagar un servidor de verdad. O simplemente espera, es entretenimiento gratis.",
            status: "INTENTANDO CONEXIÓN",
            dismiss: "SOBREVIVIRÉ",
            connected: "SEÑAL ADQUIRIDA",
        },
        mode: {
            educational: "Educativo",
            educationalDescription: "Experiencia guiada con explicaciones narrativas y progresivas.",
            freeLab: "Lab Libre",
            freeLabDescription: "Acceso completo a herramientas y visualizaciones para experimentación manual y análisis.",
            selectViewingMode: "Selecciona el Modo de Visualización",
            availableModels: "Modelos Disponibles",
        },
        status: {
            ready: "Listo",
            coming: "Próximo",
        },
        models: {
            bigram: {
                name: "Explorador Bigrama",
                subtitle: "Capítulo 1 · Contando Pares",
                description: "Empieza aquí. El modelo de lenguaje más simple: cuenta con qué frecuencia un carácter sigue a otro, guárdalo en una tabla y muestrea el siguiente carácter. Verás exactamente cómo un modelo genera texto a partir de estadísticas puras — y por qué un solo carácter de memoria no es suficiente.",
            },
            ngram: {
                name: "Laboratorio N-Gram",
                subtitle: "Capítulo 2 · Más Memoria, Más Problemas",
                description: "¿Y si el modelo recuerda dos caracteres? ¿Tres? ¿Cinco? Las predicciones mejoran — pero la tabla explota exponencialmente y el modelo aún no puede generalizar. Descubre los límites fundamentales de los modelos basados en conteo.",
            },
            neuralNetworks: {
                name: "Redes Neuronales",
                subtitle: "Capítulo 3 · Del Conteo al Aprendizaje",
                description: "El conteo chocó contra un muro. Ahora aprendemos. Construye intuición sobre perceptrones, funciones de activación, retropropagación y descenso de gradiente — los bloques que permiten a las máquinas descubrir patrones por sí mismas.",
            },
            mlp: {
                name: "Modelo MLP",
                subtitle: "Capítulo 4 · Modelado Neuronal del Lenguaje",
                description: "Aplica todo lo aprendido: reemplaza la tabla N-gram con una red neuronal que usa embeddings densos y pesos aprendidos. Ve cómo un MLP generaliza más allá de coincidencias exactas y produce mejor texto con menos parámetros.",
            },
            transformer: {
                name: "Arquitectura Transformer",
                subtitle: "Capítulo 5 · La Atención es Todo",
                description: "La arquitectura detrás de GPT y la IA moderna. La auto-atención permite al modelo enfocarse dinámicamente en cualquier parte de la secuencia, eliminando ventanas de contexto fijas. Próximamente.",
            },
        },
        dashboard: {
            chip: "Laboratorio de Interpretabilidad de Modelos",
            suite: "Suite",
            description1: "Explora el funcionamiento interno de los modelos de lenguaje mediante visualizaciones interactivas.",
            description2: "Sigue una ruta guiada o experimenta libremente en el sandbox.",
            launchUnit: "INICIAR UNIDAD",
            secureLock: "BLOQUEO SEGURO",
            footerCopyright: "© 2026 LM-LAB INSTRUMENTS",
            footerSystem: "SISTEMA_INTERPRETABILIDAD",
            secureConnection: "Conexión Segura",
            hardwareMock: "Hardware: v4-8 TPU MOCK",
        },
        placeholders: {
            mlp: {
                title: "Explorador MLP",
                description: "Explorador de modelos de lenguaje Multi-Layer Perceptron. Actualmente en desarrollo - vuelve pronto.",
            },
            transformer: {
                title: "Explorador Transformer",
                description: "Explorador de modelos transformer basados en atención. Actualmente en desarrollo - vuelve pronto.",
            },
        },
        landing: {
            hero: {
                badge: "Unidad de Investigación",
                subtitle: "Laboratorio de Interpretabilidad Interactiva",
                description: "Desmitificando los Modelos de Lenguaje a través de la ingeniería de primeros principios y evidencia visual.",
                subDescription: "Esta unidad se centra en la interpretabilidad mecanística: la ingeniería inversa de los pesos neuronales en conceptos humanos comprensibles.",
                start: "Inicializar Modelo Base",
                recommended: "Recomendado para principiantes",
            },
            highlights: {
                visualizations: "Visualización Interactiva",
                inference: "Inferencia en Vivo",
                guided: "Ruta Guiada",
                backend: "Backend PyTorch",
            },
            learningPath: {
                title: "Ruta de Aprendizaje",
                status: {
                    soon: "En Desarrollo",
                    ready: "Unidad Activa",
                },
            },
            modes: {
                title: "Protocolos de Laboratorio",
                entryTitle: "Elige Tu Experiencia",
                entrySubtitle: "Selecciona cómo quieres explorar el lab. Puedes cambiarlo en cualquier momento.",
                defaultNote: "Usando Modo Educativo por defecto",
                educational: {
                    title: "Modo Educativo",
                    subtitle: "Descubrimiento Guiado",
                    description: "Narrativa paso a paso que explica el 'porqué' detrás de las matemáticas. Ideal para el aprendizaje conceptual.",
                    tag: "Recomendado",
                    features: ["Narrativas guiadas", "Revelaciones progresivas", "Explicaciones conceptuales"],
                },
                freeLab: {
                    title: "Modo Lab Libre",
                    subtitle: "Entorno Sandbox",
                    description: "Acceso total a todas las herramientas de visualización y parámetros de generación. Para experimentación avanzada.",
                    tag: "Avanzado",
                    features: ["Todas las herramientas", "Control de parámetros", "Sin flujo guiado"],
                },
                cta: "Empezar con Bigrama",
                ctaSubtext: "El modelo más simple — el mejor punto de partida",
                changeMode: "Cambiar modo",
                selectedMode: "Seleccionado",
            },
            availableModels: {
                title: "Unidades Biológicas Disponibles",
                enter: "Entrar al Lab",
                locked: "Protocolo Restringido",
            },
            footer: {
                text: "Instrumento Científico v2.2 // Build 2026",
            },
        },
    },
    footer: {
        builtBy: "Construido por",
        sourceAvailable: "El código fuente está disponible en",
    },
    datasetExplorer: {
        title: "Evidencia del Corpus",
        subtitle: "¿Por qué el modelo aprendió '{context}' -> '{next}'?",
        scanning: "Escaneando corpus de entrenamiento...",
        occurrencesFound: "Ocurrencias Encontradas",
        source: "Fuente",
        contextSnippets: "Fragmentos de Contexto",
        noExamples: "No se encontraron ejemplos para esta transición.",
        fetchError: "No se pudieron obtener ejemplos del dataset",
        explorerTitle: "Explorador del Corpus",
        searching: "Buscando en el Dataset...",
        querySequence: "Secuencia Consultada",
        found: "Se encontraron {count} ocurrencias",
        exampleContexts: "Contextos de Ejemplo",
        noExamplesValidation: "No se encontraron ejemplos en el fragmento de validación.",
    },
    training: {
        title: "Insight del Entrenamiento",
        noData: "Ejecuta inferencia para ver datos de entrenamiento",
        tooltip: {
            lossTitle: "¿Qué es la Pérdida (Loss)?",
            lossErrorPrefix: "Error de Predicción:",
            lossError: "La pérdida mide cuán 'sorprendido' está el modelo. Una pérdida alta significa que adivina mal frecuentemente.",
            lossBenchmarkPrefix: "El Referente:",
            lossBenchmark: "Adivinar al azar daría una pérdida de ~4.56 (-ln(1/96)). ¡Cualquier valor menor significa que el modelo ha aprendido algo!",
            lossCurve: "La curva descendente muestra al modelo descubriendo patrones lentamente en tu texto.",
        },
        stats: {
            finalLoss: "Pérdida Final",
            steps: "Pasos",
            batchSize: "Tamaño de Lote",
            learningRate: "Ratio de Aprendizaje",
            parameters: "Parámetros",
            tooltips: {
                finalLoss: "El nivel de error. Al final del entrenamiento, debería ser lo más bajo posible.",
                steps: "Cuántas veces el modelo practicó para mejorar sus predicciones.",
                batchSize: "La cantidad de piezas de información que el modelo procesa a la vez.",
                learningRate: "La velocidad de aprendizaje. Ni muy rápido para no pasarse, ni muy lento para no tardar demasiado.",
                parameters: "El tamaño de la red neuronal o 'cerebro' del modelo.",
            },
        },
    },
    ngram: {
        training: {
            title: "Insights del Entrenamiento",
            stats: {
                totalTokens: "Tokens Totales",
                uniqueContexts: "Contextos Únicos",
                utilization: "Utilización de Contexto",
                sparsity: "Espasidad",
                transitionDensity: "Densidad de Transición",
                subs: {
                    possiblePrefix: "de",
                    possibleSuffix: "posibles",
                    fractionObserved: "Fracción de contextos observados",
                    unseen: "Fracción de contexto no visto",
                },
            },
        },
    },
    landing: {
        hero: {
            status: "Sistema Online :: v2.2",
            role: "Investigación e Ingeniería",
            title: "ADRIAN LAYNEZ ORTIZ",
            tagline1: "Matemáticas e Informática.",
            tagline2: "Interpretabilidad Mecanística · Ingeniería de Alto Rendimiento.",
            cta: {
                lab: "Ver Laboratorio",
                notes: "Leer Notas",
            },
        },
        metrics: {
            research: "Años de Investigación",
            repos: "Repos Open Source",
            projects: "Proyectos Activos",
            curiosity: "Curiosidad",
        },
        about: {
            badge: "Sobre Mí",
            building: "Desarrollando",
            projectTitle: "Motor de Deep Learning — CUDA / C++",
            projectDesc: "Kernels personalizados para operaciones matriciales y retropropagación",
            bio: {
                titlePrefix: "Uniendo Matemáticas Abstractas",
                titleSuffix: "e Inteligencia Artificial",
                p1: "Estudio el Doble Grado en <strong class='text-foreground'>Matemáticas e Ingeniería Informática</strong> en la Universidad Complutense de Madrid. Mi investigación se centra en comprender las redes neuronales a su nivel más profundo — desde la dinámica de gradientes hasta la optimización a nivel de kernel.",
                p2: "Me especializo en <strong class='text-foreground'>Interpretabilidad Mecanística</strong> — la ciencia de realizar ingeniería inversa sobre cómo las redes neuronales representan y procesan la información internamente. En lugar de tratar los modelos como cajas negras, descompongo sus circuitos para entender <em class='text-foreground/80'>por qué funcionan</em>.",
                mission: "Mi misión: hacer los sistemas de IA transparentes a través de un análisis matemático riguroso e ingeniería de bajo nivel.",
            },
        },
        skills: {
            title: "Competencias Técnicas",
            linearAlgebra: "Álgebra Lineal",
            topology: "Topología",
            convexOpt: "Optimización Convexa",
        },
        work: {
            badge: "Trabajo Seleccionado",
            titlePrefix: "Ingeniería desde",
            titleSuffix: "Primeros Principios",
            description: "Cada proyecto comienza con una pregunta. Desde reimplementar papers seminales hasta escribir kernels de GPU desde cero, cada uno es un ejercicio de comprensión profunda.",
            viewAll: "Ver Todos los Proyectos",
            items: {
                nanoTransformer: {
                    title: "Nano-Transformer",
                    desc: "Reproducción desde cero de 'Attention Is All You Need' en PyTorch — Multi-Head Attention, Positional Encodings y LayerNorm implementados sin módulos preconstruidos.",
                },
                cudaKernels: {
                    title: "Kernels Matriciales CUDA",
                    desc: "Kernels de CUDA escritos a mano explorando la optimización SGEMM — desde implementaciones ingenuas hasta estrategias de memoria compartida en mosaico, comparadas con cuBLAS.",
                },
                autograd: {
                    title: "Motor Autograd",
                    desc: "Librería ligera de diferenciación automática en modo inverso. Construye dinámicamente grafos de computación y propaga gradientes mediante la regla de la cadena.",
                },
                mathDl: {
                    title: "Matemáticas del Deep Learning",
                    desc: "Artículos interactivos explorando la teoría rigurosa detrás de la IA moderna — análisis de convergencia SGD, el álgebra lineal de LoRA y geometría diferencial en variedades neuronales.",
                },
                distributed: {
                    title: "Inferencia Distribuida",
                    desc: "Exploraciones arquitectónicas en entrenamiento paralelo de datos, fragmentación de modelos y tuberías de inferencia optimizadas para redes neuronales a gran escala.",
                },
            },
        },
        contact: {
            badge: "Abierto a Oportunidades",
            titlePrefix: "Construyamos",
            titleMiddle: "Algo",
            titleSuffix: "Juntos",
            description: "Ya sea una colaboración de investigación, una oportunidad de pasantía o simplemente una conversación sobre las matemáticas de la inteligencia — me encantaría saber de ti.",
            email: "Contactar",
            github: "Perfil de GitHub",
            githubShort: "GitHub",
            linkedin: "LinkedIn",
        },
    },
    models: {
        bigram: {
            title: "Modelo de Lenguaje Bigrama",
            description: "El bloque fundamental del modelado de secuencias. Un modelo probabilístico que predice el siguiente carácter basándose únicamente en el predecesor inmediato.",
            params: "Parámetros",
            vocab: "Vocabulario",
            trainingData: "Datos de Entrenamiento",
            loss: "Pérdida Final",
            unknown: "Desconocido",
            tooltips: {
                params: "Son como las conexiones del cerebro. Este modelo es simple, por lo que no necesita muchas.",
                vocab: "Es el conjunto de letras y símbolos que el modelo conoce, como su propio alfabeto.",
                trainingData: "La cantidad de texto que el modelo leyó para aprender a escribir.",
                loss: "Es la puntuación de 'error'. Cuanto más baja sea, mejor sabe el modelo qué letra viene a continuación.",
            },
            sections: {
                visualization: {
                    title: "Visualización: Matriz de Transición",
                    description: "Aquí es donde vive el 'conocimiento' del modelo. Para un modelo Bigrama, esta cuadrícula representa qué letras suelen seguir a otras."
                },
                inference: {
                    title: "Inferencia y Generación",
                    description: "Interactúa con el modelo en tiempo real. Observa cómo 'adivina' el siguiente carácter basándose en probabilidades aprendidas."
                },
                architecture: {
                    title: "Arquitectura del Modelo",
                    description: "Una mirada técnica a las 'neuronas' y capas que procesan la información."
                },
                training: {
                    title: "Insights de Entrenamiento",
                    description: "Observando el proceso de aprendizaje. Estas métricas muestran cómo el modelo optimizó sus parámetros reduciendo el error de predicción (pérdida) durante 5000 iteraciones."
                },
            },
            hero: {
                scientificInstrument: "Instrumento Científico v1.0",
                explanationButton: "¿Necesitas una explicación intuitiva?",
                explanationSub: "Entiende la idea central antes de sumergirte en las matemáticas y visualizaciones.",
            },
            matrix: {
                title: "Matriz de Transición",
                activeSlice: "Transición de Slice Activo",
                tryIt: {
                    label: "Pruébalo:",
                    text: "Haz clic en cualquier celda coloreada para ver",
                    highlight: "ejemplos reales de entrenamiento",
                },
                searchPlaceholder: "Resaltar carácter…",
                runInference: "Ejecuta inferencia para generar la matriz de transición",
                tooltip: {
                    title: "¿Cómo leer este gráfico?",
                    desc: "Las filas representan el carácter actual y las columnas el siguiente carácter. Las celdas más brillantes indican mayor probabilidad de transición.",
                    rows: "Filas (Y):",
                    rowsDesc: "La letra que el modelo acaba de escribir.",
                    cols: "Columnas (X):",
                    colsDesc: "La letra que el modelo intenta adivinar.",
                    brightness: "Brillo:",
                    brightnessDesc: "Cuanto más brillante sea un cuadrado, más probable es que ese par de letras aparezca en el texto.",
                    example: "Ejemplo: Si la fila es 'q' y la columna 'u' brilla intensamente, significa que el modelo sabe que después de 'q' casi siempre viene 'u'.",
                },
                slice: "Slice:",
                datasetMeta: {
                    learnedFrom: "Aprendido de",
                    summarizes: "resume",
                    rawChars: "caracteres brutos",
                    inTrain: "en el split de entrenamiento",
                    vocab: "a través de",
                    symbols: "símbolos únicos",
                    corpus: "Nombre del Corpus:",
                    rawText: "Texto Bruto Total:",
                    trainingSplit: "Datos de Entrenamiento:",
                    vocabulary: "Tamaño del Vocabulario:",
                    charTokens: "caracteres",
                },
                probFlow: {
                    badge: "Visualizador de Flujo de Probabilidad",
                    alreadyNormalized: "⚠ La matriz parece pre-normalizada",
                    description: "Explora cómo los conteos brutos se convierten en probabilidades y cómo el modelo muestrea el siguiente token. Este diagrama interactivo muestra el pipeline completo de inferencia: desde seleccionar un carácter de contexto, hasta normalizar su fila en una distribución de probabilidad, hasta muestrear estocásticamente el siguiente token.",
                    step1: "Paso 1: Seleccionar Contexto",
                    step2: "Paso 2: Normalizar",
                    step3: "Paso 3: Muestrear Siguiente Token",
                    currentToken: "Token Actual",
                    typeToChange: "Escribe para cambiar contexto",
                    normalize: "Normalizar",
                    softmax: "Softmax",
                    temperature: "Temperatura",
                    educational: {
                        normTitle: "Normalización Simple",
                        normDesc: "Divide cada conteo por la suma de la fila. Esto convierte frecuencias brutas en probabilidades que suman 1.0.",
                        softmaxTitle: "Softmax (Escalado por Temperatura)",
                        softmaxDesc: "Exponencia valores y normaliza. La temperatura controla la nitidez: temp baja → distribución punteada, temp alta → distribución uniforme.",
                        tempTitle: "Temperatura",
                        tempDesc: "Controla la nitidez de la distribución. Temperatura baja (< 1) concentra la probabilidad en los tokens más probables. Temperatura alta (> 1) la distribuye más uniformemente, produciendo resultados más variados.",
                    },
                    tempLabel: "Temperatura",
                    tempTooltip: "Controla la aleatoriedad. Más baja = más determinista, Más alta = más creativo/aleatorio",
                    sampleButton: "Muestrear Siguiente Token",
                    sample: "Muestrear Siguiente Token",
                    sampling: "Muestreando...",
                    result: "Resultado Muestreado",
                    sampled: "Muestreado",
                    topCandidate: "Candidato principal",
                    mostLikely: "Más Probable",
                    probability: "Probabilidad",
                    roll: "Tirada Aleatoria",
                    explanation: "El modelo lanzó un dado ponderado (tirada = {roll}) y seleccionó '{token}' con probabilidad {prob}%",
                    stochasticNote: "El muestreo es estocástico — cada clic puede producir un resultado diferente incluso para el mismo carácter de contexto.",
                },
                labModeGuide: "Esta es la matriz de transición completa entrenada con ensayos de Paul Graham. Cada fila es un carácter; cada columna es el carácter que le sigue. Celdas más brillantes = transiciones más frecuentes. Haz clic en cualquier celda para ver ejemplos reales del corpus.",
                limitationGuide: "Observa la restricción fundamental: el modelo solo mira el último carácter. No puede aprender que 'th' casi siempre va seguido de 'e', porque cuando ve 'h', la 't' ya está olvidada. Esta memoria de un solo token es exactamente lo que los modelos N-gram y neurales superan.",
                storySteps: {
                    problem: {
                        title: "El Problema",
                        body: "El lenguaje es secuencial — cada carácter depende de lo que vino antes. El desafío es capturar esta estructura computacionalmente. ¿Cómo construimos un modelo que pueda predecir lo que viene después en un flujo de texto?",
                    },
                    representation: {
                        title: "Representando Texto",
                        body: "Antes de modelar el lenguaje, necesitamos decidir cómo representarlo. La elección de representación determina el tamaño del vocabulario, la capacidad del modelo y sus limitaciones.",
                    },
                    solution: {
                        title: "La Solución Bigrama",
                        body: "El enfoque más simple: contar con qué frecuencia cada carácter sigue a todos los demás en un gran corpus de entrenamiento. Estos conteos, una vez normalizados en probabilidades, forman un modelo estadístico completo del lenguaje a nivel de carácter.",
                    },
                    matrix: {
                        title: "La Matriz de Transición",
                        body: "Cada conteo se almacena en una matriz V × V (V = tamaño del vocabulario). Cada fila representa un carácter actual; cada columna representa el siguiente. El brillo de una celda codifica la probabilidad de transición aprendida del texto real.",
                    },
                    probabilities: {
                        title: "De Conteos a Probabilidades",
                        body: "Los conteos brutos se normalizan fila por fila para que cada fila sume 1.0, formando una distribución de probabilidad válida. El modelo puede entonces hacer predicciones concretas: \"Después de 'h', hay un 34% de probabilidad de que el siguiente carácter sea 'e'.\"",
                    },
                    limitation: {
                        title: "La Limitación Fundamental",
                        body: "El modelo bigrama tiene cero memoria más allá del carácter inmediatamente anterior. No puede aprender que 'th' casi siempre va seguido de 'e', porque cuando ve 'h', la 't' ya está olvidada. Este horizonte de un solo token es lo que motiva los modelos N-gram y neurales.",
                    },
                },
                representation: {
                    charTitle: "Tokens a nivel de carácter",
                    charBody: "Vocabulario pequeño y fijo (~96 caracteres ASCII imprimibles). Toda entrada posible es representable. Simple de implementar y visualizar — ideal para entender los fundamentos.",
                    wordTitle: "Tokens a nivel de palabra",
                    wordBody: "Unidades semánticas más ricas, pero el vocabulario puede alcanzar 50.000–500.000 entradas. Las palabras raras causan escasez; las palabras no vistas en inferencia causan fallos. Mucho más difícil de escalar.",
                },
                builderLabel: "Constructor bigrama paso a paso",
            },
            inference: {
                title: "Consola de Inferencia",
                probDist: "1. Distribución de Probabilidad",
                probDistDesc: "Escribe una frase para ver los top-k caracteres más probables a continuación.",
                tooltip: {
                    title: "¿Qué es la Inferencia?",
                    process: "El Proceso:",
                    processDesc: "El modelo toma tu texto, mira el",
                    processHighlight: "último carácter",
                    processEnd: ", y busca las probabilidades de lo que viene después en su cerebro (la Matriz).",
                    topK: "Top-K:",
                    topKDesc: "Solo mostramos los ganadores principales. Si K=5, ves los 5 candidatos más probables.",
                    note: "Nota: Este modelo es \"determinista\" en sus probabilidades pero \"estocástico\" (aleatorio) cuando realmente elige un carácter para generar texto.",
                },
                lastChar: "Último car.:",
                form: {
                    input: "Texto de Entrada",
                    placeholder: "Escribe texto para analizar...",
                    topK: "Predicciones Top-K",
                    analyze: "Analizar",
                    analyzing: "Analizando...",
                },
            },
            stepwise: {
                title: "Predicción Paso a Paso",
                mainTitle: "2. Predicción Paso a Paso",
                description: "Observa al modelo predecir una secuencia carácter por carácter.",
                form: {
                    input: "Texto de Entrada",
                    placeholder: "Texto inicial...",
                    steps: "Pasos de Predicción",
                    predict: "Predecir Pasos",
                    predicting: "Prediciendo...",
                },
                table: {
                    step: "Paso",
                    char: "Carácter",
                    prob: "Probabilidad",
                },
                result: "Resultado:",
            },
            generation: {
                title: "Patio de Generación",
                mainTitle: "3. Generación de Texto",
                description: "Deja que el modelo alucine texto muestreando de la distribución.",
                tooltip: {
                    title: "¿Cómo se genera el texto?",
                    sampling: "Muestreo:",
                    samplingDesc: "El modelo no solo elige la respuesta #1. \"Tira un dado\" ponderado por probabilidades. Por eso puede generar texto diferente cada vez.",
                    temp: "Temperatura:",
                    tempDesc: "Valores más altos hacen que el dado sea más \"loco\" (más aleatorio). Valores más bajos lo hacen más \"seguro\" y repetitivo.",
                    note: "¡Prueba temperatura 2.0 para ver galimatías, o 0.1 para verlo atascarse en bucles!",
                },
                form: {
                    startChar: "Carácter Inicial",
                    numTokens: "Número de Tokens",
                    temp: "Temperatura",
                    generate: "Generar",
                    generating: "Generando...",
                },
                copyToClipboard: "Copiar texto generado",
            },
            architecture: {
                title: "Especificación Técnica",
                subtitle: "Desglose detallado del mecanismo interno del modelo, capacidades y restricciones.",
                mechanism: "Mecanismo de Inferencia",
                capabilities: "Capacidades",
                constraints: "Restricciones",
                modelCard: {
                    title: "Tarjeta del Modelo",
                    type: "Tipo de Arquitectura",
                    complexity: "Clasificación de Complejidad",
                    useCases: "Casos de Uso Principales",
                    description: "Descripción",
                },
                tooltips: {
                    matrixW: {
                        title: "¿Qué es la Matriz W?",
                        desc: "Es esencialmente una tabla de búsqueda de 9216 números (96x96 caracteres en el vocabulario). Cada número representa la \"puntuación no normalizada\" de cuán probable es que un carácter siga a otro.",
                    },
                    softmax: {
                        title: "¿Qué es Softmax?",
                        desc: "Softmax toma puntuaciones brutas (logits) y las aplasta en una distribución de probabilidad. Todos los números se vuelven positivos y suman 1 (100%).",
                    },
                    loss: {
                        title: "¿Qué es la Pérdida (Entropía Cruzada)?",
                        desc: "La pérdida mide la distancia entre la predicción del modelo y la verdad. Si la verdad es 'n' y el modelo dio a 'n' un 0.1% de probabilidad, la pérdida será muy alta. El entrenamiento es el proceso de ajustar los pesos para minimizar esta distancia.",
                    },
                },
                stepsList: {
                    matrixW: "Busca la fila de la matriz de pesos W correspondiente al índice del carácter actual. Esta fila contiene las puntuaciones brutas no normalizadas (logits) para cada posible carácter siguiente.",
                    softmax: "Aplica softmax a la fila de logits para producir una distribución de probabilidad válida sobre el vocabulario. Cada valor se vuelve positivo y la fila suma exactamente 1.0.",
                    loss: "Durante el entrenamiento, calcula la pérdida de entropía cruzada entre la distribución predicha y el verdadero siguiente carácter. Retropropaga gradientes para actualizar W y minimizar el error de predicción futuro.",
                },
                analysis: {
                    strengths: [
                        "Solución exacta en forma cerrada — no se requiere descenso de gradiente. Los conteos son estadísticas suficientes.",
                        "Entrenamiento instantáneo en cualquier tamaño de corpus. O(N) en el número de tokens de entrenamiento.",
                        "Totalmente interpretable: cada celda en W es una probabilidad directamente legible.",
                    ],
                    limitations: [
                        "Cero contexto más allá del token inmediatamente anterior — no puede modelar patrones multi-carácter.",
                        "Sin generalización: cada par de caracteres se trata independientemente sin noción de similitud.",
                        "El vocabulario escala como O(V²) — impracticable para modelos a nivel de palabra con vocabularios grandes.",
                    ],
                },
                steps: {
                    predicts: "Predice el siguiente carácter vía:",
                    optimizes: "Optimiza parámetros usando:",
                },
            },
            guide: {
                badge: "Guía para Exploradores No Técnicos",
                title: "¿Cómo funciona este \"Cerebro\"?",
                subtitle: "Explicando el modelo Bigrama para que hasta mi madre lo entienda (con mucho amor).",
                switchHint: "Cambia al Modo Educativo para ver la guía conceptual",
                cards: {
                    memory: {
                        title: "Memoria de Pez",
                        desc: "Un modelo **Bigrama** tiene la memoria más corta del mundo: solo recuerda la **última letra** que escribió. Para decidir qué letra viene después, solo puede mirar la anterior. No tiene contexto de palabras o frases enteras.",
                    },
                    darts: {
                        title: "Lanzamiento de Dardos",
                        desc: "El modelo no \"lee\". Solo tiene una tabla gigante que dice: \"Si la última letra fue 'a', hay un 10% de probabilidad de que la siguiente sea 'n'\". Lanzar el dardo (muestreo) es lo que genera texto de manera aleatoria pero coherente.",
                    },
                    heatmap: {
                        title: "El Mapa de Calor",
                        desc: "La cuadrícula coloreada (Matriz) es el **corazón** del modelo. Los cuadrados brillantes son las \"rutas\" más frecuentes que el modelo encontró en los libros que leyó durante su entrenamiento.",
                    },
                },
            },
            historicalContext: {
                description: "El modelo bigrama es la instancia más simple de una cadena de Markov aplicada al lenguaje. Estudiado por primera vez por Claude Shannon en su artículo de 1948 'A Mathematical Theory of Communication', los bigramas a nivel de carácter demostraron que incluso modelos estadísticos sin contexto capturan estructura significativa en el lenguaje natural.",
                limitations: [
                    "Cero memoria más allá del predecesor inmediato — no puede aprender patrones multi-carácter como 'th' → 'e'.",
                    "Sin generalización — cada par de caracteres se trata independientemente sin noción de similitud.",
                ],
                evolution: "Las limitaciones de los modelos bigrama motivaron directamente las extensiones N-gram (contexto más largo) y eventualmente los enfoques neuronales (representaciones aprendidas). Todo modelo de lenguaje moderno puede rastrear su linaje hasta esta simple matriz de transición.",
            },
            educationalOverlay: {
                visualGuideTitle: "Guía de Visualización",
                visualGuideDescription: "Cada celda de esta matriz representa P(siguiente | actual), la probabilidad de que un carácter siga a otro. Las celdas más brillantes indican parejas de caracteres más frecuentes en el corpus de entrenamiento.",
                probabilityAnalysisTitle: "Análisis de Probabilidad",
                probabilityAnalysisDescription: "Escribe cualquier texto para ver qué caracteres predice el modelo como siguientes, ordenados por probabilidad aprendida. El modelo solo mira el último carácter: no tiene memoria del contexto anterior.",
                generationLabTitle: "Laboratorio de Generación",
                generationLabDescription: "La generación de texto funciona muestreando repetidamente la distribución de probabilidades. La temperatura controla cuán aleatoria es cada muestra: valores bajos producen resultados más predecibles; valores altos, secuencias más creativas (o sin sentido).",
            },
        },
        ngram: {
            title: "Modelo de Lenguaje N-Grama",
            description: "Un modelo de lenguaje estadístico a nivel de carácter con tamaño de contexto variable. Visualiza cómo aumentar la ventana de contexto agudiza las predicciones a costa de una escasez exponencial.",
            sections: {
                context: {
                    title: "Tamaño del Contexto",
                    description: "Ajusta el tamaño del contexto (N) para condicionar las predicciones en más historia.",
                },
                slice: {
                    title: "Slice Activo",
                    descriptionN1: "Para N=1 (Bigrama), visualizamos la matriz de transición de Markov simple P(siguiente | actual).",
                    descriptionNPlus: "Para N>1, visualizamos el slice condicional P(siguiente | contexto). Haz clic en las celdas para rastrear ejemplos.",
                },
                inference: {
                    title: "Inferencia y Generación",
                    description: "Interactúa con el modelo en tiempo real. Observa cómo selecciona el siguiente token basándose en las probabilidades aprendidas.",
                    distribution: {
                        title: "Distribución de Probabilidad",
                        desc: "Escribe una frase para ver los top-k caracteres siguientes más probables.",
                    },
                    stepwise: {
                        title: "Predicción Paso a Paso",
                        desc: "Observa al modelo predecir una secuencia carácter por carácter.",
                    },
                    generation: {
                        title: "Generación de Texto",
                        desc: "Deja que el modelo alucine texto muestreando de la distribución.",
                    },
                },
            },
            hero: {
                stats: {
                    uniqueContexts: { label: "Contextos Únicos", desc: "N-gramas observados" },
                    vocab: { label: "Vocabulario", desc: "Caracteres únicos" },
                    contextSpace: { label: "Espacio de Contexto", desc: "|V|^{n}" },
                    tokens: { label: "Tokens de Entrenamiento", desc: "Total tokens vistos" },
                },
            },
            viz: {
                hint: {
                    label: "Pruébalo:",
                    text: "Haz clic en cualquier celda coloreada de la matriz para ver <strong class='text-white font-semibold'>ejemplos reales de entrenamiento</strong>.",
                },
            },
            controls: {
                contextSize: "Tamaño de Contexto (N)",
                contextDesc: "Número de caracteres previos para condicionar",
                unigram: "Unigrama",
                bigram: "Bigrama",
                trigram: "Trigrama",
                fourgram: "4-grama",
                fivegram: "5-grama",
                explosion: "Explosión (5+)",
            },
            lab: {
                badge: "Modo Lab Libre · Acceso completo a instrumentos",
                contextLevels: {
                    1: "Sin contexto — cada carácter se predice de forma independiente según la frecuencia del corpus. El más rápido pero el menos preciso.",
                    2: "Condiciona en 1 carácter previo. Cadena de Markov simple; baja dispersión, precisión moderada.",
                    3: "Condiciona en 2 caracteres previos. Mejores predicciones pero el espacio de contexto crece a |V|².",
                    4: "Condiciona en 3 caracteres. Alta precisión en secuencias vistas; dispersión significativa en las no vistas.",
                    5: "Contexto máximo. Predicciones muy precisas donde hay datos, pero la mayoría de contextos no se han visto — explosión combinatoria inminente.",
                },
                flow: {
                    afterContext: "La matriz a continuación muestra la distribución de probabilidad aprendida de los datos de entrenamiento para el nivel N actual.",
                    afterMatrix: "Usa la consola de inferencia para consultar el modelo con tu propio texto y observar cómo el tamaño de contexto afecta las predicciones.",
                    afterComparison: "El gráfico de calidad de entrenamiento a continuación refleja qué tan bien el modelo se ajusta al corpus en el nivel N seleccionado.",
                },
                performanceSummary: {
                    title: "Resumen de Rendimiento",
                    description: "Métricas de ejecución y entrenamiento del modelo actual",
                    inferenceTime: "Tiempo de Inferencia",
                    device: "Dispositivo",
                    corpusSize: "Tamaño del Corpus",
                    trainingDuration: "Duración del Entrenamiento",
                    totalTokens: "Total de Tokens",
                    perplexity: "Perplejidad",
                    finalLoss: "NLL Final",
                    ms: "ms",
                    tokens: "tokens",
                },
                comparison: {
                    title: "Comparación de Modelos",
                    description: "Métricas para N=1..5",
                    ppl: "PPL",
                    util: "Util",
                    space: "Espacio",
                    tooltipPpl: "Perplejidad — menor significa predicciones más seguras",
                    tooltipUtil: "Fracción de contextos posibles vistos durante el entrenamiento",
                    tooltipSpace: "Total de combinaciones de contexto posibles (|V|^N)",
                },
                sparsity: {
                    title: "Dispersión de Datos",
                    description: "Cuánto del espacio de contexto se observa realmente",
                    observedContexts: "Contextos Observados",
                    possibleSuffix: "posibles",
                    avgTransitions: "Trans. Promedio / Contexto",
                    nextTokens: "siguientes-tokens por contexto observado",
                    utilLabel: "Utilización de contexto",
                    utilHint: "Fracción de contextos posibles vistos en datos de entrenamiento",
                    sparsityLabel: "Dispersión de tabla",
                    sparsityHint: "Fracción de pares (contexto, siguiente-token) nunca observados",
                },
                warning5: {
                    title: "Umbral combinatorio superado",
                    hint: "Reduce N a 1–4 para inferencia en vivo, predicción paso a paso y generación. Un N menor también reduce la dispersión.",
                },
                sections: {
                    transitions: "Probabilidades de Transición",
                    transitionsDescN1: "Matriz completa P(siguiente | actual)",
                    transitionsDescNPlus: "Slice P(siguiente | contexto)",
                    conditionedOn: "Condicionado en:",
                    sparsity: "Dispersión de Datos",
                    trainingQuality: "Calidad de Entrenamiento",
                    trainingQualityDesc: "Curva de pérdida para el modelo N={n} durante el entrenamiento",
                    nextToken: "Predicción del Siguiente Token",
                    nextTokenDesc: "Escribe texto y observa la distribución de probabilidad sobre los siguientes caracteres",
                    stepwise: "Predicción Paso a Paso",
                    stepwiseDesc: "Rastrea la ventana de contexto deslizándose carácter a carácter",
                    generation: "Generación de Texto",
                    generationDesc: "Genera texto de forma autorregresiva usando el modelo N-grama actual",
                },
                hero: {
                    title: "Modelo de Lenguaje N-Grama",
                    description: "Un modelo de lenguaje estadístico a nivel de carácter con tamaño de contexto variable. Visualiza cómo aumentar la ventana de contexto agudiza las predicciones a costa de una escasez exponencial.",
                    uniqueContexts: "Contextos Únicos",
                    vocabulary: "Vocabulario",
                    contextSpace: "Espacio de Contexto",
                    trainingTokens: "Tokens de Entrenamiento",
                    uniqueChars: "Caracteres únicos",
                    totalTokensSeen: "Total de tokens vistos",
                },
                lossChart: {
                    title: "Pérdida de entrenamiento (NLL)",
                    final: "Final:",
                    ppl: "PPL:",
                    start: "Inicio",
                    progress: "Progreso de entrenamiento",
                    end: "Fin",
                    perplexity: "Perplejidad",
                    perplexityHint: "Menor = predicciones más seguras",
                    finalNll: "NLL Final",
                    finalNllHint: "Log-verosimilitud negativa en datos de entrenamiento",
                },
                footer: "LM-Lab · Instrumento Científico v1.0",
            },
            training: {
                title: "Insights de Entrenamiento",
                stats: {
                    totalTokens: "Total Tokens",
                    uniqueContexts: "Contextos Únicos",
                    utilization: "Utilización",
                    sparsity: "Espasidad",
                    transitionDensity: "Densidad de Matriz",
                    subs: {
                        possiblePrefix: "de",
                        possibleSuffix: "posibles",
                        fractionObserved: "fracción de contextos posibles observados",
                        unseen: "de contextos nunca vistos",
                    },
                },
            },
            historical: {
                title: "Significado Histórico y Contexto",
                learnMore: "Aprender Más",
                description: "Descripción",
                limitations: "Limitaciones Clave",
                evolution: "Evolución a la IA Moderna",
            },
            explosion: {
                title: "Contexto Demasiado Grande — Explosión Combinatoria",
                description: "A medida que aumenta N, el número de contextos posibles crece exponencialmente (|V|^N). Para este tamaño de vocabulario, calcular la matriz de transición completa se vuelve computacionalmente impracticable y requiere un conjunto de datos enorme para evitar la escasez.",
                complexity: "|V|^N = Complejidad Espacial",
                limit: "Límite Clásico Alcanzado",
            },
            diagnostics: {
                vocabSize: "Vocabulario",
                contextSize: "Tamaño de Contexto (N)",
                contextSpace: "Espacio de Contexto (|V|^N)",
                sparsity: "Espasidad",
                sub: {
                    observed: "{count} observados",
                    possible: "Contextos Posibles",
                    utilized: "{percent}% utilizado",
                },
            },
            educationalOverlay: {
                contextControlTitle: "Control del Tamaño de Contexto",
                contextControlDescription: "Aumentar N permite al modelo condicionar con más historia, pero el número de contextos posibles crece como |V|^N. Esa explosión exponencial es la tensión central de los modelos n-grama: más contexto da predicciones más finas, pero también más dispersión de datos.",
                sliceVisualizationTitle: "Vista por Slice de Matriz",
                sliceVisualizationDescription: "Para N > 1, el tensor de transición completo es demasiado grande para mostrarse. En su lugar, fijamos el contexto actual y mostramos la fila de probabilidad resultante: un slice de la tabla de alta dimensión.",
                probabilityDistributionTitle: "Distribución de Probabilidad",
                probabilityDistributionDescription: "El modelo toma los últimos N caracteres de tu entrada, encuentra el contexto correspondiente en su tabla y devuelve la distribución de probabilidad sobre los posibles siguientes caracteres.",
                generationPredictionTitle: "Generación y Predicción",
                generationPredictionDescription: "En modo educativo nos centramos en entender cómo se elige un único token siguiente. Cambia a Lab Libre para desbloquear el trazador paso a paso completo y el playground de generación.",
                simplifiedSimulation: "La predicción paso a paso y la generación completa están disponibles en modo Lab Libre.",
            },
        },
        mlp: {
            title: "MLP + Embeddings",
            description: "Explora 108 configuraciones MLP entrenadas. Observa cómo los embeddings emergen del ruido, compara dinámicas de entrenamiento entre arquitecturas y genera texto desde representaciones aprendidas a nivel de carácter.",
            hero: {
                badge: "Laboratorio de Investigación",
            },
            freeLab: {
                title: "Laboratorio de Configuración MLP",
                description: "Selecciona cualquier configuración del Model Zoo, inspecciona curvas de entrenamiento, explora el espacio de embeddings y compara modelos lado a lado.",
            },
            page: {
                switchToEducational: "Cambia al Modo Educativo para la narrativa guiada completa",
            },
            narrative: {
                hero: {
                    eyebrow: "Narrativa Educativa",
                    titlePrefix: "Más Allá de las Tablas:",
                    titleHighlight: "MLP + Embeddings",
                    description: "Cómo los perceptrones multicapa y las representaciones vectoriales aprendidas transformaron el modelado del lenguaje — del conteo de co-ocurrencias al aprendizaje de representaciones distribuidas del significado.",
                },
                sections: {
                    s00: { number: "00", label: "Punto de Partida" },
                    s01: { number: "01", label: "Fundamentos" },
                    s02: { number: "02", label: "Modelado del Lenguaje" },
                    s03: { number: "03", label: "Límite de Escalabilidad" },
                    s04: { number: "04", label: "El Gran Avance" },
                    s05: { number: "05", label: "Límites Estructurales" },
                    s06: { number: "06", label: "Exploración Empírica" },
                    s07: { number: "07", label: "Estabilidad del Entrenamiento" },
                    s08: { number: "08", label: "Mirando al Futuro" },
                },
                s00: {
                    heading: "Por Qué los N-gramas No Eran Suficientes",
                    lead: "Ya sabemos que los N-gramas pueden contar. Después de trabajar con bigramas y trigramas, surge naturalmente una pregunta: ¿qué no pueden hacer?",
                    p1: "Los modelos N-grama almacenan una tabla de conteos — con qué frecuencia apareció cada secuencia de N caracteres en los datos de entrenamiento. Esto funciona, pero tiene límites. Si una secuencia de 3 caracteres nunca apareció en el entrenamiento, el modelo le asigna",
                    p1H1: "probabilidad cero",
                    p1End: ", aunque sea completamente razonable. La tabla también crece exponencialmente: un vocabulario de 70 caracteres da 70³ = 343.000 trigramas posibles, y la mayoría nunca se observan. Un N mayor significa exponencialmente más celdas vacías.",
                    p2: "Peor aún, los N-gramas no tienen",
                    p2H1: "noción de similitud",
                    p2End: ". El modelo trata cada carácter como un símbolo aislado. No tiene forma de saber que \"a\" y \"e\" son ambas vocales, o que los patrones aprendidos para un contexto podrían transferirse a uno ligeramente diferente. Cada contexto se aprende desde cero, en aislamiento.",
                    calloutTitle: "La idea central",
                    calloutText: "Una tabla solo puede memorizar. Lo que necesitamos es una función — algo que pueda generalizar desde los patrones que ha visto hacia los que no ha visto. Una función puede aprender que las vocales se comportan de manera similar, que ciertas secuencias de caracteres comparten estructura, y que las combinaciones no vistas no son aleatorias. Esa función es una red neuronal.",
                },
                s01: {
                    heading: "¿Qué Es un Perceptrón Multicapa?",
                    lead: "Antes de hablar de capas y arquitecturas, empecemos con la unidad más pequeña: una sola neurona artificial. Una neurona, una decisión. Apila suficientes y puedes aproximar casi cualquier patrón en los datos.",
                    p1: "Una neurona toma una lista de números como entrada, multiplica cada uno por un",
                    p1H1: "peso",
                    p1Mid: "— un dial que indica cuán importante es esa entrada — los suma todos y pasa el resultado por una",
                    p1H2: "función de activación",
                    p1End: "que introduce una curva. Una sola neurona es poco impresionante. Pero la idea escala.",
                    calloutTitle1: "¿Qué es un peso?",
                    calloutText1: "Un peso es un número entrenable — un dial que la red ajusta durante el aprendizaje. Un peso positivo grande significa \"presta mucha atención a esta entrada\". Un peso cercano a cero significa \"ignórala en su mayoría\". El entrenamiento es el proceso de encontrar los ajustes correctos comprobando repetidamente cuán equivocada fue una predicción y ajustando cada peso ligeramente en la dirección que reduce el error. Esto se llama descenso de gradiente.",
                    p2: "Organiza muchas neuronas una al lado de la otra, todas leyendo la misma entrada, y obtienes una",
                    p2H1: "capa",
                    p2Mid: ". Cada neurona en esa capa aprende un patrón diferente. Apila dos o más capas y la segunda capa lee las detecciones de la primera — aprende patrones de patrones. Esta pila es un",
                    p2H2: "Perceptrón Multicapa (MLP)",
                    p2Tail: ".",
                    figLabel1: "Arquitectura MLP · Esquema",
                    figHint1: "Una red feedforward con capas de entrada, ocultas y de salida conectadas por matrices de pesos aprendidas.",
                    p3: "Sin la función de activación entre capas, apilar sería inútil — múltiples transformaciones lineales colapsan en una sola. La no linealidad (Tanh, ReLU) es lo que hace que la profundidad sea significativa.",
                    formulaCaption: "Cada símbolo aquí es solo la 'suma ponderada + aplastamiento' descrita arriba. σ es la función de activación, W₁ y W₂ son matrices de pesos que la red aprende, y softmax convierte los números finales en probabilidades que suman 1.",
                    calloutTitle2: "Por qué importa la profundidad",
                    calloutText2: "Una sola capa oculta puede teóricamente aproximar cualquier función, pero en la práctica las redes más profundas aprenden representaciones jerárquicas de forma más eficiente — menos parámetros, mejor generalización.",
                    figLabel2: "Interactivo · No Linealidad y Fronteras de Decisión",
                    figHint2: "Alterna entre modelos lineales, superficiales y profundos para ver cómo las capas no lineales permiten fronteras complejas.",
                },
                s02: {
                    heading: "MLP Aplicado al Lenguaje (Sin Embeddings)",
                    lead: "La forma más simple de usar un MLP para el lenguaje: toma los N tokens anteriores, convierte cada uno en un vector numérico, concaténalos y alimenta el resultado a la red para predecir el siguiente token.",
                    p1: "Para alimentar caracteres a una red neuronal, primero necesitamos convertirlos en números. El método más directo es un",
                    p1H1: "vector one-hot",
                    p1Mid: ": una lista de ceros de la longitud del vocabulario, con un solo 1 en la posición de ese carácter. Con una ventana de contexto de tamaño N, concatenamos N de estos vectores para formar una entrada de dimensión",
                    p1H2: "N × V",
                    p1End: ", luego la pasamos por una o más capas ocultas para producir una distribución de probabilidad sobre el siguiente token.",
                    formulaCaption: "La entrada al MLP es una concatenación de N vectores one-hot, uno por token de contexto.",
                    calloutTitle: "¿Qué significa realmente la pérdida?",
                    calloutP1: "La pérdida es una medida de sorpresa. Después de cada predicción, el modelo compara lo que dijo con lo que realmente vino después.",
                    calloutP2: "Si el modelo le dio al carácter correcto una probabilidad de 0,9, estaba seguro y acertó. Poca sorpresa. Pérdida baja.",
                    calloutP3: "Si le dio al carácter correcto una probabilidad de 0,02, estaba casi seguro de que aparecería otra cosa. Gran sorpresa. Pérdida alta.",
                    calloutP4: "El entrenamiento es el proceso de reducir esta sorpresa promedio hasta que las predicciones del modelo dejen de ser sorprendentes.",
                    figLabel1: "Interactivo · Intuición de la Pérdida",
                    figHint1: "Arrastra el deslizador para establecer cuán seguro está el modelo en el token correcto. Observa cómo la pérdida de entropía cruzada explota cuando la confianza se acerca a cero.",
                    p2: "Esto ya representa un gran avance respecto a las tablas N-grama. En lugar de memorizar conteos exactos de co-ocurrencia, el modelo",
                    p2H1: "aprende una función",
                    p2End: "que mapea patrones de contexto a predicciones. Puede interpolar entre patrones vistos y generalizar a combinaciones nuevas.",
                    p3: "El MLP puede descubrir que ciertas secuencias de caracteres se comportan de manera similar, incluso si nunca ha visto el N-grama exacto antes.",
                    calloutTitle2: "Mejora clave sobre los N-gramas",
                    calloutText2: "Los modelos N-grama asignan probabilidad cero a cualquier contexto que nunca observaron en el entrenamiento. Un MLP puede asignar probabilidad no nula a contextos no vistos porque aprende una función suave — no una tabla de búsqueda.",
                    figLabel2: "Interactivo · Paso Hacia Adelante del MLP",
                    figHint2: "Escribe un texto semilla corto y avanza por cada etapa del paso hacia adelante — desde tokens brutos hasta la distribución de probabilidad final.",
                },
                s03: {
                    heading: "El Problema con las Entradas One-Hot",
                    lead: "La codificación one-hot parece natural, pero crea graves problemas de escalabilidad que se vuelven catastróficos a medida que crecen los vocabularios.",
                    p1H1: "Explosión de dimensionalidad de entrada.",
                    p1: "Con un vocabulario a nivel de carácter de ~96 tokens y un contexto de 8 caracteres, el vector de entrada tiene 768 dimensiones — manejable. Pero con un vocabulario a nivel de palabra de 50.000 tokens y un contexto de 5 palabras, la entrada salta a 250.000 dimensiones. Solo la primera matriz de pesos tendría decenas de miles de millones de parámetros.",
                    p2H1: "Matrices de pesos de primera capa masivas.",
                    p2: "La matriz W₁ que conecta la entrada con la primera capa oculta tiene forma (N·V) × H, donde H es el tamaño oculto. Para vocabularios grandes, esta sola matriz domina todo el presupuesto de parámetros, haciendo el entrenamiento lento y prohibitivo en memoria.",
                    p3H1: "Sin noción de similitud.",
                    p3: "En el espacio one-hot, cada token está equidistante de todos los demás. Los vectores de \"cat\" y \"kitten\" están tan alejados como los de \"cat\" y \"quantum\". El modelo debe aprender cada relación desde cero, sin ningún prior estructural.",
                    formulaCaption: "Todos los vectores one-hot son equidistantes — el modelo no obtiene información sobre similitud semántica de la propia codificación.",
                    calloutTitle: "El muro de escalabilidad",
                    calloutText: "Estos tres problemas — explosión dimensional, matrices de pesos enormes y representaciones ortogonales — forman juntos un muro de escalabilidad. El MLP one-hot ingenuo simplemente no puede escalar a vocabularios del mundo real. Necesitamos una forma fundamentalmente mejor de representar tokens.",
                },
                s04: {
                    heading: "El Cambio de Juego: Embeddings de Palabras",
                    lead: "En lugar de representar cada token como un vector one-hot disperso, aprendemos un vector denso y de baja dimensión para cada token del vocabulario. Estos se llaman embeddings.",
                    p1: "Un embedding es una tabla de búsqueda — una matriz E de forma V × D, donde V es el tamaño del vocabulario y D es la dimensión del embedding (típicamente 10–300). Para obtener la representación del token t, simplemente seleccionamos la fila t-ésima de E.",
                    formulaCaption: "Una búsqueda de embedding: seleccionar la fila t de la matriz de embedding E da un vector denso de D dimensiones.",
                    p2: "La idea clave es que",
                    p2H1: "cada dimensión del embedding captura una propiedad semántica latente",
                    p2End: ". Estas dimensiones no están diseñadas a mano — emergen automáticamente del entrenamiento.",
                    p3: "Dado que los embeddings son densos y continuos, los tokens similares se agrupan naturalmente en el espacio de embeddings. El modelo puede aprovechar esta estructura para",
                    p3H1: "generalizar entre tokens semánticamente relacionados",
                    p3End: ". Si el modelo ha aprendido algo sobre \"cat\", puede transferir parcialmente ese conocimiento a \"kitten\" porque sus vectores de embedding están cerca.",
                    p4: "Esto reduce drásticamente la dimensionalidad efectiva de entrada. En lugar de N × V (potencialmente cientos de miles), el MLP ahora recibe N × D (quizás unos pocos cientos) — órdenes de magnitud más pequeño, con información más rica.",
                    pullQuote: "Los embeddings transforman los tokens de símbolos aislados en puntos de un espacio semántico continuo, donde la proximidad codifica el significado. Esta sola idea desbloqueó una nueva era en el modelado del lenguaje.",
                    figLabel1: "Ilustrativo · Espacio de Embeddings (Simplificado)",
                    figHint1: "Esta es una ilustración pedagógica — no datos reales del modelo. Haz clic en los tokens para explorar cómo los caracteres similares se agrupan.",
                },
                s05: {
                    heading: "Nuevas Limitaciones de MLP + Embeddings",
                    lead: "Los embeddings resuelven el problema de representación, pero la arquitectura MLP en sí introduce limitaciones estructurales que ninguna cantidad de ajuste puede superar.",
                    p1H1: "Ventana de contexto de tamaño fijo.",
                    p1: "Un MLP debe recibir un número fijo de tokens de entrada. No puede atender dinámicamente a contextos más largos o más cortos — cada predicción usa exactamente N tokens anteriores, ni más ni menos. La información fuera de esta ventana es completamente invisible para el modelo.",
                    p2: "La consecuencia es grave para el lenguaje: los pronombres, las referencias y la continuidad temática dependen de contexto que puede estar muchos tokens atrás.",
                    figLabel1: "Interactivo · Ceguera de la Ventana de Contexto",
                    figHint1: "Arrastra el deslizador para ampliar la ventana de contexto. Observa cuándo 'Mary' (el referente) entra en el campo de visión — y nota cuán pequeña debe ser la ventana para ocultarla por completo.",
                    p3H1: "Las dependencias de largo alcance están fuera del alcance.",
                    p3: "El problema se agrava en textos más largos. En el lenguaje real, un pronombre puede referirse a un sustantivo introducido decenas de tokens antes. Ninguna ventana fija de tamaño práctico puede cerrar estos huecos de manera confiable.",
                    figLabel2: "Demo · Fallo en Dependencias de Largo Alcance",
                    figHint2: "Una oración de 19 palabras donde el pronombre 'she' se refiere a 'scientist' 15 tokens atrás. Compara cómo cambia la predicción del MLP a medida que crece la ventana.",
                    p4H1: "Significado del token dependiente de la posición.",
                    p4: "Dado que el MLP concatena embeddings de extremo a extremo, el mismo token en la posición 1 y en la posición 3 ocupa diferentes porciones del vector de entrada y activa diferentes columnas de W₁. El modelo aprende pesos completamente separados para cada posición.",
                    figLabel3: "Interactivo · Sensibilidad a la Posición",
                    figHint3: "Alterna 'the' entre la posición 1 y la posición 3. Las columnas resaltadas en W₁ muestran qué parámetros activa cada instancia — conjuntos completamente diferentes.",
                    p5H1: "Explosión de parámetros y dilución de señal.",
                    p5: "Incluso con embeddings, la primera matriz de pesos W₁ tiene forma (N · D) × H. Duplicar la ventana de contexto duplica el tamaño de esta capa. Al mismo tiempo, a medida que N crece, el embedding de cada token se reduce a una fracción más pequeña de la entrada total — diluyendo cada señal.",
                    figLabel4: "Interactivo · Cuello de Botella por Concatenación",
                    figHint4: "Alterna entre las vistas de Crecimiento de Parámetros y Dilución de Señal. Arrastra el deslizador de tamaño de contexto y observa cómo se expande W₁.",
                    calloutTitle: "La misma causa raíz",
                    calloutText: "Las cuatro limitaciones comparten un origen común: el MLP trata todo su contexto como un único vector plano. No tiene mecanismo para razonar sobre la estructura, el orden o la importancia relativa de los tokens individuales. Superar esto requiere arquitecturas que procesen secuencias como secuencias — no como blobs concatenados. Esa arquitectura es el Transformer.",
                },
                s06: {
                    heading: "Explorando Configuraciones MLP + Embeddings",
                    lead: "Con los embeddings en su lugar, el modelo de lenguaje MLP tiene varios hiperparámetros clave que controlan su capacidad, eficiencia y comportamiento. Comprender su impacto requiere experimentación sistemática.",
                    p1: "Las elecciones arquitectónicas principales incluyen la",
                    p1H1: "dimensión del embedding",
                    p1Mid1: "(cuántas características latentes por token), el",
                    p1H2: "tamaño de la capa oculta",
                    p1Mid2: "(cuántas neuronas en cada capa oculta), el",
                    p1H3: "número de capas ocultas",
                    p1End: "(profundidad de la red), y el tamaño de la ventana de contexto.",
                    p2: "Para entender cómo estas elecciones afectan el comportamiento del modelo, entrenamos muchos modelos MLP con diferentes configuraciones de hiperparámetros en el mismo conjunto de datos. Este barrido sistemático revela compromisos clave: embeddings más grandes capturan semántica más rica pero arriesgan sobreajuste con datos pequeños, capas ocultas más anchas aumentan la capacidad pero ralentizan el entrenamiento, y redes más profundas pueden aprender características más abstractas pero son más difíciles de optimizar.",
                    hyperparamCards: {
                        embDim: { title: "Dimensión del Embedding", desc: "Controla la riqueza de las representaciones de tokens. Valores más grandes capturan más matices semánticos pero requieren más datos." },
                        hiddenSize: { title: "Tamaño de la Capa Oculta", desc: "Determina el ancho computacional del modelo. Capas más anchas pueden detectar más patrones por capa, pero aumentan la memoria y el cómputo." },
                        numLayers: { title: "Número de Capas", desc: "Controla la profundidad representacional. Los modelos más profundos pueden componer características jerárquicamente, pero enfrentan desafíos de estabilidad." },
                        contextWindow: { title: "Ventana de Contexto", desc: "Cuántos tokens anteriores considera el modelo. Ventanas más grandes dan más información pero aumentan la dimensionalidad de entrada linealmente." },
                    },
                    figLabel1: "Interactivo · Temperatura Softmax",
                    figHint1: "Ajusta la temperatura para ver cómo agudiza o aplana la distribución de probabilidad sobre los siguientes tokens.",
                    calloutTitle: "Por qué importa la exploración sistemática",
                    calloutText: "No existe una configuración óptima única — los hiperparámetros óptimos dependen del tamaño del conjunto de datos, el vocabulario y el presupuesto computacional. La única forma de desarrollar intuición es explorar el espacio empíricamente y observar cómo cada elección afecta la pérdida, la perplejidad y la calidad de generación.",
                    figLabel2: "Interactivo · Explorador de Hiperparámetros",
                    figHint2: "Ajusta los deslizadores para explorar cómo la dimensión del embedding, el tamaño oculto y la tasa de aprendizaje afectan la pérdida de validación, el coste computacional, la dinámica de entrenamiento y los embeddings aprendidos.",
                    p3: "El explorador interactivo de arriba te permite comparar modelos en estas dimensiones, visualizando pérdida de validación, perplejidad, estabilidad de entrenamiento, coste computacional, calidad del texto generado y el espacio de embeddings aprendido. Las insignias de anomalía señalan patrones preocupantes como sobreajuste o gradientes inestables.",
                },
                s07: {
                    heading: "Desafíos de Entrenamiento Profundo para MLPs Grandes",
                    lead: "Hacer que los MLPs profundos entrenen bien fue uno de los problemas prácticos más difíciles en la historia de las redes neuronales. Sin técnicas cuidadosas, las redes profundas simplemente no aprenden.",
                    p1H1: "Inicialización de pesos.",
                    p1: "Si los pesos se inicializan demasiado grandes, las activaciones explotan a través de las capas. Demasiado pequeños, y los gradientes se desvanecen antes de llegar a las capas tempranas. Los esquemas de inicialización adecuados (como Xavier o Kaiming) establecen la escala inicial basándose en las dimensiones de la capa para mantener una propagación de señal estable.",
                    formulaCaption1: "Inicialización Kaiming: los pesos se extraen de una Gaussiana escalada por el fan-in, manteniendo la varianza estable a través de capas ReLU.",
                    figLabel1: "Interactivo · Sensibilidad a la Inicialización",
                    figHint1: "Compara curvas de pérdida bajo diferentes escalas de inicialización. Una inicialización bien escalada es crítica para la convergencia.",
                    p2H1: "Gradientes que se desvanecen y explotan.",
                    p2: "Durante la retropropagación, los gradientes se multiplican a través de cada capa. En una red profunda, si estos multiplicadores son consistentemente menores que 1, los gradientes se reducen exponencialmente (desvanecimiento). Si son mayores que 1, crecen exponencialmente (explosión). En cualquier caso, la red no aprende eficazmente.",
                    formulaCaption2: "La regla de la cadena a través de L capas: los gradientes son productos de Jacobianos por capa. Si cada factor es ligeramente < 1 o > 1, el producto se desvanece o explota.",
                    figLabel2: "Interactivo · Flujo de Gradientes entre Capas",
                    figHint2: "Alterna entre regímenes de gradientes que se desvanecen, estables y que explotan para ver cómo cambia la magnitud del gradiente por capa.",
                    p3: "Durante muchos años, entrenar redes de más de 2–3 capas fue extremadamente poco fiable. Los investigadores descubrieron que la combinación de la elección de la función de activación, la inicialización adecuada y las técnicas de normalización era esencial para un entrenamiento estable.",
                    p4H1: "Normalización por Lotes",
                    p4: "fue un avance clave. Al normalizar las activaciones dentro de cada capa para tener media cero y varianza unitaria (en un mini-lote), mantiene las distribuciones internas estables mientras la red entrena. Esto reduce drásticamente la sensibilidad a la inicialización y la tasa de aprendizaje, permitiendo el entrenamiento fiable de redes mucho más profundas.",
                    formulaCaption3: "Normalización por Lotes: normaliza las activaciones h usando estadísticas del lote (μ_B, σ²_B), luego reescala con parámetros aprendidos γ y β.",
                    calloutTitle: "Por qué BatchNorm lo cambió todo",
                    calloutText: "Antes de BatchNorm, entrenar redes profundas requería un ajuste meticuloso de hiperparámetros. Después, los profesionales podían entrenar redes de 10, 20 o incluso más de 100 capas de manera fiable. Actúa como un estabilizador que suaviza el paisaje de pérdida, permitiendo que el descenso de gradiente converja más rápido y de manera más fiable.",
                    figLabel3: "Interactivo · Efecto de la Normalización por Lotes",
                    figHint3: "Activa y desactiva BatchNorm para ver cómo estabiliza las distribuciones de activación entre capas.",
                },
                s08: {
                    heading: "Limitaciones Finales y el Camino por Delante",
                    lead: "Incluso con embeddings, arquitecturas profundas y técnicas de entrenamiento modernas, el MLP opera fundamentalmente sobre ventanas de tamaño fijo — y este techo define su era en la historia del modelado del lenguaje.",
                    p1: "El MLP procesa cada ventana de contexto de forma independiente. No tiene memoria de lo que vino antes de la ventana, ningún mecanismo para atender dinámicamente a tokens distantes, y ninguna forma de manejar secuencias de longitud variable sin relleno o truncamiento.",
                    p2: "Esto significa que los MLPs no pueden modelar dependencias de largo alcance — el tipo de estructura que hace que el lenguaje natural sea coherente a través de oraciones y párrafos.",
                    p3: "Estas limitaciones estructurales motivaron una serie de innovaciones arquitectónicas que definen la trayectoria moderna del modelado del lenguaje:",
                    p3H1: "Redes Neuronales Recurrentes (RNNs)",
                    p3Mid1: "introdujeron la memoria secuencial, procesando un token a la vez mientras mantienen un estado oculto.",
                    p3H2: "Arquitecturas convolucionales (como WaveNet)",
                    p3Mid2: "aplicaron convoluciones dilatadas para capturar patrones jerárquicos sobre secuencias. Y finalmente,",
                    p3H3: "Transformers",
                    p3End: "introdujeron la auto-atención — un mecanismo que permite a cada token atender directamente a cada otro token, independientemente de la distancia.",
                    pullQuote: "El MLP fue la primera arquitectura en demostrar que las redes neuronales podían aprender lenguaje — pero su ventana fija reveló que aprender lenguaje requiere arquitecturas que entiendan secuencias, no solo instantáneas.",
                    p4: "A pesar de estas limitaciones, el framework MLP + Embeddings estableció conceptos que siguen siendo fundamentales en todos los modelos de lenguaje modernos: representaciones de tokens aprendidas, jerarquías de características no lineales y entrenamiento de extremo a extremo basado en gradientes. Cada Transformer sigue usando capas de embedding y bloques MLP feedforward — las ideas introducidas aquí nunca desaparecieron; evolucionaron.",
                },
                cta: {
                    heading: "Continúa Explorando",
                    freeLabTitle: "Abrir Lab Libre",
                    freeLabDesc: "Experimenta con modelos MLP + Embeddings de forma interactiva. Entrena, visualiza embeddings y genera texto con diferentes hiperparámetros.",
                    transformerTitle: "Siguiente: Transformers",
                    transformerDesc: "Descubre cómo la auto-atención supera la limitación de ventana fija del MLP y permite una comprensión del lenguaje verdaderamente contextual.",
                },
                footer: {
                    text: "De tablas de conteo a representaciones aprendidas — el modelo MLP + Embeddings marcó el momento en que el modelado del lenguaje se volvió verdaderamente neuronal.",
                    brand: "LM-Lab · Narrativa MLP + Embeddings",
                },
                oneHot: {
                    title: "Codificación One-Hot",
                    sparse: "Dispersa, de alta dimensión. Cada token está igualmente distante de todos los demás. Sin noción de similitud.",
                    learnedTitle: "Embeddings Aprendidos",
                    dense: "Denso, de baja dimensión. Las palabras similares (\"cat\" y \"mat\") obtienen vectores similares — el modelo puede generalizar.",
                },
                mlpDiagram: {
                    input: "Entrada",
                    inputDesc: "Tokens de contexto (one-hot o embeddings)",
                    hidden1: "Oculta 1",
                    hidden1Desc: "Características aprendidas",
                    hidden2: "Oculta 2",
                    hidden2Desc: "Patrones de orden superior",
                    output: "Salida",
                    outputDesc: "Probabilidades del siguiente token",
                },
            },
            explorer: {
                loading: "Cargando configuraciones…",
                errorPrefix: "Error al cargar la cuadrícula MLP:",
                noConfigs: "No hay configuraciones MLP disponibles desde el backend.",
                sections: {
                    s01Title: "Visión General del Model Zoo",
                    s01Subtitle: "configuraciones completamente entrenadas — haz clic en cualquier punto para seleccionarlo y sincronizar los deslizadores.",
                    s02Title: "Configuración Seleccionada",
                    s02Subtitle: "Tarjetas de métricas, indicadores de anomalías y un resumen en lenguaje sencillo de la calidad de entrenamiento de este modelo.",
                    s03Title: "Espacio de Embeddings",
                    s03Subtitle: "Tokens del vocabulario proyectados a 2D mediante PCA. Desplázate por las instantáneas de entrenamiento para ver cómo emerge la estructura del ruido.",
                    s04Title: "Generación de Texto",
                    s04Subtitle: "Genera secuencias de caracteres desde el modelo seleccionado. Ajusta la temperatura y la longitud para explorar la distribución de salida.",
                    s05Title: "Diagnósticos Avanzados de Entrenamiento",
                    s05Subtitle: "Flujo de gradientes, salud de neuronas y patrones de sobreajuste a lo largo del entrenamiento completo.",
                },
                zoo: {
                    expandableTitle: "Model Zoo · {count} Configuraciones",
                    description: "Empieza aquí. Cada punto es un modelo completamente entrenado. Haz clic en cualquier punto para seleccionarlo y sincronizar los deslizadores. Usa los filtros para encontrar las mejores configuraciones, las peores o los valores atípicos.",
                },
                sliders: {
                    embeddingDim: "Dim. Embedding",
                    hiddenSize: "Tamaño Oculto",
                    learningRate: "Tasa de Aprendizaje",
                },
                config: { active: "Activo:", score: "puntuación" },
                metrics: {
                    valLoss: "Pérdida Val.",
                    trainLoss: "Pérdida Entren.",
                    loss: "Pérdida",
                    trainSmoothed: "Entren. (suavizado)",
                    perplexity: "Perplejidad",
                    random: "aleatorio:",
                    trainValGap: "Brecha Entren.–Val.",
                    params: "Parámetros",
                    compute: "Cómputo",
                    tooltips: {
                        valLoss: "Pérdida de validación: qué tan bien predice el modelo datos no vistos durante el entrenamiento. Menor = mejor. Esta es la métrica principal.",
                        trainLossOnly: "Solo pérdida de entrenamiento — pérdida de validación no disponible para esta configuración. La pérdida de entrenamiento puede ser engañosamente optimista.",
                        trainSmoothed: "Media del último ~10% de los valores de pérdida de entrenamiento registrados. El suavizado elimina el ruido por lote.",
                        perplexity: "Perplejidad ≈ exp(pérdida). Si la perplejidad = 20, el modelo es tan incierto como elegir aleatoriamente entre 20 tokens. Menor = mejor.",
                        randomPerplexity: "Perplejidad que lograría un modelo aleatorio uniforme. Cualquier modelo útil debería estar muy por debajo de esto.",
                        trainValGap: "Brecha Entren.–Val. = pérdida_val − pérdida_entren_suavizada. Positivo = sobreajuste. Negativo = saludable o subajuste. Valores > 0.3 son preocupantes.",
                        paramsCount: "Número total de pesos y sesgos aprendibles en esta configuración del modelo.",
                        compute: "Cómputo = parámetros × pasos de entrenamiento ({steps}k). Es un proxy determinista del coste computacional — independiente de la máquina.",
                        computeDetail: "{params} parámetros × {steps}k pasos. Los modelos más grandes cuestan más de entrenar pero no siempre generalizan mejor.",
                        score: "Puntuación de calidad compuesta — mayor es mejor. Calculada como cuánto mejoró esta configuración sobre la línea base aleatoria.",
                    },
                },
                anomalies: {
                    aboveRandom: "≥ Aleatorio",
                    overfitting: "Sobreajuste",
                    valLossUp: "Pérd. Val. ↑",
                    noConvergence: "Sin Convergencia",
                    unstableGrad: "∇ Inestable",
                    pplMismatch: "PPL ≠ exp(L)",
                    tooltips: {
                        aboveRandom: "La pérdida final está en o por encima de la línea base aleatoria — el modelo puede no haber aprendido patrones significativos.",
                        overfitting: "La brecha entren.–val. supera 0.3 — el modelo memoriza los datos de entrenamiento mejor de lo que generaliza.",
                        valLossUp: "La pérdida de validación seguía aumentando al final del entrenamiento — señal de inicio de sobreajuste.",
                        noConvergence: "La pérdida no disminuyó significativamente durante el entrenamiento — la tasa de aprendizaje puede ser demasiado alta o baja.",
                        unstableGrad: "Las normas de gradiente variaron >1000× durante el entrenamiento — indica inestabilidad de optimización.",
                        pplMismatch: "La perplejidad reportada no coincide con exp(pérdida). Esto puede indicar un problema en el pipeline de datos.",
                    },
                },
                summaries: {
                    aboveRandom: "Este modelo apenas supera al azar. Probablemente no aprendió patrones significativos — revisa la tasa de aprendizaje y la arquitectura.",
                    nonDecreasing: "La pérdida no disminuyó durante el entrenamiento. El modelo no convergió — la tasa de aprendizaje puede ser demasiado alta o baja.",
                    overfitting: "Este modelo sobreajusta — memoriza los datos de entrenamiento mejor de lo que generaliza. La brecha entre pérdida de entrenamiento y validación es grande.",
                    lossIncreasing: "La pérdida de validación seguía aumentando al final del entrenamiento — señal de sobreajuste tardío. El modelo entrenó demasiado tiempo.",
                    unstableGradients: "Las normas de gradiente variaron salvajemente durante el entrenamiento — la optimización fue inestable. Esto a menudo significa que la tasa de aprendizaje es demasiado alta.",
                    stillImproving: "El entrenamiento seguía mejorando en el último paso. Con más cómputo, este modelo podría converger más.",
                    balanced: "Este modelo entrena de forma estable y generaliza bien. Una configuración sólida y equilibrada.",
                    converged: "Entrenamiento completado. El modelo convergió con una brecha de generalización moderada.",
                },
                computeLabels: { minimal: "Mínimo", low: "Bajo", moderate: "Moderado", high: "Alto", veryHigh: "Muy Alto" },
                timeline: {
                    title: "Línea de Tiempo del Entrenamiento",
                    noData: "No hay datos de línea de tiempo disponibles.",
                    pts: "pts",
                    every: "cada",
                    steps: "pasos",
                    total: "total",
                    nonUniform: "no uniforme",
                    trend: "Tendencia:",
                    variance: "Varianza:",
                    converged: "Convergió ~",
                    tooltips: {
                        chart: "Curvas de pérdida a lo largo de los pasos de entrenamiento. Verde = pérdida de validación (principal). Morado = pérdida de entrenamiento. Rojo discontinuo = línea base aleatoria.",
                        pts: "Número de puntos de control de métricas registrados durante el entrenamiento. Más puntos = curvas más suaves e informativas.",
                        interval: "Se guardó una instantánea de métricas cada {interval} pasos de actualización de gradiente.",
                        totalSteps: "Total de actualizaciones de gradiente realizadas. Todas las configuraciones entrenan exactamente {steps}k pasos para una comparación justa.",
                        trend: "Dirección de la pérdida de validación en la segunda mitad del entrenamiento. Decreciente = aún aprendiendo. Plana = convergida. Creciente = inicio de sobreajuste.",
                        variance: "Varianza estadística de la pérdida de validación a lo largo del entrenamiento completo. Cercana a cero = entrenamiento estable.",
                        convergenceStep: "Paso de entrenamiento donde la pérdida de validación cayó por primera vez por debajo del 50% de su valor inicial.",
                    },
                    chart: {
                        randomBaseline: "línea base aleatoria",
                        train: "entren.",
                        valPrimary: "val. (principal)",
                        trainingSteps: "Pasos de Entrenamiento",
                    },
                },
                embeddingSpace: {
                    title: "PCA 2D · Deriva del Embedding",
                    tooltip: "Cada punto es un token del vocabulario, proyectado desde el espacio de embeddings aprendido a 2D mediante PCA. Usa el deslizador de instantáneas para ver cómo evolucionan los embeddings.",
                },
                generation: {
                    title: "Muestra Generada",
                    seedPlaceholder: "Texto semilla…",
                    generateButton: "Generar",
                    temp: "Temp",
                    tokens: "Tokens",
                    tempTooltip: "La temperatura controla la aleatoriedad. Baja (0.1) = determinista. Alta (2.0) = creativo pero caótico.",
                    tokensTooltip: "Número máximo de caracteres a generar. El modelo genera un carácter a la vez; más tokens = salida más larga pero más lenta.",
                    estPpl: "PPL est. ≈",
                    chars: "chars",
                    pressGenerate: "Pulsa Generar para producir texto desde el modelo seleccionado.",
                    pplTooltip: "Perplejidad = exp(pérdida). Esta es la perplejidad estimada del modelo en la distribución de entrenamiento — menor significa predicciones más seguras y fluidas.",
                },
                diagnostics: {
                    intro: "Estos diagnósticos revelan la dinámica interna del entrenamiento: flujo de gradientes, uso de neuronas y patrones de sobreajuste.",
                    gradNormLabel: "Norma de Gradiente por Pasos",
                    deadNeuronLabel: "Ratio de Neuronas Muertas por Pasos",
                    gradNormSection: "ⓘ Normas de Gradiente por Capa",
                    activationSection: "ⓘ Salud de Activaciones durante el Entrenamiento",
                    genGapSection: "ⓘ Mapa de Calor de Brecha de Generalización · Todas las Configuraciones",
                    tooltips: {
                        gradNorm: "La norma de gradiente es la magnitud global de las actualizaciones de pesos en cada paso de entrenamiento. Valores estables y moderados indican una optimización saludable.",
                        deadNeuron: "Fracción de neuronas que nunca se activan durante el entrenamiento. Una neurona 'muerta' siempre produce cero, sin contribuir al aprendizaje.",
                        gradNormLayer: "Muestra las magnitudes de gradiente por grupo de parámetros a través de las instantáneas de entrenamiento. Magnitudes equilibradas entre capas sugieren un aprendizaje estable.",
                        activationHealth: "Muestra estadísticas de saturación y neuronas muertas a lo largo del tiempo de entrenamiento. La saturación significa que las neuronas están atascadas cerca de los límites de la activación tanh (±1).",
                        genGap: "Diferencia entre pérdida de entrenamiento y validación en todas las configuraciones, promediada sobre las tasas de aprendizaje. Verde = el modelo generaliza bien. Rojo = sobreajuste.",
                    },
                },
                dataSource: "Datos reales de {count} configuraciones entrenadas · {steps}k pasos cada una · registradas cada {interval} pasos.",
                primaryValLoss: "Principal: pérdida de validación.",
                primaryTrainLoss: "Principal: pérdida de entrenamiento (val. no disponible).",
            },
            compareMode: {
                needMore: "Se necesitan al menos 2 configuraciones para comparar.",
                needAtLeastTwoConfigs: "Se necesitan al menos 2 configuraciones para comparar.",
                description: "Selecciona dos configuraciones para comparar lado a lado. El texto semilla del generador principal se sincroniza con ambas.",
                selectTwoConfigsToCompare: "Selecciona dos configuraciones para comparar lado a lado. El texto semilla del generador principal se sincroniza con ambas.",
                configLabel: "Config {label}",
                config: "Config",
                configA: "Config A",
                configB: "Config B",
                title: "Comparación Lado a Lado",
                seed: "Semilla:",
                editSeedHint: "(editar en el generador principal arriba)",
                editInMainGeneratorAbove: "(editar en el generador principal arriba)",
                selectAConfig: "Seleccionar una config…",
                selectConfigA: "Seleccionar Config A",
                selectConfigB: "Seleccionar Config B arriba",
                diffTitle: "B vs A — diferencias",
                diffSummary: "B vs A — diferencias",
                noTimelineData: "Sin datos de línea de tiempo.",
                steps: "Pasos",
                train: "entren.",
                val: "val.",
                trainingLoss: "Pérdida de Entrenamiento",
                embeddingSpace: "Espacio de Embeddings",
                generatedText: "Texto Generado",
                temperature: "T",
                generate: "Generar",
                generating: "Generando…",
                seedTextAboveWillBeUsed: "Se usará el texto semilla de arriba.",
                metrics: {
                    valLoss: "Pérd. Val.",
                    perplexity: "Perplejidad",
                    gap: "Brecha",
                    genGap: "Brecha Gen.",
                    score: "Puntuación",
                    params: "Parámetros",
                },
                panel: {
                    trainingLoss: "Pérdida de Entrenamiento",
                    embeddingSpace: "Espacio de Embeddings",
                    generatedText: "Texto Generado",
                    seedUsed: "Se usará el texto semilla de arriba.",
                    noTimeline: "Sin datos de línea de tiempo.",
                    tempLabel: "T=",
                    generateButton: "Generar",
                },
            },
            scatterPlot: {
                description: "Cada punto es un modelo entrenado. X = número de parámetros (coste), Y = pérdida de validación final (menor es mejor). Color = dimensión del embedding. La línea discontinua es la",
                paretoFrontier: "frontera de Pareto",
                paretoDesc: "— mejor pérdida para cada nivel de cómputo.",
                highlighted: "resaltados",
                filters: {
                    all: "Todos",
                    allTip: "Mostrar todas las configuraciones",
                    best: "Mejores ★",
                    bestTip: "Top 25% por puntuación compuesta",
                    worst: "Peores",
                    worstTip: "Bottom 25% por puntuación — mayor pérdida, menor calidad",
                    anomalies: "Anomalías",
                    anomaliesTip: "Configs con brecha de generalización > 0.3 o puntuación < 0.2",
                },
                legend: { paretoLine: "Frontera de Pareto" },
                footer: "{count} configuraciones · Haz clic en cualquier punto para seleccionar · Abajo-derecha = más cómputo, menos beneficio",
                axisX: "Parámetros",
                axisY: "Pérd. Val.",
            },
            embeddingDrift: {
                snapshotLabel: "Instantánea de entrenamiento",
                trainingSnapshot: "Instantánea de entrenamiento",
                stepLabel: "Paso",
                step: "Paso",
                loading: "Cargando embeddings…",
                phaseText: {
                    p0: "Inicialización aleatoria — los embeddings aún no tienen estructura.",
                    p1: "Entrenamiento temprano — los clústeres comienzan a formarse.",
                    p2: "Entrenamiento temprano-medio — las categorías de caracteres se vuelven distintas.",
                    p3: "Entrenamiento medio — el espacio de embeddings muestra estructura clara. Los tokens similares se agrupan.",
                    p4: "Entrenamiento tardío — la estructura se consolida, el ruido se reduce.",
                    p5: "Punto de control final — embeddings completamente entrenados. Esto es lo que el modelo usa para predecir.",
                },
                phases: {
                    "0": "Inicialización aleatoria — los embeddings aún no tienen estructura.",
                    "1": "Entrenamiento temprano — los clústeres comienzan a formarse.",
                    "2": "Entrenamiento temprano-medio — las categorías de caracteres se vuelven distintas.",
                    "3": "Entrenamiento medio — el espacio de embeddings muestra estructura clara. Los tokens similares se agrupan.",
                    "4": "Entrenamiento tardío — la estructura se consolida, el ruido se reduce.",
                    "5": "Punto de control final — embeddings completamente entrenados. Esto es lo que el modelo usa para predecir.",
                },
                snapshotUnavailable: "Instantánea no disponible — mostrando el punto de control más cercano disponible.",
            },
            embeddingViz: {
                loading: "Cargando embeddings…",
                waiting: "Esperando datos de embeddings…",
                dim1: "Dimensión 1 (PCA)",
                dim2: "Dimensión 2 (PCA)",
                tokens: "tokens",
                clickInfo: "Haz clic en cualquier token para resaltar sus vecinos más cercanos. Los tokens similares se agrupan en el espacio de embeddings aprendido.",
                clickToHighlight: "Haz clic en cualquier token para resaltar sus vecinos más cercanos. Los tokens similares se agrupan en el espacio de embeddings aprendido.",
                deselectInfo: "Haz clic en otro token o en \"{token}\" de nuevo para deseleccionar. Las líneas discontinuas conectan con los 4 vecinos más cercanos en el espacio de embeddings.",
                clickToDeselect: "Haz clic en otro token o en \"{token}\" de nuevo para deseleccionar. Las líneas discontinuas conectan con los 4 vecinos más cercanos en el espacio de embeddings.",
                categories: {
                    vowel: "Vocales",
                    vowels: "Vocales",
                    consonant: "Consonantes",
                    consonants: "Consonantes",
                    digit: "Dígitos",
                    digits: "Dígitos",
                    punctuation: "Puntuación",
                    whitespace: "Espacio / Especial",
                    spaceSpecial: "Espacio / Especial",
                },
            },
            nearestNeighbors: {
                title: "Vecinos Más Cercanos (Similitud Coseno)",
                loading: "Cargando datos de vecinos…",
                neighborsOf: "Vecinos de",
                noNeighborData: "No hay datos de vecinos para este token.",
                noData: "No hay datos de vecinos para este token.",
                selectPrompt: "Selecciona un token arriba para ver sus vecinos más cercanos por similitud coseno en el espacio de embeddings.",
            },
            snapshotDiagnostics: {
                noSnapshotData: "No hay datos de instantáneas disponibles.",
                noGradData: "No hay datos de norma de gradiente en las instantáneas.",
                noSatData: "No hay datos de saturación de activaciones en las instantáneas.",
                gradLegend: "Verde = gradientes pequeños · Amarillo/Rojo = gradientes grandes · Magnitudes consistentes entre capas indican un entrenamiento saludable.",
                saturatedLeft: "Activaciones saturadas (izquierda)",
                deadRight: "Neuronas muertas (derecha)",
                satLegend: "La saturación alta significa que muchas neuronas están fijadas en los extremos de tanh (±1). Las neuronas muertas nunca se activan. Ambas desperdician capacidad.",
                satNote: "La saturación alta significa que muchas neuronas están fijadas en los extremos de tanh (±1). Las neuronas muertas nunca se activan. Ambas desperdician capacidad.",
                stepHeader: "Paso",
                step: "Paso",
            },
            genGapHeatmap: {
                header: "oculto ↓ / emb →",
                axisLabel: "oculto ↓ / emb →",
                gapLabel: "Brecha:",
                legend: {
                    healthy: "< 0 (saludable)",
                    low: "0–0.1",
                    mid: "0.1–0.2",
                    medium: "0.1–0.2",
                    high: "0.2–0.3",
                    overfit: "> 0.3 (sobreajuste)",
                },
                note: "Cada celda promedia la brecha entren.–val. en todas las tasas de aprendizaje para ese par (emb_dim, hidden_size). Rojo = sobreajuste. Verde = generalización saludable.",
                description: "Cada celda promedia la brecha entren.–val. en todas las tasas de aprendizaje para ese par (emb_dim, hidden_size). Rojo = sobreajuste. Verde = generalización saludable.",
                configs: "configs (entre LRs)",
                avgGap: "brecha prom.=",
                bestLoss: "mejor pérdida=",
            },
        },
        neuralNetworks: {
            title: "Redes Neuronales y Deep Learning",
            description: "Una exploración desde primeros principios de las redes neuronales artificiales — del perceptrón a la retropropagación. Comprende cómo los parámetros aprendidos reemplazan al conteo y por qué las representaciones densas generalizan donde los N-gramas fallan.",
            hero: {
                badge: "Computación Neuronal",
            },
            freeLab: {
                title: "Playground de Redes Neuronales",
                description: "Experimenta libremente con perceptrones, funciones de activación, actualizaciones de pesos y dinámicas de entrenamiento.",
            },
            sections: {
                historicalOrigins: { number: "01", label: "Historia" },
                countingToLearning: { number: "02", label: "Aprendizaje" },
                perceptron: { number: "03", label: "Perceptrón" },
                weightsAndBias: { number: "04", label: "Parámetros" },
                activationFunctions: { number: "05", label: "Activaciones" },
                backpropagation: { number: "06", label: "Retroprop." },
                parameterUpdates: { number: "07", label: "Actualizaciones" },
                bigramConnection: { number: "08", label: "Conexión" },
                limitations: { number: "09", label: "Reflexión" },
                playground: {
                    inputs: {
                        title: "Entradas",
                        desc: "Valores de características que se introducen en el perceptrón. Cada entrada se multiplica por su peso correspondiente antes de sumarse.",
                        x1: "Primer valor de entrada (x₁). Se multiplica por el peso w₁ antes de entrar al nodo de suma.",
                        x2: "Segundo valor de entrada (x₂). Se multiplica por el peso w₂ antes de entrar al nodo de suma.",
                    },
                    weights: {
                        title: "Parámetros",
                        desc: "Parámetros aprendibles que escalan cada entrada. El sesgo desplaza el umbral de activación independientemente de las entradas.",
                        w1: "Peso para la entrada x₁. Controla cuánto influye x₁ en la salida. Se actualiza por descenso de gradiente durante el entrenamiento.",
                        w2: "Peso para la entrada x₂. Controla cuánto influye x₂ en la salida. Se actualiza por descenso de gradiente durante el entrenamiento.",
                        bias: "Término de sesgo (b). Desplaza la suma ponderada, permitiendo que la neurona se active incluso cuando todas las entradas son cero.",
                    },
                    activation: {
                        title: "Función de Activación",
                        desc: "Transformación no lineal aplicada tras la suma ponderada. Sin ella, apilar capas colapsaría en una única función lineal.",
                        linear: "Sin transformación — la salida es igual a la suma ponderada z. Útil como referencia, pero no puede modelar patrones no lineales.",
                        relu: "Unidad Lineal Rectificada. Devuelve max(0, z). Dispersa, eficiente y ampliamente usada en redes profundas.",
                        sigmoid: "Comprime la salida a (0, 1). Útil para salidas de probabilidad binaria, pero puede causar gradientes que desaparecen.",
                        tanh: "Comprime la salida a (−1, 1). Centrada en cero, a menudo preferida sobre sigmoid para capas ocultas.",
                    },
                    training: {
                        title: "Entrenamiento",
                        desc: "Ajusta el objetivo y la tasa de aprendizaje, luego avanza paso a paso por el descenso de gradiente para minimizar la pérdida.",
                        target: "El valor de salida deseado (y). El modelo intenta minimizar la diferencia cuadrática entre su predicción y este objetivo.",
                        learningRate: "Tasa de aprendizaje (η). Controla el tamaño del paso en el descenso de gradiente. Muy alta causa inestabilidad; muy baja ralentiza la convergencia.",
                        step: "Ejecuta un paso de descenso de gradiente: calcula los gradientes y actualiza w₁, w₂ y b por −η × gradiente.",
                        auto: "Ejecuta 10 pasos de descenso de gradiente en secuencia para observar cómo evolucionan los parámetros y la pérdida.",
                        reset: "Reinicia todos los parámetros e historial de entrenamiento a sus valores iniciales.",
                        random: "Aleatoriza los pesos y el sesgo para explorar una región diferente del paisaje de pérdida.",
                        steps: "Número total de pasos de descenso de gradiente realizados en esta sesión de entrenamiento.",
                        stepIndex: "Número de paso en el registro del historial de entrenamiento.",
                        noData: "Sin datos de entrenamiento aún",
                        noDataHint: "Haz clic en \"Entrenar 1 Paso\" o \"Auto-Entrenar ×10\" para comenzar",
                        insightsTitle: "Perspectivas de Entrenamiento",
                        runInference: "Ejecuta inferencia para ver los datos de entrenamiento",
                        stats: {
                            finalLoss: { label: "Pérdida Final", desc: "El nivel de error al final del entrenamiento. Cuanto menor, mejor." },
                            steps: { label: "Pasos", desc: "Cuántas veces el modelo actualizó sus parámetros durante el entrenamiento." },
                            batchSize: { label: "Tamaño de Lote", desc: "Número de ejemplos procesados por paso de actualización de gradiente." },
                            learningRate: { label: "Tasa de Aprendizaje", desc: "Tamaño del paso en el descenso de gradiente. Muy alta causa inestabilidad; muy baja ralentiza la convergencia." },
                            parameters: { label: "Parámetros", desc: "Número total de pesos aprendibles en el modelo." },
                        },
                    },
                    visualization: {
                        sum: "Nodo de suma ponderada (Σ). Calcula z = w₁x₁ + w₂x₂ + b antes de aplicar la función de activación.",
                        output: "Predicción final ŷ = activación(z). Es el valor que la red produce tras aplicar la no linealidad.",
                        loss: "Pérdida de error cuadrático medio: L = (ŷ − objetivo)². Mide cuánto se aleja la predicción del objetivo deseado.",
                        activationNode: "Nodo de función de activación. Aplica la no linealidad seleccionada a la suma ponderada z.",
                        activationCurve: "Curva de la función de activación. El punto muestra la entrada z actual y su salida correspondiente f(z).",
                        equation: "Ecuación completa del paso hacia adelante: multiplica cada entrada por su peso, suma el sesgo y aplica la función de activación.",
                        lossCurve: "Pérdida a lo largo de los pasos de entrenamiento. Una curva descendente indica que el modelo está aprendiendo.",
                        lossCurveLabel: "Pérdida por pasos de entrenamiento",
                        lossTooltipTitle: "¿Qué es la Pérdida?",
                        lossTooltipErrorLabel: "Error de Predicción",
                        lossTooltipError: "La pérdida mide cuánto se \"sorprende\" el modelo. Una pérdida alta significa que está prediciendo mal con frecuencia.",
                        lossTooltipBenchmarkLabel: "El Punto de Referencia",
                        lossTooltipBenchmark: "Una predicción aleatoria pura daría una pérdida de ~4.56 (−ln(1/96)). Cualquier valor menor significa que el modelo ha aprendido algo.",
                        lossTooltipCaption: "La curva descendente muestra al modelo descubriendo lentamente patrones en tu texto.",
                    },
                    tabs: {
                        perceptron: "Visualiza el paso hacia adelante de una sola neurona: las entradas se escalan por pesos, se suman con un sesgo y pasan por una activación.",
                        activation: "Explora cómo la función de activación elegida transforma la suma ponderada z en la predicción final ŷ.",
                        gradients: "Inspecciona el flujo de gradientes por la regla de la cadena y observa exactamente cómo se actualizará cada parámetro.",
                        training: "Sigue la evolución de la pérdida y los parámetros a lo largo de los pasos para observar el descenso de gradiente en acción.",
                    },
                    gradients: {
                        forwardPass: "Paso hacia adelante: calcula z, aplica la activación y calcula la pérdida a partir de la predicción y el objetivo actuales.",
                        forwardPassLabel: "Paso Hacia Adelante",
                        chainRule: "Retropropagación mediante la regla de la cadena: descompone ∂L/∂w en un producto de gradientes locales a través de cada nodo.",
                        chainRuleLabel: "Gradientes (Regla de la Cadena)",
                        weightUpdate: "Actualización propuesta de parámetros: nuevo valor = valor anterior − η × gradiente. Se aplica al hacer clic en Entrenar 1 Paso.",
                        weightUpdateLabel: "Actualización de Pesos Propuesta",
                        linearSum: "Pre-activación lineal: z = w₁x₁ + w₂x₂ + b. La suma ponderada bruta antes de la función de activación.",
                        linearSumLabel: "Suma lineal",
                        prediction: "Predicción ŷ = activación(z). La salida de la neurona tras aplicar la función de activación no lineal.",
                        predictionLabel: "Predicción",
                        loss: "Pérdida L = (ŷ − objetivo)². Error cuadrático entre la predicción y el valor objetivo deseado.",
                        lossLabel: "Pérdida",
                    },
                    buttons: {
                        trainStep: "Entrenar 1 Paso",
                        autoTrain: "Auto-Entrenar ×10",
                        reset: "Reiniciar",
                        random: "Aleatorio",
                    },
                    tabLabels: {
                        perceptron: "Perceptrón",
                        activation: "Activación",
                        gradients: "Gradientes",
                        training: "Entrenamiento",
                    },
                    diagram: {
                        caption: "Ajusta las entradas, pesos y sesgo para ver cómo el perceptrón los transforma en una salida.",
                        inputX1: "Entrada x₁",
                        inputX2: "Entrada x₂",
                        weightW1: "Peso w₁",
                        weightW2: "Peso w₂",
                        biasB: "Sesgo b",
                    },
                },
            },
        },
    },
    bigramNarrative: {
        hero: {
            eyebrow: "Comprendiendo los Modelos de Lenguaje",
            titlePrefix: "El Modelo",
            titleSuffix: "Bigrama",
            description: "Una exploración desde primeros principios del modelo estadístico de lenguaje más simple — y por qué sigue importando."
        },
        problem: {
            title: "El Problema de la Predicción",
            lead: "El lenguaje es fundamentalmente secuencial. Cada palabra que lees ahora está influenciada por las palabras que vinieron antes.",
            p1: "Esta propiedad — que cada token en una secuencia lleva ",
            p1Highlight: "expectativas sobre lo que sigue",
            p2: " — es lo que hace el lenguaje tanto expresivo como predecible. También es lo que lo hace tan difícil de modelar computacionalmente.",
            p3: "El desafío central del modelado de lenguaje es engañosamente simple de enunciar:",
            quote: "Dado lo que ya hemos visto, ¿qué debería venir a continuación?",
            p4: "Esta pregunta ha impulsado décadas de investigación en ",
            h1: "lingüística computacional",
            h2: "teoría de la información",
            h3: "aprendizaje profundo",
            p5: ". Para construir un modelo que pueda responderla, necesitamos una forma de capturar la estructura estadística del lenguaje. Empecemos con el enfoque más simple posible.",
            label: "Fundamentos"
        },
        coreIdea: {
            label: "Idea Central",
            title: "La Idea Estadística Más Simple",
            lead: "¿Y si, en lugar de intentar comprender el significado, simplemente observáramos patrones?",
            p1: "Concretamente: ",
            h1: "¿con qué frecuencia un carácter sigue a otro?",
            p2: " Esta es la idea central detrás del modelo Bigrama. Ignora la gramática, la semántica y las dependencias de largo alcance por completo. Solo hace una pregunta: dado el token actual, ¿cuál es la distribución de probabilidad sobre el siguiente token?",
            caption: "La suposición Bigrama: el siguiente token depende solo del actual.",
            p3: "Modelamos P(x_{t+1} | x_t) — la probabilidad de ver un token siguiente particular dado solo el token que acabamos de observar. Nada más, nada menos. Esta simplificación radical es lo que hace el modelo tanto tratable como limitado.",
            calloutTitle: "Idea Clave",
            calloutP1: "El \"bi\" en Bigrama significa ",
            calloutH1: "dos",
            calloutP2: ". El modelo considera pares de tokens — el actual y el siguiente. No tiene memoria de nada anterior al token actual."
        },
        mechanics: {
            label: "Mecánica",
            title: "Construyendo una Tabla de Transición",
            lead: "Para aprender estas probabilidades, el modelo recorre un corpus de entrenamiento y cuenta cada par de tokens consecutivos.",
            p1: "Para cada token A, registra con qué frecuencia cada posible token B aparece inmediatamente después. Estos conteos forman una ",
            h1: "matriz",
            p2: " — una tabla bidimensional donde las filas representan el token actual y las columnas el siguiente. Cada celda contiene el número de veces que esa transición específica se observó en los datos de entrenamiento.",
            p3: "La visualización a continuación es un renderizado en vivo de esta matriz de transición. Las celdas más brillantes indican pares más frecuentes — patrones que el modelo ha aprendido de texto real.",
            calloutTitle: "Leyendo la Matriz",
            calloutP1: "Cada fila representa un carácter \"dado\". Cada columna representa el carácter \"siguiente\". El brillo de una celda codifica cuán probable es esa transición. Observa cómo algunas filas son casi uniformes (el modelo no está seguro) mientras otras tienen picos pronunciados (preferencias fuertes)."
        },
        normalization: {
            label: "Normalización",
            title: "De Conteos a Probabilidades",
            lead: "Los conteos brutos por sí solos no nos dicen mucho. Para hacer predicciones, necesitamos convertirlos en probabilidades.",
            p1: "Lo hacemos ",
            h1: "normalizando cada fila",
            p2: " de la matriz de conteos — dividiendo cada conteo por el total de transiciones desde el token de esa fila. Tras la normalización, cada fila suma 1.0, formando una distribución de probabilidad válida.",
            p3: "El modelo ahora puede hacer afirmaciones concretas: \"Después de la letra h, hay un 32% de probabilidad de que el siguiente carácter sea e, un 15% de que sea a, etc.\"",
            p4: "Pruébalo tú mismo. Escribe cualquier texto para ver qué predice el modelo que vendrá a continuación — basado ",
            h2: "únicamente en el último carácter",
            p5: " de tu entrada."
        },
        sampling: {
            label: "Muestreo",
            title: "Generando Texto Nuevo",
            lead: "Una vez que tenemos una distribución de probabilidad, podemos hacer algo notable: generar texto completamente nuevo.",
            p1: "El proceso se llama ",
            h1: "muestreo autorregresivo",
            p2: ". Comienza con un carácter semilla, muestrea el siguiente de su distribución de probabilidad, luego usa ese nuevo carácter como semilla para el siguiente paso. Repite indefinidamente.",
            calloutTitle: "Temperatura",
            calloutP1: "El parámetro de ",
            calloutH1: "temperatura",
            calloutP2: " controla cuán \"creativa\" es la generación. A ",
            calloutH2: "temperaturas bajas",
            calloutP3: ", el modelo casi siempre elige el token más probable. A ",
            calloutH3: "temperaturas altas",
            calloutP4: ", muestrea más uniformemente — produciendo resultados sorprendentes y a menudo sin sentido.",
            tempP1: "Cómo muestreas importa tanto como lo que aprendiste. Un único parámetro de ",
            tempH1: "temperatura",
            tempP2: " escala los logits antes del paso final de softmax. Por debajo de 1.0, la distribución se afila — el modelo casi siempre elige su carácter mejor clasificado. Por encima de 1.0, la distribución se aplana — cada carácter tiene más oportunidades, a costa de la coherencia.",
            tempBridge: "Ahora prueba el playground de generación. El mismo modelo bigrama produce texto notablemente diferente a temperatura 0.1 versus 2.5 — no porque su conocimiento cambiara, sino porque su estrategia de muestreo lo hizo.",
            softmaxFigureLabel: "Temperatura Softmax · Conceptual",
            softmaxFigureHint: "Arrastra el control deslizante para ver cómo la temperatura redistribuye la misma distribución de probabilidad.",
            playgroundLabel: "Playground de Generación",
            playgroundHint: "Ajusta la temperatura y observa cómo afecta la creatividad del texto generado.",
            p3: "Genera texto a continuación y observa cómo un modelo con ",
            h2: "solo un carácter de memoria",
            p4: " produce texto que es estadísticamente plausible a nivel de carácter, pero sin significado en ningún nivel superior."
        },
        reflection: {
            label: "Reflexión",
            title: "Potencia y Limitaciones",
            lead: "El modelo Bigrama es poderoso precisamente por su simplicidad.",
            p1: "Requiere muy pocos parámetros — solo una matriz V × V, donde V es el tamaño del vocabulario. Entrena instantáneamente. Y proporciona una clara ",
            h1: "línea base probabilística",
            p2: " para la generación de lenguaje que todo modelo más sofisticado debe superar.",
            calloutTitle: "La Limitación Fundamental",
            calloutP1: "El modelo no tiene ",
            calloutH1: "memoria más allá de un solo token",
            calloutP2: ". No puede aprender que \"th\" suele ir seguido de \"e\", porque cuando ve \"h\", ya ha olvidado la \"t\". Captura co-ocurrencia local pero nada sobre palabras, frases o significado.",
            p3: "Esta limitación es exactamente lo que motiva la progresión hacia arquitecturas más sofisticadas: ",
            h2: "los N-gramas",
            p4: " extienden la ventana de contexto, ",
            h3: "los MLPs",
            p5: " aprenden representaciones densas, y ",
            h4: "los Transformers",
            p6: " atienden a toda la secuencia a la vez.",
            quote: "Cada modelo en este laboratorio se construye sobre la misma pregunta central: dado el contexto, ¿qué viene a continuación?"
        },
        tokens: {
            label: "Representación",
            title: "Representando texto",
            lead: "Dividimos el texto en tokens.",
            charTitle: "Caracteres:",
            charDesc: "vocabulario pequeño, fácil de ver.",
            wordTitle: "Palabras:",
            wordDesc: "más expresivas, vocabulario enorme.",
            note: "Usamos caracteres aquí.",
            charLevelTitle: "Tokens a nivel de carácter",
            charLevelBody: "Vocabulario pequeño y fijo de ~96 símbolos ASCII imprimibles. Toda entrada posible es representable. Simple de implementar y visualizar — ideal para entender los fundamentos del modelado de lenguaje.",
            wordLevelTitle: "Tokens a nivel de palabra",
            wordLevelBody: "Unidades semánticas más ricas que transmiten más significado por token. Pero el vocabulario puede alcanzar 50.000–500.000 entradas, haciendo la matriz de transición enorme. Las palabras raras causan escasez; las palabras no vistas durante el entrenamiento causan fallos completos en inferencia.",
            charLimitations: "Los modelos a nivel de carácter tienen un vocabulario pequeño y manejable — pero deben aprender todo desde cero. No hay nociones preconstruidas de palabras, morfología o significado. El modelo debe descubrir que 't', 'h', 'e' juntos forman una palabra común puramente a partir de estadísticas de co-ocurrencia.",
            wordLimitations: "Los modelos a nivel de palabra son más expresivos pero enfrentan un problema fundamental de escalabilidad. El inglés tiene más de 170.000 palabras de uso común. Un modelo bigrama a nivel de palabra necesitaría una matriz de transición de 170.000 × 170.000 — casi 29.000 millones de celdas — la mayoría vacías. Este problema de escasez es una de las principales motivaciones para los modelos de lenguaje neurales.",
            whyCharHere: "Para este laboratorio, usamos tokens a nivel de carácter. El vocabulario se mantiene lo suficientemente pequeño como para visualizar toda la matriz de transición a la vez, haciendo el conocimiento aprendido del modelo directamente inspeccionable. Cada decisión de diseño que ves aquí escala directamente a modelos a nivel de palabra y subpalabra — solo cambia el tamaño del vocabulario."
        },
        counting: {
            title: "La idea Bigrama",
            lead: "Contar pares: actual -> siguiente. Más conteos = más probable.",
            builderTitle: "Constructor paso a paso",
            builderDesc: "Recorre el texto; cada par añade +1 a una celda.",
            p1: "La operación central es casi vergonzosamente simple: recorre el texto de entrenamiento un carácter a la vez, y para cada par consecutivo (carácter actual → siguiente carácter), incrementa un contador. Eso es todo. Después de escanear millones de caracteres, estos conteos codifican la estructura estadística del lenguaje.",
            p2: "El constructor paso a paso a continuación hace esto concreto. Observa cómo cada par de caracteres en el texto de entrada añade exactamente un conteo a la celda correspondiente en la matriz.",
            calloutTitle: "Por qué funciona el conteo",
            calloutText: "La Ley de los Grandes Números garantiza que a medida que crecen los datos de entrenamiento, las frecuencias observadas convergen a las probabilidades subyacentes reales del lenguaje."
        },
        matrix: {
            title: "La tabla de transición",
            lead: "Filas = token actual, columnas = siguiente.",
            desc: "Construye abajo, luego ve la matriz completa."
        },
        probabilities: {
            title: "Conteos a probabilidades",
            lead: "Normaliza cada fila al 100%.",
            desc: "El modelo lee la fila del último token y muestrea el siguiente.",
            inferenceIntro: "La herramienta a continuación te permite recorrer este proceso de inferencia paso a paso: elige cualquier carácter de contexto, selecciona cómo normalizar su fila — división simple o softmax — y luego muestrea para ver qué carácter predice el modelo. Prueba varios caracteres y observa cómo cambia la distribución según lo que el modelo vio más a menudo en el entrenamiento.",
            overlayTitle: "Conteos -> Probabilidades -> Muestreo",
            overlayDesc: "Elige token, normaliza fila, muestrea el siguiente.",
            step1: "1) Valores de fila",
            step2: "2) Normalizar",
            step3: "3) Muestrear siguiente token",
            currentToken: "Token actual",
            typeChar: "Escribe un carácter",
            normalizeSimple: "Normalización simple",
            softmax: "Softmax",
            sampleNext: "Muestrear siguiente token",
            mostLikely: "Más probable:",
            remaining: "Restante:",
            stochastic: "El muestreo es aleatorio."
        },
        limitations: {
            title: "Limitaciones",
            lead: "El Bigrama no tiene memoria—solo el último token.",
            desc: "Sin contexto largo. De ahí los N-gramas y las redes neuronales."
        },
        textToNumbers: {
            label: "Cómo los Ordenadores Ven el Texto",
            title: "Convirtiendo Texto en Números",
            lead: "Un ordenador no puede leer letras como tú. Necesita números que pueda almacenar y comparar.",
            p1: "Damos a cada carácter un número, como un número de asiento en un teatro. Ahora el modelo puede contar qué asiento numerado tiende a venir después.",
            bridge: "Una vez que el texto se convierte en números, podemos construir una tabla de conteos. Luego podemos convertir esa tabla en probabilidades para la siguiente letra.",
        },
        cliffhanger: {
            label: "La Trampa",
            title: "Un Gran Problema",
            lead: "Este modelo solo recuerda una letra. Esa es una memoria muy pequeña.",
            p1: "Si ves 't' y luego 'h', quieres que el modelo recuerde ambas. Pero un modelo bigrama olvida la 't' en cuanto ve la 'h'.",
            hookLine: "¿Qué ocurre si dejamos que el modelo recuerde más de una letra?",
        },
        cta: {
            freeLabButton: "Explorar en Lab Libre",
            nextTitle: "¿Y si Recordamos Más?",
            nextDesc: "Conoce el modelo N-gram — una máquina de predicción que mira los últimos caracteres, no solo uno.",
        },
        footer: {
            text: "A continuación, haremos crecer esta idea hacia un modelo N-gram — una versión extendida que recuerda más de un carácter anterior.",
            brand: "LM-Lab · Modo Educativo"
        }
    },
    bigramBuilder: {
        description: "Construimos la matriz bigrama escaneando el texto carácter por carácter. Por cada par de caracteres consecutivos (actual → siguiente), incrementamos la celda [actual, siguiente]. Esta tabla captura con qué frecuencia un carácter es seguido por otro.",
        placeholder: "Escribe texto aquí...",
        hint: "Introduce algún texto para ver cómo se construye la matriz bigrama.",
        buttons: {
            build: "Construir Matriz",
            next: "Siguiente Paso",
            autoPlay: "Auto-Reproducir",
            pause: "Pausar",
            instant: "Completar",
            reset: "Reiniciar"
        },
        vocab: "Vocabulario educativo",
        normalized: "Texto normalizado:",
        empty: "(vacío tras filtrar)",
        skipped: "Mostrando los primeros {max} caracteres únicos por claridad (omitiendo {count} carácter(es) único(s)).",
        step1: "Paso",
        step2: "actualiza celda [",
        step3: "].",
        currentStep: "Paso Actual",
        updatingCell: "Actualizando celda en fila",
        updatingCellCol: "col",
        pressBuild: "Pulsa Construir Matriz y empieza a iterar sobre los pares de caracteres.",
        table: {
            curnxt: "act \\ sig"
        }
    },
    ngramNarrative: {
        hero: {
            eyebrow: "Comprendiendo los Modelos de Lenguaje",
            titlePrefix: "El Modelo",
            titleSuffix: "N-Gram",
            description: "¿Qué sucede cuando le damos a un modelo de lenguaje más de un carácter de memoria? Un viaje a través de ventanas de contexto, explosiones combinatorias y los límites del conteo.",
        },
        moreContext: {
            label: "Más Contexto",
            title: "Más Allá de un Solo Carácter",
            lead: "El defecto fatal del modelo Bigrama es su amnesia — solo recuerda el último carácter. ¿Y si dejamos que el modelo mire más atrás?",
            p1: "Un modelo N-gram condiciona sus predicciones en los",
            p1Highlight: "N caracteres anteriores",
            p1End: " en lugar de solo uno. Un trigrama (N=2) mira los últimos dos caracteres; un 4-grama mira tres; y así sucesivamente.",
            p2: "Esta simple extensión tiene un impacto profundo en la calidad de predicción. Con más contexto, el modelo puede distinguir entre secuencias que un bigrama trataría de forma idéntica. Después de \"th\", sabe que \"e\" es mucho más probable que después de solo \"h\".",
            p3: "Pero esta mejora viene con un costo elevado — uno que define la tensión central del modelado estadístico del lenguaje.",
            calloutTitle: "La Suposición N-gram",
            calloutText: "Un modelo N-gram asume que el siguiente token depende solo de los N tokens anteriores. Esta es la suposición de Markov de orden N. Intercambia contexto global por tratabilidad.",
        },
        contextWindow: {
            label: "Ventana de Contexto",
            title: "Viendo Más del Pasado",
            lead: "La ventana de contexto determina cuántos caracteres previos puede \"ver\" el modelo al hacer una predicción.",
            caption: "Observa cómo ventanas de contexto más grandes capturan patrones más significativos — pero el número de contextos posibles explota.",
            hint: "Observa cómo el contexto crece carácter por carácter al aumentar N.",
            p1: "Cada incremento en N le da al modelo más información con la que trabajar. Pero también multiplica el número de estados posibles que el modelo debe rastrear — un tema que exploraremos en detalle.",
        },
        howItWorks: {
            label: "Mecánica",
            title: "Contando con Contexto",
            lead: "El proceso de conteo es el mismo que en los bigramas — pero ahora en lugar de contar pares, contamos grupos más largos: el contexto de N caracteres más lo que sigue.",
            p1: "Para cada posición en el texto de entrenamiento, el modelo extrae el",
            p1Highlight: " contexto de N caracteres",
            p1End: " y cuenta qué carácter le sigue. Después usa esos conteos como una tabla de búsqueda: encuentra el contexto, luego lee el siguiente carácter más común.",
            p2: "A medida que N crece, la tabla de conteo adquiere más dimensiones. Con N=1 (bigrama), es una cuadrícula simple. Con N=2, imagina una pila de cuadrículas — una para cada posible contexto de dos caracteres. La tabla crece en todas las direcciones.",
        },
        improvement: {
            label: "Mejora",
            title: "La Predicción Mejora",
            lead: "Ahora viene la recompensa. Cuando el modelo ve más contexto, sus predicciones se vuelven mucho más seguras y correctas.",
            example: "Después de \"h\", la siguiente letra no está clara. Después de \"th\", \"e\" se vuelve muy probable. Después de \"the\", un espacio se vuelve muy probable.",
        },
        statistical: {
            label: "Naturaleza Estadística",
            title: "Un Modelo Puramente Estadístico",
            lead: "Los modelos N-gram no entienden el lenguaje. Son máquinas de conteo sofisticadas.",
            p1: "Cada predicción es una",
            p1Highlight: "búsqueda en tabla",
            p1End: " — el modelo encuentra el contexto coincidente en su tabla y devuelve la distribución de probabilidad almacenada. No hay parámetros aprendidos, ni gradientes, ni optimización.",
            p2: "Esto hace que los N-gramas sean extremadamente rápidos en inferencia y trivialmente interpretables: siempre puedes preguntar \"¿por qué el modelo predijo X?\" y rastrear la respuesta hasta ejemplos exactos de entrenamiento.",
            calloutTitle: "Sin Generalización",
            calloutText: "Si el modelo nunca ha visto un contexto particular en el entrenamiento, tiene cero información sobre lo que viene después. A diferencia de las redes neuronales, los N-gramas no pueden generalizar a partir de contextos similares — cada contexto se trata como completamente independiente.",
        },
        complexity: {
            label: "Complejidad",
            title: "La Explosión Combinatoria",
            lead: "Aquí yace la limitación fundamental de los modelos N-gram: el número de contextos posibles crece como |V|^N.",
            p1: "Con un vocabulario de ~96 caracteres, un bigrama tiene 96 contextos posibles. Un trigrama tiene 9.216. Un 4-grama tiene",
            p1Highlight: " 884.736",
            p1End: ". Un 5-grama tiene más de 84 millones. La mayoría de estos contextos nunca aparecerán en ningún corpus de entrenamiento realista.",
            p2: "Este crecimiento exponencial significa que a medida que N aumenta, la tabla del modelo se vuelve abrumadoramente dispersa. La mayoría de las celdas contienen cero conteos, haciendo las predicciones poco fiables o imposibles para contextos no vistos.",
            vocabCalloutTitle: "Y empeora mucho más con palabras",
            vocabCalloutText: "Este laboratorio usa caracteres (~96 posibles). Los modelos reales usan palabras. Con 50.000 palabras, incluso una matriz de bigramas necesita 2.500 millones de celdas. Una tabla de trigramas necesitaría 125 billones. Las matemáticas se vuelven catastróficas muy rápido.",
            comparisonLabel: "Comparación N-Gram · Métricas del backend en vivo",
            comparisonHint: "Compara perplejidad, utilización de contexto y espacio de estados entre diferentes valores de N.",
            metricsLegend: {
                perplexity: "Perplejidad — más baja significa predicciones más seguras. Mide cuán \"sorprendido\" está el modelo en promedio.",
                utilization: "Utilización de contexto — qué fracción de todos los posibles contextos de N caracteres fueron realmente observados en los datos de entrenamiento.",
                contextSpace: "Espacio de contexto — el número total de contextos teóricamente posibles (|V|^N). Crece exponencialmente.",
            },
        },
        vocabulary: {
            label: "Vocabulario",
            title: "Caracteres vs. Palabras",
            lead: "Usamos tokens a nivel de carácter en este laboratorio, pero los N-gramas del mundo real a menudo operan con palabras — haciendo la explosión aún peor.",
            p1: "Con un vocabulario de 50.000 palabras, incluso una",
            p1Highlight: " matriz bigrama necesita 2.500 millones de celdas",
            p1End: ". Una tabla de trigramas requeriría 125 billones de entradas. Por eso los N-gramas a nivel de palabra más allá de N=3 son esencialmente impracticables sin suavizado y poda agresivos.",
            p2: "Los modelos a nivel de carácter mantienen el vocabulario pequeño (~96), haciendo factible visualizar y explorar la tabla completa. Pero el compromiso es que los caracteres individuales casi no portan significado semántico.",
        },
        noUnderstanding: {
            label: "Limitaciones",
            title: "Sin Verdadera Comprensión",
            lead: "Los modelos N-gram capturan patrones de co-ocurrencia local pero no tienen noción de significado, gramática o coherencia de largo alcance.",
            p1: "El modelo trata \"the cat sat on the\" y \"the dog sat on the\" como contextos completamente no relacionados (para N < longitud completa de la oración). No puede reconocer que ambos involucran un animal sentado sobre algo.",
            p2: "Esta incapacidad de",
            p2Highlight: "generalizar entre contextos similares",
            p2End: " es lo que finalmente limita los modelos N-gram. Sin importar cuántos datos recojas, siempre habrá contextos válidos que el modelo nunca ha visto.",
            p3: "Esta limitación fundamental es exactamente lo que motiva la transición a enfoques neuronales — modelos que aprenden representaciones densas y continuas capaces de reconocer similitud entre contextos.",
        },
        deeperProblem: {
            label: "Limitaciones",
            title: "El Problema Más Profundo",
            lead: "La explosión es un problema práctico. Pero hay uno filosófico que es aún peor.",
            p1: "Imagina que el texto empieza con \"the cat sat on the\". Si el modelo ha visto ese contexto exacto, puede predecir lo que sigue desde la memoria.",
            p2: "Ahora cambia una palabra: \"the dog sat on the\". Un humano ve que es casi igual. El modelo N-gram lo trata como una situación totalmente nueva.",
            p3: "Los N-gramas no tienen concepto de 'similar'. Los contextos 'the cat' y 'the dog' son tan distintos para el modelo como 'the cat' y 'xyzq'. Cada uno es una fila separada en la tabla, sin conexión con ninguna otra.",
            calloutTitle: "Sin Generalización",
            calloutText: "Si el modelo nunca ha visto una secuencia particular en el entrenamiento, no tiene nada que decir. No puede adivinar. No puede razonar por analogía. Simplemente se encoge de hombros.",
        },
        endOfCounting: {
            label: "Reflexión",
            title: "El Fin del Conteo",
            lead: "Hemos llegado al límite de lo que el conteo puede hacer.",
            p1: "Empezamos con bigramas, que recuerdan un carácter. Pasamos a N-gramas, que recuerdan más, y vimos mejorar las predicciones.",
            p2: "Luego nos topamos con dos muros. El muro de la explosión: la tabla crece demasiado rápido para llenarse. Más memoria multiplica la tabla una y otra vez.",
            p3: "El muro de la generalización: cada contexto es una isla. El modelo no puede compartir conocimiento entre contextos similares, por lo que falla con frases nuevas.",
            quote: "La era del conteo ha terminado. La era del aprendizaje comienza.",
            hookLine: "En el próximo capítulo, dejamos de contar. Empezamos a aprender.",
        },
        conclusion: {
            label: "Reflexión",
            title: "El Puente hacia Modelos Neuronales",
            lead: "Los modelos N-gram llevan el modelado estadístico del lenguaje a su extremo lógico — y revelan por qué se necesita un enfoque fundamentalmente diferente.",
            p1: "Hemos visto que aumentar el contexto mejora las predicciones pero desencadena una explosión exponencial en el espacio de estados. Esto no es un error — es una propiedad inherente de los modelos discretos basados en conteo.",
            p2: "El problema central es la representación: los N-gramas representan cada contexto como un punto aislado en un vasto espacio discreto. No hay noción de similitud entre contextos, no hay forma de compartir fuerza estadística entre patrones relacionados.",
            p3: "Los modelos neuronales de lenguaje resuelven esto mapeando tokens discretos en espacios vectoriales continuos donde contextos similares viven cerca unos de otros. Esto les permite generalizar de ejemplos vistos a contextos no vistos pero similares.",
            p4: "La progresión de Bigrama → N-gram → Red Neuronal no es solo histórica — refleja una comprensión cada vez más profunda de lo que significa modelar el lenguaje computacionalmente.",
            quote: "La maldición de la dimensionalidad no es un fallo de los N-gramas — es la razón por la que se inventaron las representaciones neuronales.",
        },
        cta: {
            title: "Continúa Explorando",
            labButton: "Abrir Lab Libre",
            labDesc: "Cambia al modo Lab Libre para acceso completo a la consola de inferencia N-gram, predictor paso a paso y generador de texto con tamaño de contexto ajustable.",
            neuralButton: "Siguiente: Del Conteo al Aprendizaje",
            neuralDesc: "Hemos llevado el conteo a su límite. Ahora construimos algo que aprende.",
        },
        footer: {
            text: "La era estadística está completa. Has visto lo que el conteo puede hacer — y dónde se rompe. Siguiente: modelos que aprenden.",
            brand: "LM-Lab · Modo Educativo",
        },
    },
    neuralNetworkNarrative: {
        cta: {
            title: "Continúa el Viaje",
            subtitle: "Entiendes los bloques fundamentales. Ahora vélos aplicados al lenguaje.",
            labButton: "Abrir Laboratorio Libre",
            labDesc: "Experimenta con perceptrones, funciones de activación y dinámicas de entrenamiento en el playground interactivo.",
            mlpButton: "Siguiente: Modelo MLP",
            mlpDesc: "Aplica estos fundamentos de redes neuronales para construir un modelo de lenguaje real a nivel de caracteres con embeddings.",
        },
        hero: {
            eyebrow: "Comprendiendo los Modelos de Lenguaje",
            titlePrefix: "Redes Neuronales y",
            titleSuffix: "Deep Learning",
            description: "En los capítulos anteriores, exploramos modelos bigrama y N-gram — sistemas de lenguaje construidos sobre contar y memorizar patrones. Funcionan, pero chocan contra un muro. Ahora hacemos una pregunta diferente: ¿y si una máquina pudiera aprender los patrones por sí misma, como un estudiante aprende a leer? Esta es la historia de las redes neuronales — estructuras matemáticas inspiradas en el cerebro que aprenden ajustando millones de pequeños diales hasta acertar.",
            titlePrimary: "Redes Neuronales",
            titleSecondary: "Deep Learning",
        },
        historical: {
            title: "El Sueño de las Máquinas Pensantes",
            lead: "Antes de los GPTs y el deep learning, había una idea simple y audaz: ¿y si pudiéramos construir un modelo matemático de una célula cerebral?",
            p1: "El año es 1943. Warren McCulloch, un neurocientífico, y Walter Pitts, un lógico autodidacta apenas salido de la adolescencia, publican un artículo que cambiará la computación para siempre. Proponen que una sola célula cerebral — una neurona — puede modelarse como una simple puerta lógica: recibe señales de otras neuronas, y si esas señales son lo suficientemente fuertes, \"dispara\" y envía su propia señal hacia adelante. McCulloch y Pitts demostraron que redes de estas unidades simples podrían, en teoría, computar cualquier cosa. Este fue el nacimiento de la idea de que la",
            p1Highlight: "inteligencia podría emerger de simples operaciones matemáticas",
            p1End: " conectadas de la manera correcta. El cerebro no funciona con magia — funciona con señales, umbrales y conexiones. Si pudiéramos replicar eso en una máquina, quizás podríamos replicar el pensamiento mismo.",
            p2: "En 1958, Frank Rosenblatt construyó el Mark I Perceptron — la primera máquina que podía genuinamente aprender de la experiencia. Era un dispositivo físico en Cornell, cableado con fotocélulas y potenciómetros, diseñado para reconocer formas simples. El New York Times publicó una historia afirmando que la Marina había construido una máquina que podía \"caminar, hablar, ver, escribir, reproducirse y ser consciente de su existencia.\" La euforia era enorme. El propio Rosenblatt fue más cuidadoso, pero la emoción era real: por primera vez, una máquina estaba ajustando sus propios parámetros para mejorar en una tarea, sin ser programada explícitamente para cada caso.",
            p3: "Entonces llegó el desplome. En 1969, Marvin Minsky y Seymour Papert publicaron \"Perceptrons\", un análisis matemático riguroso que probaba que los perceptrones de una sola capa tenían",
            p3Highlight: "limitaciones fundamentales que nunca podrían superar",
            p3End: ". El ejemplo más famoso fue XOR — una función lógica simple que ningún perceptrón individual podía aprender, sin importar cuánto lo entrenaras. El impacto del libro fue devastador. La financiación se secó. Los investigadores se mudaron a otros campos. El período de aproximadamente 1969 a 1986 se conoció como el \"Invierno de la IA\" — una larga y fría era en la que la investigación de redes neuronales se consideraba ampliamente un callejón sin salida.",
            quote: "\"La cuestión no es si las máquinas inteligentes pueden tener sentimientos, sino si las máquinas pueden ser inteligentes sin sentimientos.\" — Marvin Minsky, 1986",
            p4: "Pero la idea se negó a morir. A lo largo de los años 70 y principios de los 80, un puñado de investigadores siguió trabajando en relativa oscuridad. En 1986, David Rumelhart, Geoffrey Hinton y Ronald Williams publicaron su artículo histórico sobre retropropagación — el algoritmo que finalmente mostró cómo las redes multicapa podían aprender. El Invierno de la IA comenzó a descongelarse. Pasarían otros 25 años, el auge de los conjuntos de datos masivos y la revolución de las GPU antes de que el deep learning conquistara el mundo. Pero la semilla se plantó en 1943, y nunca dejó de crecer.",
        },
        countingToLearning: {
            title: "De Contar a Aprender",
            lead: "¿Recuerdas nuestro modelo bigrama? Aprendía contando con qué frecuencia un carácter seguía a otro. El modelo N-gram lo extendía contando secuencias más largas. Ambos son fundamentalmente la misma idea: observar, contar, buscar. Las redes neuronales representan una filosofía completamente diferente.",
            p1: "Piensa en lo que realmente almacena un modelo bigrama. Para cada par de caracteres en el texto de entrenamiento, incrementa un contador en una tabla gigante. Cuando necesita predecir el siguiente carácter, busca la fila del carácter actual y lee las probabilidades almacenadas. Esto es pura memorización — el modelo",
            p1Highlight: "no entiende por qué existen ciertos patrones",
            p1End: ", solo que fueron observados. Si el modelo nunca ha visto una combinación particular en sus datos de entrenamiento, tiene literalmente cero información sobre ella. No puede razonar por analogía, no puede notar que \"th\" se comporta de manera similar a \"sh\" en muchos contextos, no puede transferir conocimiento de un patrón a otro.",
            p2: "Las redes neuronales toman el enfoque opuesto. En lugar de memorizar conteos exactos, aprenden un conjunto de",
            p2Highlight: "parámetros numéricos continuos — pesos y sesgos",
            p2End: " — que se ajustan gradualmente durante el entrenamiento. Estos parámetros no corresponden a ningún ejemplo de entrenamiento específico. En cambio, codifican conocimiento comprimido y generalizado sobre los patrones en los datos. Una red neuronal que ha aprendido sobre \"th\" automáticamente tendrá algún conocimiento útil sobre \"sh\" también, porque los parámetros que capturan un patrón se superponen con los que capturan el otro.",
            insightTitle: "La Clave",
            insightText: "Un modelo bigrama almacena un número por cada par de caracteres (el conteo). Una red neuronal almacena un conjunto de parámetros compartidos que codifican conocimiento sobre TODOS los pares de caracteres simultáneamente. Por eso las redes neuronales pueden generalizar: no memorizan hechos individuales — aprenden las reglas subyacentes que generan esos hechos.",
            p3: "Este cambio del conteo discreto a la optimización continua es quizás el salto conceptual más importante en todo el aprendizaje automático. Es la diferencia entre un estudiante que memoriza cada respuesta de un libro de texto y uno que entiende los principios subyacentes lo suficientemente bien como para resolver problemas nuevos que nunca ha visto. Veamos exactamente cómo funciona esto, comenzando con la red neuronal más simple posible: una sola neurona artificial.",
        },
        perceptron: {
            title: "El Perceptrón",
            lead: "Toda red neuronal, sin importar cuán masiva sea, está construida a partir de copias de un simple bloque: la neurona artificial, o perceptrón. Entender esta única unidad es la clave para entender todo lo que sigue.",
            p1: "Imagina que estás decidiendo si salir a la calle. Tienes varias entradas: ¿está soleado? ¿Hace calor? ¿Tienes tiempo libre? Cada uno de estos factores importa, pero no por igual — quizás el clima te importa más que el tiempo libre. Un perceptrón funciona exactamente como este proceso de decisión. Recibe entradas numéricas, y cada entrada es",
            p1Highlight: "multiplicada por un peso que representa cuán importante es esa entrada",
            p1End: ". Un peso positivo grande significa \"esta entrada empuja fuertemente hacia sí.\" Un peso negativo grande significa \"esta entrada empuja fuertemente hacia no.\" Un peso cercano a cero significa \"esta entrada apenas importa.\" El perceptrón suma todas estas entradas ponderadas, añade un término de sesgo (piénsalo como tu humor base — ¿estás generalmente inclinado a salir o quedarte?), y produce un solo número.",
            p2: "Pero una suma cruda no es suficiente. Necesitamos una decisión — sí o no, disparar o no disparar, igual que una neurona real. Así que la suma se pasa a través de una función de activación que la comprime en un rango útil. En el perceptrón original, esta era una simple función escalón: si la suma es mayor que cero, salida 1 (\"dispara\"); de lo contrario, salida 0 (\"no dispara\"). Las redes neuronales modernas usan funciones más suaves, que exploraremos en breve.",
            formulaCaption: "La fórmula del perceptrón: multiplica cada entrada por su peso, suma todo, añade un sesgo, y pasa el resultado por una función de activación f. Esta es la operación atómica de todas las redes neuronales.",
            p3: "Lo que hace esto poderoso es que, con los pesos y sesgo correctos, un solo perceptrón puede",
            p3Highlight: "trazar una línea recta a través de los datos y clasificar todo a un lado como categoría A y al otro como categoría B",
            p3End: ". Puede aprender a distinguir entre caracteres, clasificar spam de correo legítimo, o detectar patrones simples — todo encontrando los números correctos para sus pesos y sesgo durante el entrenamiento.",
            p4: "Pero hay una trampa, y es importante. Un solo perceptrón solo puede aprender patrones que sean linealmente separables — problemas donde puedes trazar una línea recta (o un plano, en dimensiones superiores) entre las categorías. Muchos problemas del mundo real no son tan simples, como veremos cuando discutamos el infame problema XOR. Por ahora, miremos más de cerca los dos tipos de números que hacen funcionar al perceptrón: pesos y sesgos.",
        },
        weightsAndBias: {
            title: "Pesos y Sesgos",
            lead: "Si el perceptrón es el motor, entonces los pesos y sesgos son los diales y perillas que controlan su comportamiento. Estos números — colectivamente llamados \"parámetros\" — son todo lo que la red sabe. Cuando decimos que una red neuronal ha \"aprendido\" algo, queremos decir que ha encontrado buenos valores para estos parámetros.",
            p1: "Piensa en los pesos como perillas de volumen en una mesa de mezclas. Cada entrada a la neurona tiene su propia perilla. Subirla (peso positivo grande) hace que la voz de esa entrada sea fuerte e influyente. Bajarla (cerca de cero) efectivamente la silencia. Ponerla en negativo la convierte en contraria — cuando esa entrada dice \"sí\", la neurona escucha \"no\". El peso en cada conexión codifica la",
            p1Highlight: "relación entre esa entrada específica y la salida de la neurona",
            p1End: ". Una neurona que ha aprendido a detectar la letra \"e\" después de \"th\" tendrá un peso positivo grande en la conexión desde la entrada \"h\" y un peso positivo grande desde la entrada \"t\", mientras que las entradas para caracteres irrelevantes tendrán pesos cercanos a cero.",
            p2: "El sesgo es más sutil pero igualmente importante. Actúa como la",
            p2Highlight: "tendencia base de la neurona — su disposición a activarse incluso antes de ver cualquier entrada",
            p2End: ". Un sesgo positivo significa que la neurona está ansiosa por disparar; necesita menos evidencia de las entradas para activarse. Un sesgo negativo significa que la neurona es reacia; necesita señales de entrada fuertes para superar su estado \"apagado\" por defecto. Juntos, los pesos determinan en qué dirección mira la frontera de decisión, y el sesgo determina dónde se sitúa. Sin sesgo, toda frontera de decisión tendría que pasar por el origen — una restricción severa que paralizaría el aprendizaje.",
            p3: "Aquí está la parte hermosa: al inicio del entrenamiento, todos estos números son aleatorios. La red no sabe nada. Pero a través del proceso de entrenamiento, cada peso y sesgo es empujado — miles o millones de veces — en la dirección que reduce errores. Con el tiempo, el ruido aleatorio cristaliza en conocimiento estructurado. Los parámetros de una red entrenada son una codificación comprimida de todo lo que aprendió de los datos, almacenado como nada más que una larga lista de números decimales.",
            calloutTitle: "Por Qué Importan los \"Parámetros\"",
            calloutText: "GPT-3 tiene 175 mil millones de parámetros. Se rumorea que GPT-4 tiene más de un billón. Cada parámetro es solo un número decimal — un peso o un sesgo. Pero colectivamente, estos números codifican una cantidad asombrosa de conocimiento sobre lenguaje, razonamiento y el mundo. El arte del deep learning es encontrar los valores correctos para todos ellos.",
        },
        activations: {
            title: "Funciones de Activación",
            lead: "Hemos establecido que un perceptrón calcula una suma ponderada y añade un sesgo. Pero aquí hay un problema: las sumas ponderadas son operaciones lineales. Si apilas operaciones lineales unas sobre otras, solo obtienes otra operación lineal. Sin algo que rompa la linealidad, una red de 100 capas sería matemáticamente equivalente a una sola capa. Las funciones de activación son el ingrediente crucial que le da a las redes neuronales su poder.",
            p1: "El problema central es este: si cada neurona simplemente devuelve su suma ponderada directamente, entonces sin importar cuántas capas apiles, toda la red colapsa en una única transformación lineal. Imagina intentar dibujar una línea curva usando solo una regla — no puedes. Las funciones lineales solo pueden modelar relaciones en línea recta. Pero el mundo real está lleno de curvas, umbrales y patrones no lineales. La letra \"e\" es el carácter más común en inglés, pero solo en ciertos contextos — después de \"th\" es muy probable, pero después de \"ee\" mucho menos. Estas relaciones no lineales dependientes del contexto son exactamente lo que las funciones de activación permiten capturar a la red.",
            p2: "Una función de activación se sitúa en la salida de cada neurona y transforma la suma ponderada en algo no lineal. Piénsala como un filtro que remodela la señal. La neurona calcula su suma, y luego la función de activación decide cómo expresar ese resultado. Diferentes funciones de activación tienen diferentes personalidades, y la elección de cuál usar tiene un impacto profundo en qué tan bien aprende la red.",
            reluTitle: "ReLU (Rectified Linear Unit)",
            reluDesc: "El caballo de batalla del deep learning moderno. La regla es simplísima: si la entrada es positiva, pásala sin cambios; si es negativa, devuelve cero. Eso es todo. Esto crea un \"codo\" afilado en cero — las neuronas disparan (positivo) o se quedan en silencio (cero). ReLU es rápida de computar, no sufre ciertas patologías de entrenamiento, y funciona notablemente bien en la práctica. La mayoría de las redes neuronales que encuentras hoy usan ReLU o alguna de sus variantes.",
            sigmoidTitle: "Sigmoide (Función Logística)",
            sigmoidDesc: "La clásica curva en S. Comprime suavemente cualquier entrada al rango (0, 1), haciéndola perfecta para salidas que representan probabilidades. Una entrada muy negativa se mapea a casi 0; una muy positiva a casi 1; y cero se mapea exactamente a 0.5. La sigmoide fue la función de activación dominante durante décadas, pero tiene una debilidad: para entradas muy grandes o muy pequeñas, la curva es casi plana, lo que hace que los gradientes se vuelvan infinitesimalmente pequeños y el entrenamiento agonizantemente lento — un problema llamado \"gradientes que desaparecen.\"",
            tanhTitle: "Tanh (Tangente Hiperbólica)",
            tanhDesc: "Como la sigmoide pero centrada en cero, mapeando entradas al rango (-1, 1). Este centrado en cero ayuda con la estabilidad del entrenamiento porque las salidas tienen valores tanto positivos como negativos, lo que significa que los gradientes durante la retropropagación están menos sesgados en una dirección. Tanh comparte el problema de gradientes que desaparecen de la sigmoide en los extremos, pero generalmente entrena más rápido para capas ocultas.",
            p3: "La elección de la función de activación no es solo un detalle técnico — ",
            p3Highlight: "da forma fundamental a cómo fluye la información a través de la red y cuán eficientemente puede aprender",
            p3End: ". La simplicidad de ReLU hizo prácticas las redes profundas (10+ capas) por primera vez, porque evita el problema de gradientes que desaparecen que plagaba a sigmoide y tanh. Esta única innovación — elegir una mejor función de activación — fue uno de los avances clave que permitió la revolución del deep learning.",
        },
        backpropagation: {
            title: "Retropropagación",
            lead: "Ahora tenemos una red con pesos, sesgos y funciones de activación. Pero, ¿cómo aprende realmente? ¿Cómo se transforman parámetros iniciales aleatorios en conocimiento estructurado? La respuesta es la retropropagación — posiblemente el algoritmo más importante de toda la inteligencia artificial.",
            p1: "El aprendizaje comienza con el fracaso. Alimentamos la red con una entrada (digamos, el carácter \"h\"), produce una predicción (una distribución de probabilidad sobre el siguiente carácter), y comparamos esa predicción con lo que realmente vino después en el texto de entrenamiento. La diferencia entre predicción y realidad es el error, y lo medimos con una",
            p1Highlight: "función de pérdida — un solo número que nos dice exactamente cuán equivocados estamos",
            p1End: ". Cuando la pérdida es alta, la red está confundida. Cuando es baja, la red está acertando. Todo el objetivo del entrenamiento es hacer este número lo más pequeño posible.",
            lossCaption: "La función de pérdida L(y, ŷ) compara la predicción de la red ŷ con la respuesta verdadera y. Una pérdida mayor significa una peor predicción. Entrenar es el proceso de minimizar este valor a través de todos los ejemplos.",
            p2: "La pregunta clave es: dado que conocemos nuestro error actual, ¿cómo debemos cambiar cada peso para reducirlo? Aquí es donde entra el cálculo. Para cada peso en la red, calculamos",
            p2Highlight: "cuánto cambiaría la pérdida si empujáramos ese peso ligeramente",
            p2End: " — esto es el gradiente, la pendiente matemática del error respecto a ese peso particular. Un gradiente positivo significa \"aumentar este peso aumentará el error\" (así que debemos disminuirlo). Un gradiente negativo significa \"aumentar este peso disminuirá el error\" (así que debemos aumentarlo). La magnitud nos dice cuán sensible es el error a ese peso.",
            p3: "Pero aquí está el truco brillante que hace esto eficiente. En una red multicapa, calcular el gradiente para pesos en capas tempranas parece que requeriría rastrear cada camino posible a través de la red — un cómputo exponencialmente costoso. La retropropagación resuelve esto trabajando hacia atrás: calcula el",
            p3Highlight: "gradiente en la capa de salida primero, luego lo propaga eficientemente hacia atrás a través de cada capa usando la regla de la cadena del cálculo",
            p3End: ". Cada capa recibe el gradiente de la capa superior, lo multiplica por su propio gradiente local, y pasa el resultado hacia atrás. Esta elegante recursión significa que calcular gradientes para TODOS los pesos toma aproximadamente el mismo tiempo que un solo paso hacia adelante por la red.",
            p4: "Una vez que tenemos el gradiente para cada peso, aplicamos la regla de actualización: cada peso se empuja en la dirección opuesta a su gradiente, por un paso pequeño controlado por la \"tasa de aprendizaje\" (η). Una tasa de aprendizaje demasiado grande sobrepasará los valores óptimos y oscilará salvajemente. Una demasiado pequeña tardará una eternidad en converger. Encontrar la tasa de aprendizaje correcta es una de las artes prácticas del entrenamiento de redes neuronales.",
            updateCaption: "La regla de actualización por descenso de gradiente: cada peso w se actualiza restando la tasa de aprendizaje η multiplicada por el gradiente de la pérdida respecto a ese peso. Esta simple regla, aplicada millones de veces, es cómo aprenden las redes neuronales.",
            p5: "Todo este ciclo — paso hacia adelante, calcular pérdida, paso hacia atrás, actualizar pesos — se repite para cada lote de ejemplos de entrenamiento, potencialmente millones de veces. Cada ciclo empuja los pesos una cantidad mínima hacia mejores predicciones. Es un proceso lento e iterativo, como un escultor tallando piedra astilla por astilla. Pero el efecto acumulativo es notable: el ruido aleatorio se transforma en un sistema que captura patrones profundos del lenguaje.",
        },
        parameterUpdates: {
            title: "Aprendizaje como Actualización de Parámetros",
            lead: "Hemos descrito la mecánica de un solo paso de actualización. Pero el entrenamiento real implica hacer esto miles o millones de veces. ¿Cómo es el proceso completo? ¿Cómo pasa una red de no saber nada a capturar la estructura estadística de un idioma?",
            p1: "Imagina esto: inicializas una red neuronal con pesos aleatorios. Le das el carácter \"t\" y le pides que prediga qué viene después. Produce una distribución casi uniforme — cada carácter es igualmente probable. La letra \"h\" obtiene la misma probabilidad que \"z\" o \"7\". Las predicciones son",
            p1Highlight: "indistinguibles de lanzar un dado — ruido puro y estructurado",
            p1End: ". Este es el punto de partida de toda red neuronal jamás entrenada. La pérdida es enorme porque la red está máximamente confundida.",
            p2: "Ahora comienza el entrenamiento. Para cada ejemplo en los datos de entrenamiento, calculamos la pérdida, ejecutamos la retropropagación, y actualizamos cada peso por una cantidad mínima. Después de unos cientos de actualizaciones, algo mágico empieza a ocurrir: la pérdida baja. La red comienza a favorecer caracteres comunes sobre los raros. Después de unos miles de actualizaciones, empieza a aprender patrones específicos de caracteres — que las vocales tienden a seguir a las consonantes, que los espacios siguen a ciertas letras. Después de decenas de miles de actualizaciones, captura patrones más sutiles: \"th\" casi siempre es seguido por \"e\", \"a\", \"i\" u \"o\". La red está literalmente esculpiendo sus parámetros para coincidir con la estructura estadística del idioma, un empujoncito a la vez.",
            insightTitle: "El Paisaje de Error",
            insightText: "Imagina la pérdida de la red como una altura en un vasto paisaje montañoso. Cada posible configuración de pesos corresponde a un punto en este paisaje. Entrenar es como dejar caer una bola en este terreno y dejarla rodar cuesta abajo. La bola sigue la pendiente más pronunciada (el gradiente) en cada paso. Puede quedarse atascada en valles que no son el punto más bajo absoluto (mínimos locales), o desacelerarse en mesetas planas. Pero notablemente, en la práctica, el descenso de gradiente encuentra soluciones suficientemente buenas incluso para problemas enormemente complejos. El paisaje de las redes neuronales, a pesar de su dimensionalidad astronómica, resulta ser sorprendentemente navegable.",
            p3: "El proceso de entrenamiento típicamente toma horas, días, o incluso semanas para modelos grandes. Pero cuando converge, el resultado es extraordinario: un conjunto de parámetros numéricos que codifican, en forma comprimida, los patrones de un idioma entero. La red no ha memorizado el texto de entrenamiento — ha extraído sus regularidades y las ha almacenado en una forma que generaliza a texto que nunca ha visto.",
        },
        bigramConnection: {
            title: "Conexión con Modelos Bigrama",
            lead: "He aquí un hecho notable: puedes construir una red neuronal que haga exactamente lo que hace un modelo bigrama — y luego observar cómo aprende a hacer algo mejor. Esta conexión entre contar y aprender es una de las ideas más iluminadoras de todo el modelado de lenguaje.",
            p1: "¿Recuerdas la matriz de transición bigrama? Es una tabla donde cada fila representa un carácter actual y cada columna el siguiente, con cada celda conteniendo una probabilidad. Ahora considera una red neuronal de una sola capa sin capas ocultas: toma un carácter codificado en one-hot como entrada (un vector de ceros con un solo 1 indicando el carácter actual), lo multiplica por una matriz de pesos, y aplica softmax para producir una distribución de probabilidad sobre el siguiente carácter. Aquí está el remate: esa matriz de pesos ES la matriz de transición. Una red lineal de una sola capa, entrenada para predecir el siguiente carácter, convergerá a pesos que son esencialmente idénticos a las log-probabilidades de una tabla bigrama. Contar y aprender llegan a la misma respuesta.",
            p2: "Pero la red neuronal puede ir más allá. Añade una capa oculta con activaciones no lineales, y de repente la red puede aprender",
            p2Highlight: "representaciones densas y comprimidas que capturan similitudes entre caracteres",
            p2End: ". En un modelo bigrama, 'a' y 'e' son entradas completamente no relacionadas en una tabla — dos índices de fila diferentes sin conexión. En una red neuronal, la capa oculta podría aprender a representar ambas vocales con patrones de activación similares, porque aparecen en contextos similares. Esto significa que el conocimiento sobre 'a' se transfiere automáticamente a 'e' — la red generaliza.",
            insightTitle: "De Tablas a Representaciones",
            insightText: "Un modelo bigrama almacena 96×96 = 9.216 probabilidades independientes. Una red neuronal con una capa oculta de 32 dimensiones almacena 96×32 + 32×96 = 6.144 parámetros — menos números, pero organizados de una manera que captura patrones estructurales profundos en lugar de conteos aislados. Cada carácter se convierte en un punto en un espacio de 32 dimensiones donde la distancia refleja similitud lingüística. Este es el nacimiento de la idea que lleva, eventualmente, a word embeddings, atención de transformers y LLMs modernos.",
            p3: "Por esto los modelos neuronales de lenguaje son el sucesor natural de los N-gramas. No solo memorizan patrones — aprenden una representación comprimida y estructurada del lenguaje que puede generalizar mucho más allá de los datos de entrenamiento. El modelo bigrama es el caso base que prueba el concepto; la red neuronal es la generalización que libera todo su potencial.",
        },
        limitations: {
            title: "Poder y Limitaciones",
            lead: "Hemos visto que las redes neuronales pueden aprender a hacer todo lo que hace un modelo bigrama y más. Pero, ¿cuánto más? ¿Cuáles son los límites de estos sistemas? Entender tanto el poder como las limitaciones de las primeras redes neuronales es esencial para comprender por qué el campo siguió empujando hacia arquitecturas más profundas y sofisticadas.",
            p1: "La limitación más famosa de las primeras redes neuronales es el problema XOR. XOR es una función lógica simple: dadas dos entradas binarias, devuelve 1 si exactamente una entrada es 1, y 0 en caso contrario. Dibuja estos cuatro puntos en un plano 2D y verás el problema inmediatamente — no hay",
            p1Highlight: "ninguna línea recta que pueda separar los 1s de los 0s",
            p1End: ". Y como un solo perceptrón solo puede aprender fronteras lineales, fallará en XOR sin importar cuánto lo entrenes. Esta fue la prueba matemática que terminó la primera ola de investigación en redes neuronales. Minsky y Papert lo demostraron en 1969, y el campo se enfrió durante casi dos décadas.",
            p2: "La solución, resultó ser, era casi vergonzosamente simple: añadir una capa oculta. Una red con una capa oculta de incluso solo dos neuronas puede resolver XOR perfectamente. La primera capa aprende a dividir el espacio de entrada en regiones no lineales, y la segunda capa combina esas regiones en la respuesta final. Más generalmente, una red con una capa oculta suficientemente grande puede aproximar CUALQUIER función continua con precisión arbitraria — este es el Teorema de Aproximación Universal, uno de los resultados más importantes en la teoría de redes neuronales. El problema nunca fue que las redes neuronales no pudieran hacerlo. El problema era que nadie sabía cómo entrenar redes multicapa hasta que llegó la retropropagación.",
            p3: "Incluso con retropropagación, las primeras redes neuronales enfrentaban desafíos prácticos reales. El entrenamiento era lento e inestable. Las redes con muchas capas sufrían de gradientes que desaparecen — la señal de error se encogía hasta casi cero al propagarse hacia atrás a través de muchas capas, haciendo imposible que las capas tempranas aprendieran. Requerían cantidades enormes de datos relativas a su tamaño, y los recursos computacionales de los años 90 eran órdenes de magnitud insuficientes para las arquitecturas ambiciosas que los investigadores soñaban. Estas limitaciones prácticas mantuvieron a las redes neuronales como una herramienta de nicho durante décadas, útil pero no dominante.",
            quote: "\"Lo que no puedo crear, no lo entiendo.\" — Richard Feynman. Esta filosofía impulsa la investigación en redes neuronales: entendemos los modelos de lenguaje construyéndolos desde cero, desde el bigrama más simple hasta el transformer más complejo.",
            p4: "La historia de las redes neuronales es una historia de superar limitaciones una por una. El perceptrón no podía resolver XOR — so we added hidden layers. Deep networks suffered from vanishing gradients — so we invented ReLU and batch normalization. Training was slow — so we parallelized it on GPUs. Context was limited — so we invented attention mechanisms and transformers. Cada limitación en este capítulo no es un callejón sin salida sino una señal apuntando hacia el próximo avance. Los bloques básicos que has aprendido aquí — sumas ponderadas, funciones de activación, retropropagación, descenso de gradiente — son los mismos bloques dentro de GPT-4, DALL-E y todo otro sistema de IA moderno. La escala es diferente, pero los principios son idénticos.",
        },
        footer: {
            text: "Has trazado el arco desde el conteo (bigramas) pasando por contexto extendido (N-gramas) hasta representaciones aprendidas (redes neuronales). Siguiente: aplica estas ideas para construir un modelo neuronal de lenguaje real — el MLP.",
            brand: "LM-LAB · Modo Educativo",
        },
    },
};
